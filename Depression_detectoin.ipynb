{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Depression_detectoin.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QUYMW3v8WQks","executionInfo":{"status":"ok","timestamp":1619065206307,"user_tz":420,"elapsed":460,"user":{"displayName":"Shubham Nagarkar","photoUrl":"","userId":"10621817079012605482"}},"outputId":"492b2386-7e92-460c-ff42-b12ff9cea0a0"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lwd4yowDWvOa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619065661923,"user_tz":420,"elapsed":454490,"user":{"displayName":"Shubham Nagarkar","photoUrl":"","userId":"10621817079012605482"}},"outputId":"c6a7930d-3b66-4478-c985-e40e860d3266"},"source":["import pandas as pd\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","from collections import Counter\n","from torch.nn.utils.rnn import pack_padded_sequence\n","from torchsummary import summary\n","!wget http://nlp.stanford.edu/data/glove.42B.300d.zip\n","!unzip '/content/glove.42B.300d.zip'\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-04-22 04:20:11--  http://nlp.stanford.edu/data/glove.42B.300d.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.42B.300d.zip [following]\n","--2021-04-22 04:20:11--  https://nlp.stanford.edu/data/glove.42B.300d.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: http://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip [following]\n","--2021-04-22 04:20:11--  http://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1877800501 (1.7G) [application/zip]\n","Saving to: ‘glove.42B.300d.zip’\n","\n","glove.42B.300d.zip  100%[===================>]   1.75G  5.18MB/s    in 5m 54s  \n","\n","2021-04-22 04:26:05 (5.06 MB/s) - ‘glove.42B.300d.zip’ saved [1877800501/1877800501]\n","\n","Archive:  /content/glove.42B.300d.zip\n","  inflating: glove.42B.300d.txt      \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cbNRjmMHWWqm"},"source":["TRAIN_PATH = '/content/drive/MyDrive/Depression-Detection/new-train-split.csv'\n","TEST_PATH = '/content/drive/MyDrive/Depression-Detection/new-test-split.csv'\n","VAL_PATH = '/content/drive/MyDrive/Depression-Detection/new-dev-split.csv'\n","DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","EMBEDDING_FILE = '/content/glove.42B.300d.txt'\n","vocab2index = {\"\":0, \"UNK\":1}\n","MAX_LEN = 2204\n","MIN_LEN = 109"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6XUO1RBNW86u"},"source":["def get_data(dataset):\n","  \"\"\"\n","  returns features and their labels\n","  \"\"\"\n","  features = dataset.Text\n","  PHQ = dataset.PHQ8_Score\n","  PTSD = dataset.PTSD\n","  # PTSD = dataset['PCL-C']\n","  # PTSD = np.where(PTSD == \"yes\", 1, 0)\n","  \n","  return features, PHQ, PTSD"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mw3yb6ursQuw"},"source":["def get_embeddings():\n","    embeddings_index = {}\n","    with open(EMBEDDING_FILE, encoding='utf8') as f:\n","        for line in f:\n","            values = line.rstrip().rsplit(' ')\n","            word = values[0]\n","            coefs = np.asarray(values[1:], dtype='float32')\n","            embeddings_index[word] = coefs\n","    return embeddings_index\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f1yXDCPVvP3L"},"source":["def tokenize_text(text):\n","  tokens = []\n","  for txt in text:\n","    tokens.append(txt.split())\n","  return tokens"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8JONtkgk3zJQ"},"source":["def encode_sentence(text, vocab2index):\n","    tokenized = tokenize_text([text])\n","    encoded = np.zeros(MAX_LEN, dtype=np.float32)\n","    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized[0]])\n","    length = min(MAX_LEN, len(enc1))\n","    encoded[:length] = enc1[:length]\n","    return  encoded, length"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BkT7Eh57LI0R"},"source":["def get_emb_matrix(glove_embed, word_counts, emb_size = 300):\n","    \"\"\"\n","    returns weight matrix for embeddings\n","    :params: glove_embed - glove dictionary\n","             word_counts - unique words in dataset\n","    \"\"\"\n","\n","    vocab_size = len(word_counts) + 2 \n","    vocab_to_idx = {}\n","    vocab = [\"\", \"UNK\"]\n","    W = np.zeros((vocab_size, emb_size), dtype=\"float32\")\n","    W[0] = np.zeros(emb_size, dtype='float32') # adding a vector for padding\n","    W[1] = np.random.uniform(-0.25, 0.25, emb_size) # adding a vector for unknown words \n","    vocab_to_idx[\"UNK\"] = 1\n","    i = 2\n","    for word in word_counts:\n","        if word in glove_embed:\n","            W[i] = glove_embed[word]\n","        else:\n","            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n","        vocab_to_idx[word] = i\n","        vocab.append(word)\n","        i += 1   \n","    return W, np.array(vocab), vocab_to_idx\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gbEzH-CqF_xu"},"source":["class EarlyStopping:\n","    \"\"\"\n","    Early stops the training if validation loss doesn't improve after a given patience.\n","    \n","    \"\"\"\n","    def __init__(self, patience=8, verbose=False, delta=0, path= '/content/early_stopping_model.pth'):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 10\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'early_stopping_vgg16model.pth'   \n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","    \n","    def __call__(self, val_loss, model):\n","        \n","        score = -val_loss\n","        \n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            \n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            \n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","                \n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0   \n","    \n","    def save_checkpoint(self, val_loss, model):\n","        \"\"\"\n","        saves the current best version of the model if there is decrease in validation loss\n","        \"\"\"\n","        torch.save(model.state_dict(), self.path)\n","        self.vall_loss_min = val_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bGjKYduu-tpV"},"source":["class DepressionDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, PHQ, PTSD):\n","        self.encodings = encodings\n","        self.PHQ = PHQ\n","        self.PTSD = PTSD\n","\n","    def __getitem__(self, idx):\n","        encoding = torch.tensor(self.encodings[idx][0])\n","        phq_score = torch.tensor(self.PHQ[idx])\n","        ptsd_score = torch.tensor(self.PTSD[idx])\n","        length = self.encodings[idx][1]\n","        \n","        return encoding, length, phq_score, ptsd_score\n","\n","    def __len__(self):\n","        return len(self.PHQ)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3JGwvuDWQPAv"},"source":["class LSTM(torch.nn.Module) :\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, glove_weights) :\n","        super().__init__()\n","\n","        self.dropout = nn.Dropout(0.3)\n","        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        self.embeddings.weight.data.copy_(torch.from_numpy(glove_weights))\n","        self.embeddings.weight.requires_grad = False\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=2, bidirectional=True)\n","\n","        #GRU - embeddings - WIKI, IMDB\n","        \n","        self.MLP = nn.Sequential(\n","            nn.Linear(hidden_dim,128),\n","            nn.BatchNorm1d(128),\n","            nn.ReLU(),\n","            nn.Dropout(0.3)\n","        )\n","\n","        self.ptsd_head = nn.Sequential(\n","            nn.Linear(128,64),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU(),\n","            nn.Linear(64, 1),\n","            nn.ReLU()\n","        )\n","\n","        self.phq_head = nn.Sequential(\n","            nn.Linear(128,64),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU(),\n","            nn.Linear(64, 1),\n","            nn.ReLU()\n","        )\n","\n","        \n","    def forward(self, sentence, sentence_length):\n","        sentence_embed = self.embeddings(sentence)\n","        sentence_embed = self.dropout(sentence_embed)\n","\n","        sentence_pack = pack_padded_sequence(sentence_embed, sentence_length, batch_first=True, enforce_sorted=False)\n","        out_pack, (ht, ct) = self.lstm(sentence_pack)\n","        features = self.MLP(ht[-1])\n","        ptsd = self.ptsd_head(features)\n","        phq = self.phq_head(features)\n","\n","        return torch.squeeze(phq, 1), torch.squeeze(ptsd, 1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iRi_SHtNS4P7"},"source":["def train(model, optimizer, criterion_phq, criterion_ptsd, train_loader, val_loader, epochs):\n","\n","  epoch_train_phq_loss = []\n","  epoch_train_ptsd_loss = []\n","  epoch_train_total_loss = []\n","  epoch_train_ptsd_acc = []\n","\n","  epoch_val_phq_loss = []\n","  epoch_val_ptsd_loss = []\n","  epoch_val_total_loss = []\n","  epoch_val_ptsd_acc = []\n","  \n","  epoch_val_loss = []\n","  losses = {'train':{'total':[], 'phq':[], 'ptsd':[]}, 'val':{'total':[], 'phq':[], 'ptsd':[]}}\n","  \n","  print(\"Training started...\\n\")\n","  model.to(DEVICE)\n","  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=60, gamma=0.1, last_epoch=-1, verbose=True)\n","  early_stop = EarlyStopping(patience=12)\n","\n","  for epoch in range(epochs):\n","    \n","    print(\"Epoch : \", epoch+1)\n","    model.train()\n","    for sentence, length, phq_score, ptsd_score in train_loader:\n","      sentence = sentence.to(DEVICE).long()\n","      phq_score = phq_score.to(DEVICE).type(torch.float32)\n","      ptsd_score = ptsd_score.to(DEVICE).type(torch.float32)\n","\n","      optimizer.zero_grad()\n","\n","      phq_op, ptsd_op = model(sentence, length)\n","\n","      loss_phq = criterion_phq(phq_op, phq_score)\n","      loss_ptsd = criterion_ptsd(ptsd_op, ptsd_score)\n","      loss = loss_phq + loss_ptsd\n","      loss.backward()\n","\n","  \n","      epoch_train_phq_loss.append(loss_phq.item())\n","      epoch_train_ptsd_loss.append(loss_ptsd.item())\n","      epoch_train_total_loss.append(loss.item())\n","      optimizer.step()\n","      \n","    train_total_loss = np.average(epoch_train_total_loss)\n","    train_phq_loss = np.average(epoch_train_phq_loss)\n","    train_ptsd_loss = np.average(epoch_train_ptsd_loss)\n","\n","\n","    model.eval()\n","    with torch.no_grad():\n","      for sentence, length, phq_score, ptsd_score in val_loader:\n","        sentence = sentence.to(DEVICE).long()\n","        phq_score = phq_score.to(DEVICE).type(torch.float32)\n","        ptsd_score = ptsd_score.to(DEVICE).type(torch.float32)\n","\n","        phq_op, ptsd_op = model(sentence,length)\n","\n","        loss_phq = criterion_phq(phq_op, phq_score)\n","        loss_ptsd = criterion_ptsd(ptsd_op, ptsd_score)\n","        loss = loss_phq + loss_ptsd\n","\n","\n","        epoch_val_phq_loss.append(loss_phq.item())\n","        epoch_val_ptsd_loss.append(loss_ptsd.item())\n","        epoch_val_total_loss.append(loss.item())\n","\n","      \n","      val_total_loss = np.average(epoch_val_total_loss)\n","      val_phq_loss = np.average(epoch_val_phq_loss)\n","      val_ptsd_loss = np.average(epoch_val_ptsd_loss)\n","\n","\n","    scheduler.step()\n","    early_stop(val_total_loss, model)\n","\n","    if early_stop.early_stop:\n","          print(\"Early stopping\")\n","          used_early_stopping  = True\n","          break\n","\n","    print(\"Train total loss: {0:.3f}, Train PHQ loss: {1:.3f}, Train PTSD loss: {2:.3f} \".format(train_total_loss, train_phq_loss, train_ptsd_loss))\n","    print(\"Val total loss: {0:.3f}, Val PHQ loss: {1:.3f}, Val PTSD loss: {2:.3f} \".format(val_total_loss, val_phq_loss, val_ptsd_loss))\n","    print('--------------------------------------------------------------------------------------------------------------------')\n","\n","    losses['train']['total'].append(train_total_loss) \n","    losses['train']['phq'].append(train_phq_loss) \n","    losses['train']['ptsd'].append(train_ptsd_loss) \n","\n","    losses['val']['total'].append(val_total_loss) \n","    losses['val']['phq'].append(val_phq_loss) \n","    losses['val']['ptsd'].append(val_ptsd_loss) \n","\n","  \n","\n","  return model, losses"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHnRqNJloWD3"},"source":["def get_weights(train_val_df):\n","    \n","    neg, pos = np.bincount(train_val_df)\n","    pos_weight = [1, neg/pos]\n","    \n","\n","    return torch.tensor(pos_weight, dtype=torch.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w7IaBbgTmBrE","executionInfo":{"status":"ok","timestamp":1619061264697,"user_tz":420,"elapsed":137108,"user":{"displayName":"Shubham Nagarkar","photoUrl":"","userId":"10621817079012605482"}},"outputId":"d9e00e12-a6ce-4f40-eaaa-f5346b6a4862"},"source":["#read data from csvs\n","train_dataset = pd.read_csv(TRAIN_PATH)\n","test_dataset = pd.read_csv(TEST_PATH)\n","val_dataset = pd.read_csv(VAL_PATH) \n","\n","# generate sentences and their labels\n","X_train, train_PHQ, train_PTSD = get_data(train_dataset)\n","X_val, val_PHQ, val_PTSD = get_data(val_dataset)\n","X_test, test_PHQ, test_PTSD = get_data(test_dataset)\n","\n","# train_val = np.append(train_PTSD, val_PTSD)\n","# pos_weight = get_weights(train_val)\n","\n","embeddings_dict = get_embeddings()\n","\n","train_text = list(X_train.values)\n","val_text = list(X_val.values)\n","test_text = list(X_test.values)\n","train_tokens = tokenize_text(train_text)\n","val_tokens = tokenize_text(val_text)\n","test_tokens = tokenize_text(test_text)\n","\n","counts = Counter()\n","for tok in train_tokens:\n","  counts.update(tok)\n","for tok in val_tokens:\n","  counts.update(tok)\n","for tok in test_tokens:  \n","  counts.update(tok)\n","\n","print(\"Length of unique words before removing frequent words: \", len(counts))\n","for words in list(counts):\n","  if counts[words] > 3000:\n","    del counts[words]\n","print(\"Length of unique words after removing frequent words: \", len(counts))\n","\n","#creating vocabulary\n","\n","words = [\"\", \"UNK\"]\n","for word in counts:\n","    vocab2index[word] = len(words)\n","    words.append(word)\n","\n","train_encoded = []\n","val_encoded = []\n","test_encoded = []\n","\n","for text in train_text:\n","  train_encoded.append(encode_sentence(text, vocab2index))\n","for text in val_text:\n","  val_encoded.append(encode_sentence(text, vocab2index))\n","for text in test_text:\n","  test_encoded.append(encode_sentence(text, vocab2index))\n","\n","embed_matrix, vocab, vocab_to_idx = get_emb_matrix(embeddings_dict, counts)\n","print(\"Shape of Embedding matrix : \", embed_matrix.shape)\n","print(\"Shape of Vocabulary : \", vocab.shape)\n","print(\"Length of Vocab to index : \", len(vocab_to_idx))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Length of unique words before removing frequent words:  8358\n","Length of unique words after removing frequent words:  8351\n","Shape of Embedding matrix :  (8353, 300)\n","Shape of Vocabulary :  (8353,)\n","Length of Vocab to index :  8352\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vkMJXcbpgBdI"},"source":["vocab_size = 8353\n","embedding_dim = 300\n","hidden_dim = 128\n","lr = 1e-3\n","epochs = 500\n","batch_size = 16\n","\n","model = LSTM(vocab_size, embedding_dim, hidden_dim, embed_matrix)\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","criterion_phq = torch.nn.MSELoss().to(DEVICE) \n","criterion_ptsd = torch.nn.MSELoss().to(DEVICE) \n","\n","train_loader = torch.utils.data.DataLoader(DepressionDataset(train_encoded, train_PHQ, train_PTSD), batch_size=batch_size, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(DepressionDataset(val_encoded, val_PHQ, val_PTSD), batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(DepressionDataset(test_encoded, test_PHQ, test_PTSD), batch_size=batch_size, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LO3z3YpDYVrH","executionInfo":{"status":"ok","timestamp":1619052670440,"user_tz":420,"elapsed":724664,"user":{"displayName":"Shubham Nagarkar","photoUrl":"","userId":"10621817079012605482"}},"outputId":"1035e207-4e12-4270-9d51-84641d9d9ddd"},"source":["model, losses = train(model, optimizer, criterion_phq, criterion_ptsd, train_loader, val_loader, epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training started...\n","\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Epoch :  1\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1525.297, Train PHQ loss: 69.734, Train PTSD loss: 1455.563 Train PTSD acc: 0.710\n","Val total loss: 1486.443, Val PHQ loss: 88.589, Val PTSD loss: 1397.854 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  2\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1537.154, Train PHQ loss: 69.907, Train PTSD loss: 1467.247 Train PTSD acc: 0.710\n","Val total loss: 1400.811, Val PHQ loss: 84.310, Val PTSD loss: 1316.501 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  3\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1511.379, Train PHQ loss: 67.982, Train PTSD loss: 1443.397 Train PTSD acc: 0.710\n","Val total loss: 1431.602, Val PHQ loss: 85.720, Val PTSD loss: 1345.882 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  4\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1492.517, Train PHQ loss: 66.466, Train PTSD loss: 1426.050 Train PTSD acc: 0.710\n","Val total loss: 1430.531, Val PHQ loss: 86.122, Val PTSD loss: 1344.409 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  5\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1480.282, Train PHQ loss: 64.975, Train PTSD loss: 1415.307 Train PTSD acc: 0.710\n","Val total loss: 1426.961, Val PHQ loss: 86.156, Val PTSD loss: 1340.805 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  6\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1469.754, Train PHQ loss: 63.309, Train PTSD loss: 1406.445 Train PTSD acc: 0.710\n","Val total loss: 1390.974, Val PHQ loss: 82.505, Val PTSD loss: 1308.469 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  7\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1458.592, Train PHQ loss: 62.047, Train PTSD loss: 1396.545 Train PTSD acc: 0.710\n","Val total loss: 1375.851, Val PHQ loss: 79.661, Val PTSD loss: 1296.190 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  8\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1447.723, Train PHQ loss: 60.504, Train PTSD loss: 1387.219 Train PTSD acc: 0.710\n","Val total loss: 1358.209, Val PHQ loss: 77.295, Val PTSD loss: 1280.913 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  9\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1435.153, Train PHQ loss: 58.940, Train PTSD loss: 1376.213 Train PTSD acc: 0.710\n","Val total loss: 1337.769, Val PHQ loss: 74.789, Val PTSD loss: 1262.980 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  10\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1424.365, Train PHQ loss: 57.535, Train PTSD loss: 1366.830 Train PTSD acc: 0.710\n","Val total loss: 1311.935, Val PHQ loss: 71.605, Val PTSD loss: 1240.330 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  11\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1414.502, Train PHQ loss: 56.394, Train PTSD loss: 1358.108 Train PTSD acc: 0.710\n","Val total loss: 1306.740, Val PHQ loss: 70.774, Val PTSD loss: 1235.966 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  12\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1402.752, Train PHQ loss: 55.182, Train PTSD loss: 1347.570 Train PTSD acc: 0.710\n","Val total loss: 1290.429, Val PHQ loss: 69.165, Val PTSD loss: 1221.264 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  13\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1391.446, Train PHQ loss: 53.987, Train PTSD loss: 1337.459 Train PTSD acc: 0.710\n","Val total loss: 1296.268, Val PHQ loss: 69.337, Val PTSD loss: 1226.931 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  14\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1380.055, Train PHQ loss: 52.726, Train PTSD loss: 1327.329 Train PTSD acc: 0.710\n","Val total loss: 1273.782, Val PHQ loss: 67.692, Val PTSD loss: 1206.089 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  15\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1369.531, Train PHQ loss: 51.703, Train PTSD loss: 1317.828 Train PTSD acc: 0.710\n","Val total loss: 1244.865, Val PHQ loss: 65.553, Val PTSD loss: 1179.312 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  16\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1357.317, Train PHQ loss: 50.447, Train PTSD loss: 1306.870 Train PTSD acc: 0.710\n","Val total loss: 1249.817, Val PHQ loss: 65.386, Val PTSD loss: 1184.431 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  17\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1344.460, Train PHQ loss: 49.306, Train PTSD loss: 1295.154 Train PTSD acc: 0.710\n","Val total loss: 1232.740, Val PHQ loss: 64.180, Val PTSD loss: 1168.560 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  18\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1333.572, Train PHQ loss: 48.203, Train PTSD loss: 1285.369 Train PTSD acc: 0.710\n","Val total loss: 1222.212, Val PHQ loss: 63.545, Val PTSD loss: 1158.667 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  19\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1321.554, Train PHQ loss: 47.176, Train PTSD loss: 1274.378 Train PTSD acc: 0.710\n","Val total loss: 1211.187, Val PHQ loss: 62.662, Val PTSD loss: 1148.525 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  20\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1309.834, Train PHQ loss: 46.212, Train PTSD loss: 1263.622 Train PTSD acc: 0.710\n","Val total loss: 1191.700, Val PHQ loss: 61.755, Val PTSD loss: 1129.946 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  21\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1297.955, Train PHQ loss: 45.402, Train PTSD loss: 1252.553 Train PTSD acc: 0.710\n","Val total loss: 1182.130, Val PHQ loss: 61.013, Val PTSD loss: 1121.118 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  22\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1285.517, Train PHQ loss: 44.503, Train PTSD loss: 1241.014 Train PTSD acc: 0.710\n","Val total loss: 1169.743, Val PHQ loss: 60.470, Val PTSD loss: 1109.273 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  23\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1274.430, Train PHQ loss: 43.704, Train PTSD loss: 1230.726 Train PTSD acc: 0.710\n","Val total loss: 1159.183, Val PHQ loss: 59.629, Val PTSD loss: 1099.554 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  24\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1262.555, Train PHQ loss: 42.808, Train PTSD loss: 1219.747 Train PTSD acc: 0.710\n","Val total loss: 1145.953, Val PHQ loss: 58.669, Val PTSD loss: 1087.284 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  25\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1250.718, Train PHQ loss: 41.974, Train PTSD loss: 1208.745 Train PTSD acc: 0.710\n","Val total loss: 1148.441, Val PHQ loss: 57.826, Val PTSD loss: 1090.615 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  26\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1238.992, Train PHQ loss: 41.217, Train PTSD loss: 1197.776 Train PTSD acc: 0.710\n","Val total loss: 1141.251, Val PHQ loss: 57.145, Val PTSD loss: 1084.107 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  27\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1227.517, Train PHQ loss: 40.451, Train PTSD loss: 1187.066 Train PTSD acc: 0.710\n","Val total loss: 1139.417, Val PHQ loss: 56.556, Val PTSD loss: 1082.861 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  28\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1216.037, Train PHQ loss: 39.711, Train PTSD loss: 1176.326 Train PTSD acc: 0.710\n","Val total loss: 1130.275, Val PHQ loss: 55.763, Val PTSD loss: 1074.512 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  29\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1205.653, Train PHQ loss: 39.106, Train PTSD loss: 1166.547 Train PTSD acc: 0.710\n","Val total loss: 1124.358, Val PHQ loss: 55.218, Val PTSD loss: 1069.140 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  30\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1193.606, Train PHQ loss: 38.439, Train PTSD loss: 1155.167 Train PTSD acc: 0.710\n","Val total loss: 1140.169, Val PHQ loss: 56.329, Val PTSD loss: 1083.841 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  31\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1181.752, Train PHQ loss: 37.763, Train PTSD loss: 1143.989 Train PTSD acc: 0.710\n","Val total loss: 1145.927, Val PHQ loss: 57.128, Val PTSD loss: 1088.799 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  32\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1170.225, Train PHQ loss: 37.121, Train PTSD loss: 1133.104 Train PTSD acc: 0.710\n","Val total loss: 1133.802, Val PHQ loss: 56.248, Val PTSD loss: 1077.554 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  33\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1159.234, Train PHQ loss: 36.521, Train PTSD loss: 1122.713 Train PTSD acc: 0.710\n","Val total loss: 1134.317, Val PHQ loss: 56.581, Val PTSD loss: 1077.736 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  34\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1148.028, Train PHQ loss: 35.961, Train PTSD loss: 1112.068 Train PTSD acc: 0.710\n","Val total loss: 1128.308, Val PHQ loss: 56.239, Val PTSD loss: 1072.068 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  35\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1139.146, Train PHQ loss: 35.540, Train PTSD loss: 1103.606 Train PTSD acc: 0.710\n","Val total loss: 1115.596, Val PHQ loss: 55.655, Val PTSD loss: 1059.941 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  36\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1128.218, Train PHQ loss: 35.023, Train PTSD loss: 1093.195 Train PTSD acc: 0.710\n","Val total loss: 1103.043, Val PHQ loss: 55.019, Val PTSD loss: 1048.024 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  37\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1117.351, Train PHQ loss: 34.569, Train PTSD loss: 1082.783 Train PTSD acc: 0.710\n","Val total loss: 1096.777, Val PHQ loss: 54.566, Val PTSD loss: 1042.211 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  38\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1106.767, Train PHQ loss: 34.125, Train PTSD loss: 1072.641 Train PTSD acc: 0.710\n","Val total loss: 1095.238, Val PHQ loss: 54.862, Val PTSD loss: 1040.376 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  39\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1096.237, Train PHQ loss: 33.757, Train PTSD loss: 1062.480 Train PTSD acc: 0.710\n","Val total loss: 1097.037, Val PHQ loss: 55.292, Val PTSD loss: 1041.745 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  40\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1085.723, Train PHQ loss: 33.416, Train PTSD loss: 1052.307 Train PTSD acc: 0.710\n","Val total loss: 1091.450, Val PHQ loss: 55.377, Val PTSD loss: 1036.073 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  41\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1075.056, Train PHQ loss: 33.002, Train PTSD loss: 1042.054 Train PTSD acc: 0.710\n","Val total loss: 1093.349, Val PHQ loss: 55.804, Val PTSD loss: 1037.545 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  42\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1064.416, Train PHQ loss: 32.663, Train PTSD loss: 1031.753 Train PTSD acc: 0.710\n","Val total loss: 1086.545, Val PHQ loss: 55.519, Val PTSD loss: 1031.027 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  43\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1054.480, Train PHQ loss: 32.300, Train PTSD loss: 1022.180 Train PTSD acc: 0.710\n","Val total loss: 1083.338, Val PHQ loss: 55.623, Val PTSD loss: 1027.715 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  44\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1043.678, Train PHQ loss: 31.958, Train PTSD loss: 1011.721 Train PTSD acc: 0.710\n","Val total loss: 1084.122, Val PHQ loss: 55.844, Val PTSD loss: 1028.279 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  45\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1033.435, Train PHQ loss: 31.616, Train PTSD loss: 1001.819 Train PTSD acc: 0.710\n","Val total loss: 1075.388, Val PHQ loss: 55.395, Val PTSD loss: 1019.993 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  46\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1023.017, Train PHQ loss: 31.243, Train PTSD loss: 991.774 Train PTSD acc: 0.710\n","Val total loss: 1069.133, Val PHQ loss: 54.949, Val PTSD loss: 1014.184 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  47\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1013.228, Train PHQ loss: 30.946, Train PTSD loss: 982.283 Train PTSD acc: 0.710\n","Val total loss: 1063.456, Val PHQ loss: 54.628, Val PTSD loss: 1008.827 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  48\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 1003.095, Train PHQ loss: 30.636, Train PTSD loss: 972.459 Train PTSD acc: 0.710\n","Val total loss: 1058.169, Val PHQ loss: 54.296, Val PTSD loss: 1003.873 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  49\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 993.067, Train PHQ loss: 30.317, Train PTSD loss: 962.749 Train PTSD acc: 0.710\n","Val total loss: 1052.015, Val PHQ loss: 53.880, Val PTSD loss: 998.135 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  50\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 983.826, Train PHQ loss: 29.996, Train PTSD loss: 953.830 Train PTSD acc: 0.710\n","Val total loss: 1037.090, Val PHQ loss: 53.333, Val PTSD loss: 983.757 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  51\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 974.220, Train PHQ loss: 29.685, Train PTSD loss: 944.535 Train PTSD acc: 0.710\n","Val total loss: 1027.509, Val PHQ loss: 52.979, Val PTSD loss: 974.530 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  52\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 964.636, Train PHQ loss: 29.351, Train PTSD loss: 935.285 Train PTSD acc: 0.710\n","Val total loss: 1019.882, Val PHQ loss: 52.590, Val PTSD loss: 967.292 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  53\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 954.501, Train PHQ loss: 29.040, Train PTSD loss: 925.462 Train PTSD acc: 0.710\n","Val total loss: 1014.025, Val PHQ loss: 52.360, Val PTSD loss: 961.665 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  54\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 944.047, Train PHQ loss: 28.738, Train PTSD loss: 915.308 Train PTSD acc: 0.710\n","Val total loss: 1006.333, Val PHQ loss: 52.304, Val PTSD loss: 954.029 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  55\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 934.139, Train PHQ loss: 28.417, Train PTSD loss: 905.722 Train PTSD acc: 0.710\n","Val total loss: 1002.618, Val PHQ loss: 52.374, Val PTSD loss: 950.243 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  56\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 923.790, Train PHQ loss: 28.177, Train PTSD loss: 895.613 Train PTSD acc: 0.710\n","Val total loss: 992.693, Val PHQ loss: 51.914, Val PTSD loss: 940.779 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  57\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 913.790, Train PHQ loss: 27.911, Train PTSD loss: 885.880 Train PTSD acc: 0.710\n","Val total loss: 984.333, Val PHQ loss: 51.579, Val PTSD loss: 932.753 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  58\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 903.391, Train PHQ loss: 27.568, Train PTSD loss: 875.823 Train PTSD acc: 0.710\n","Val total loss: 976.585, Val PHQ loss: 51.338, Val PTSD loss: 925.247 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  59\n","Adjusting learning rate of group 0 to 1.0000e-03.\n","Train total loss: 893.381, Train PHQ loss: 27.322, Train PTSD loss: 866.060 Train PTSD acc: 0.710\n","Val total loss: 965.258, Val PHQ loss: 50.924, Val PTSD loss: 914.334 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  60\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 883.194, Train PHQ loss: 27.062, Train PTSD loss: 856.132 Train PTSD acc: 0.710\n","Val total loss: 955.024, Val PHQ loss: 50.494, Val PTSD loss: 904.530 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  61\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 872.352, Train PHQ loss: 26.752, Train PTSD loss: 845.600 Train PTSD acc: 0.710\n","Val total loss: 946.704, Val PHQ loss: 50.270, Val PTSD loss: 896.434 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  62\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 862.003, Train PHQ loss: 26.476, Train PTSD loss: 835.527 Train PTSD acc: 0.710\n","Val total loss: 939.660, Val PHQ loss: 50.050, Val PTSD loss: 889.610 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  63\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 852.044, Train PHQ loss: 26.193, Train PTSD loss: 825.852 Train PTSD acc: 0.710\n","Val total loss: 932.062, Val PHQ loss: 49.779, Val PTSD loss: 882.283 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  64\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 842.589, Train PHQ loss: 25.931, Train PTSD loss: 816.658 Train PTSD acc: 0.710\n","Val total loss: 924.153, Val PHQ loss: 49.415, Val PTSD loss: 874.738 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  65\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 833.352, Train PHQ loss: 25.678, Train PTSD loss: 807.674 Train PTSD acc: 0.710\n","Val total loss: 915.168, Val PHQ loss: 49.033, Val PTSD loss: 866.135 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  66\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 824.789, Train PHQ loss: 25.464, Train PTSD loss: 799.325 Train PTSD acc: 0.710\n","Val total loss: 906.280, Val PHQ loss: 48.685, Val PTSD loss: 857.595 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  67\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 815.828, Train PHQ loss: 25.236, Train PTSD loss: 790.592 Train PTSD acc: 0.710\n","Val total loss: 898.344, Val PHQ loss: 48.459, Val PTSD loss: 849.885 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  68\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 807.367, Train PHQ loss: 25.000, Train PTSD loss: 782.367 Train PTSD acc: 0.710\n","Val total loss: 889.811, Val PHQ loss: 48.133, Val PTSD loss: 841.678 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  69\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 799.046, Train PHQ loss: 24.763, Train PTSD loss: 774.283 Train PTSD acc: 0.710\n","Val total loss: 882.059, Val PHQ loss: 47.816, Val PTSD loss: 834.243 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  70\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 790.604, Train PHQ loss: 24.508, Train PTSD loss: 766.096 Train PTSD acc: 0.710\n","Val total loss: 875.273, Val PHQ loss: 47.605, Val PTSD loss: 827.669 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  71\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 782.596, Train PHQ loss: 24.277, Train PTSD loss: 758.319 Train PTSD acc: 0.710\n","Val total loss: 867.335, Val PHQ loss: 47.288, Val PTSD loss: 820.047 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  72\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 774.693, Train PHQ loss: 24.058, Train PTSD loss: 750.634 Train PTSD acc: 0.710\n","Val total loss: 862.548, Val PHQ loss: 47.138, Val PTSD loss: 815.410 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  73\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 767.715, Train PHQ loss: 23.901, Train PTSD loss: 743.814 Train PTSD acc: 0.710\n","Val total loss: 858.806, Val PHQ loss: 47.209, Val PTSD loss: 811.597 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  74\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 760.063, Train PHQ loss: 23.682, Train PTSD loss: 736.381 Train PTSD acc: 0.710\n","Val total loss: 853.509, Val PHQ loss: 47.038, Val PTSD loss: 806.471 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  75\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 753.256, Train PHQ loss: 23.531, Train PTSD loss: 729.725 Train PTSD acc: 0.710\n","Val total loss: 846.889, Val PHQ loss: 46.747, Val PTSD loss: 800.141 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  76\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 745.957, Train PHQ loss: 23.317, Train PTSD loss: 722.641 Train PTSD acc: 0.710\n","Val total loss: 841.356, Val PHQ loss: 46.606, Val PTSD loss: 794.750 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  77\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 739.256, Train PHQ loss: 23.136, Train PTSD loss: 716.120 Train PTSD acc: 0.710\n","Val total loss: 835.361, Val PHQ loss: 46.352, Val PTSD loss: 789.009 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  78\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 732.520, Train PHQ loss: 22.930, Train PTSD loss: 709.591 Train PTSD acc: 0.710\n","Val total loss: 831.164, Val PHQ loss: 46.296, Val PTSD loss: 784.869 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  79\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 726.201, Train PHQ loss: 22.755, Train PTSD loss: 703.445 Train PTSD acc: 0.710\n","Val total loss: 825.592, Val PHQ loss: 46.135, Val PTSD loss: 779.458 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  80\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 719.691, Train PHQ loss: 22.583, Train PTSD loss: 697.108 Train PTSD acc: 0.710\n","Val total loss: 820.795, Val PHQ loss: 45.969, Val PTSD loss: 774.825 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  81\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 713.392, Train PHQ loss: 22.385, Train PTSD loss: 691.008 Train PTSD acc: 0.710\n","Val total loss: 814.458, Val PHQ loss: 45.694, Val PTSD loss: 768.764 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  82\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 707.406, Train PHQ loss: 22.210, Train PTSD loss: 685.196 Train PTSD acc: 0.710\n","Val total loss: 810.711, Val PHQ loss: 45.580, Val PTSD loss: 765.131 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  83\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 701.383, Train PHQ loss: 22.061, Train PTSD loss: 679.323 Train PTSD acc: 0.710\n","Val total loss: 807.117, Val PHQ loss: 45.513, Val PTSD loss: 761.604 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  84\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 695.790, Train PHQ loss: 21.907, Train PTSD loss: 673.882 Train PTSD acc: 0.710\n","Val total loss: 801.459, Val PHQ loss: 45.294, Val PTSD loss: 756.165 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  85\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 690.362, Train PHQ loss: 21.746, Train PTSD loss: 668.616 Train PTSD acc: 0.710\n","Val total loss: 796.773, Val PHQ loss: 45.060, Val PTSD loss: 751.713 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  86\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 684.609, Train PHQ loss: 21.586, Train PTSD loss: 663.022 Train PTSD acc: 0.710\n","Val total loss: 791.452, Val PHQ loss: 44.875, Val PTSD loss: 746.577 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  87\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 678.966, Train PHQ loss: 21.424, Train PTSD loss: 657.542 Train PTSD acc: 0.710\n","Val total loss: 787.437, Val PHQ loss: 44.721, Val PTSD loss: 742.717 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  88\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 673.710, Train PHQ loss: 21.292, Train PTSD loss: 652.418 Train PTSD acc: 0.710\n","Val total loss: 782.314, Val PHQ loss: 44.558, Val PTSD loss: 737.756 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  89\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 668.435, Train PHQ loss: 21.151, Train PTSD loss: 647.284 Train PTSD acc: 0.710\n","Val total loss: 780.427, Val PHQ loss: 44.513, Val PTSD loss: 735.915 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  90\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 663.469, Train PHQ loss: 21.018, Train PTSD loss: 642.451 Train PTSD acc: 0.710\n","Val total loss: 775.900, Val PHQ loss: 44.330, Val PTSD loss: 731.570 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  91\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 658.137, Train PHQ loss: 20.855, Train PTSD loss: 637.283 Train PTSD acc: 0.710\n","Val total loss: 772.902, Val PHQ loss: 44.336, Val PTSD loss: 728.567 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  92\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 653.181, Train PHQ loss: 20.695, Train PTSD loss: 632.487 Train PTSD acc: 0.710\n","Val total loss: 769.439, Val PHQ loss: 44.239, Val PTSD loss: 725.200 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  93\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 648.378, Train PHQ loss: 20.553, Train PTSD loss: 627.826 Train PTSD acc: 0.710\n","Val total loss: 766.218, Val PHQ loss: 44.237, Val PTSD loss: 721.981 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  94\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 643.485, Train PHQ loss: 20.402, Train PTSD loss: 623.083 Train PTSD acc: 0.710\n","Val total loss: 761.443, Val PHQ loss: 44.019, Val PTSD loss: 717.424 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  95\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 638.766, Train PHQ loss: 20.269, Train PTSD loss: 618.497 Train PTSD acc: 0.710\n","Val total loss: 757.337, Val PHQ loss: 43.911, Val PTSD loss: 713.426 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  96\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 634.381, Train PHQ loss: 20.159, Train PTSD loss: 614.222 Train PTSD acc: 0.710\n","Val total loss: 754.237, Val PHQ loss: 43.818, Val PTSD loss: 710.418 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  97\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 629.806, Train PHQ loss: 20.054, Train PTSD loss: 609.752 Train PTSD acc: 0.710\n","Val total loss: 750.024, Val PHQ loss: 43.748, Val PTSD loss: 706.276 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  98\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 625.238, Train PHQ loss: 19.928, Train PTSD loss: 605.310 Train PTSD acc: 0.710\n","Val total loss: 747.224, Val PHQ loss: 43.624, Val PTSD loss: 703.600 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  99\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 621.231, Train PHQ loss: 19.829, Train PTSD loss: 601.402 Train PTSD acc: 0.710\n","Val total loss: 744.419, Val PHQ loss: 43.551, Val PTSD loss: 700.869 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  100\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 616.949, Train PHQ loss: 19.708, Train PTSD loss: 597.241 Train PTSD acc: 0.710\n","Val total loss: 743.444, Val PHQ loss: 43.692, Val PTSD loss: 699.752 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  101\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 612.613, Train PHQ loss: 19.579, Train PTSD loss: 593.034 Train PTSD acc: 0.710\n","Val total loss: 740.413, Val PHQ loss: 43.610, Val PTSD loss: 696.803 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  102\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 608.279, Train PHQ loss: 19.443, Train PTSD loss: 588.836 Train PTSD acc: 0.710\n","Val total loss: 737.534, Val PHQ loss: 43.516, Val PTSD loss: 694.017 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  103\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 604.308, Train PHQ loss: 19.339, Train PTSD loss: 584.970 Train PTSD acc: 0.710\n","Val total loss: 733.342, Val PHQ loss: 43.344, Val PTSD loss: 689.998 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  104\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 600.114, Train PHQ loss: 19.205, Train PTSD loss: 580.909 Train PTSD acc: 0.710\n","Val total loss: 730.665, Val PHQ loss: 43.245, Val PTSD loss: 687.421 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  105\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 596.065, Train PHQ loss: 19.104, Train PTSD loss: 576.961 Train PTSD acc: 0.710\n","Val total loss: 728.507, Val PHQ loss: 43.209, Val PTSD loss: 685.298 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  106\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 592.328, Train PHQ loss: 19.009, Train PTSD loss: 573.318 Train PTSD acc: 0.710\n","Val total loss: 727.563, Val PHQ loss: 43.219, Val PTSD loss: 684.344 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  107\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 588.391, Train PHQ loss: 18.904, Train PTSD loss: 569.487 Train PTSD acc: 0.710\n","Val total loss: 723.501, Val PHQ loss: 43.059, Val PTSD loss: 680.442 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  108\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 584.440, Train PHQ loss: 18.785, Train PTSD loss: 565.655 Train PTSD acc: 0.710\n","Val total loss: 721.823, Val PHQ loss: 43.125, Val PTSD loss: 678.698 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  109\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 580.605, Train PHQ loss: 18.676, Train PTSD loss: 561.930 Train PTSD acc: 0.710\n","Val total loss: 717.926, Val PHQ loss: 42.954, Val PTSD loss: 674.972 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  110\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 576.794, Train PHQ loss: 18.564, Train PTSD loss: 558.230 Train PTSD acc: 0.710\n","Val total loss: 714.913, Val PHQ loss: 42.876, Val PTSD loss: 672.036 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  111\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 573.078, Train PHQ loss: 18.461, Train PTSD loss: 554.617 Train PTSD acc: 0.710\n","Val total loss: 712.466, Val PHQ loss: 42.837, Val PTSD loss: 669.629 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  112\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 569.558, Train PHQ loss: 18.365, Train PTSD loss: 551.193 Train PTSD acc: 0.710\n","Val total loss: 708.519, Val PHQ loss: 42.676, Val PTSD loss: 665.843 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  113\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 566.020, Train PHQ loss: 18.267, Train PTSD loss: 547.753 Train PTSD acc: 0.710\n","Val total loss: 704.635, Val PHQ loss: 42.536, Val PTSD loss: 662.100 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  114\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 562.757, Train PHQ loss: 18.175, Train PTSD loss: 544.581 Train PTSD acc: 0.710\n","Val total loss: 700.968, Val PHQ loss: 42.393, Val PTSD loss: 658.575 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  115\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 559.296, Train PHQ loss: 18.074, Train PTSD loss: 541.222 Train PTSD acc: 0.710\n","Val total loss: 697.425, Val PHQ loss: 42.257, Val PTSD loss: 655.168 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  116\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 556.240, Train PHQ loss: 18.007, Train PTSD loss: 538.233 Train PTSD acc: 0.710\n","Val total loss: 693.900, Val PHQ loss: 42.118, Val PTSD loss: 651.782 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  117\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 552.794, Train PHQ loss: 17.901, Train PTSD loss: 534.893 Train PTSD acc: 0.710\n","Val total loss: 690.506, Val PHQ loss: 42.019, Val PTSD loss: 648.488 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  118\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 549.761, Train PHQ loss: 17.825, Train PTSD loss: 531.936 Train PTSD acc: 0.710\n","Val total loss: 687.243, Val PHQ loss: 41.886, Val PTSD loss: 645.357 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  119\n","Adjusting learning rate of group 0 to 1.0000e-04.\n","Train total loss: 546.429, Train PHQ loss: 17.735, Train PTSD loss: 528.695 Train PTSD acc: 0.710\n","Val total loss: 684.013, Val PHQ loss: 41.754, Val PTSD loss: 642.258 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  120\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 543.398, Train PHQ loss: 17.664, Train PTSD loss: 525.734 Train PTSD acc: 0.710\n","Val total loss: 680.989, Val PHQ loss: 41.659, Val PTSD loss: 639.330 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  121\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 540.305, Train PHQ loss: 17.581, Train PTSD loss: 522.725 Train PTSD acc: 0.710\n","Val total loss: 678.659, Val PHQ loss: 41.592, Val PTSD loss: 637.067 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  122\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 537.187, Train PHQ loss: 17.497, Train PTSD loss: 519.691 Train PTSD acc: 0.710\n","Val total loss: 675.404, Val PHQ loss: 41.478, Val PTSD loss: 633.926 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  123\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 534.149, Train PHQ loss: 17.403, Train PTSD loss: 516.746 Train PTSD acc: 0.710\n","Val total loss: 672.498, Val PHQ loss: 41.346, Val PTSD loss: 631.152 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  124\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 531.143, Train PHQ loss: 17.320, Train PTSD loss: 513.823 Train PTSD acc: 0.710\n","Val total loss: 669.730, Val PHQ loss: 41.219, Val PTSD loss: 628.511 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  125\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 528.154, Train PHQ loss: 17.228, Train PTSD loss: 510.926 Train PTSD acc: 0.710\n","Val total loss: 669.185, Val PHQ loss: 41.267, Val PTSD loss: 627.919 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  126\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 525.335, Train PHQ loss: 17.153, Train PTSD loss: 508.183 Train PTSD acc: 0.710\n","Val total loss: 666.221, Val PHQ loss: 41.176, Val PTSD loss: 625.044 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  127\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 522.649, Train PHQ loss: 17.085, Train PTSD loss: 505.564 Train PTSD acc: 0.710\n","Val total loss: 664.052, Val PHQ loss: 41.067, Val PTSD loss: 622.985 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  128\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 519.805, Train PHQ loss: 17.010, Train PTSD loss: 502.795 Train PTSD acc: 0.710\n","Val total loss: 662.887, Val PHQ loss: 41.070, Val PTSD loss: 621.817 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  129\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 516.915, Train PHQ loss: 16.932, Train PTSD loss: 499.983 Train PTSD acc: 0.710\n","Val total loss: 660.127, Val PHQ loss: 40.981, Val PTSD loss: 619.146 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  130\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 514.626, Train PHQ loss: 16.885, Train PTSD loss: 497.741 Train PTSD acc: 0.710\n","Val total loss: 657.494, Val PHQ loss: 40.888, Val PTSD loss: 616.606 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  131\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 512.102, Train PHQ loss: 16.818, Train PTSD loss: 495.284 Train PTSD acc: 0.710\n","Val total loss: 655.177, Val PHQ loss: 40.782, Val PTSD loss: 614.395 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  132\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 509.485, Train PHQ loss: 16.742, Train PTSD loss: 492.743 Train PTSD acc: 0.710\n","Val total loss: 652.642, Val PHQ loss: 40.660, Val PTSD loss: 611.982 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  133\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 506.816, Train PHQ loss: 16.684, Train PTSD loss: 490.132 Train PTSD acc: 0.710\n","Val total loss: 650.101, Val PHQ loss: 40.556, Val PTSD loss: 609.545 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  134\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 504.235, Train PHQ loss: 16.606, Train PTSD loss: 487.630 Train PTSD acc: 0.710\n","Val total loss: 648.581, Val PHQ loss: 40.590, Val PTSD loss: 607.991 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  135\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 501.578, Train PHQ loss: 16.526, Train PTSD loss: 485.052 Train PTSD acc: 0.710\n","Val total loss: 646.663, Val PHQ loss: 40.538, Val PTSD loss: 606.125 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  136\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 499.201, Train PHQ loss: 16.461, Train PTSD loss: 482.740 Train PTSD acc: 0.710\n","Val total loss: 644.847, Val PHQ loss: 40.475, Val PTSD loss: 604.372 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  137\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 496.822, Train PHQ loss: 16.388, Train PTSD loss: 480.434 Train PTSD acc: 0.710\n","Val total loss: 642.615, Val PHQ loss: 40.451, Val PTSD loss: 602.165 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  138\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 494.543, Train PHQ loss: 16.338, Train PTSD loss: 478.205 Train PTSD acc: 0.710\n","Val total loss: 641.561, Val PHQ loss: 40.436, Val PTSD loss: 601.125 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  139\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 492.421, Train PHQ loss: 16.277, Train PTSD loss: 476.145 Train PTSD acc: 0.710\n","Val total loss: 640.347, Val PHQ loss: 40.432, Val PTSD loss: 599.915 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  140\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 490.083, Train PHQ loss: 16.211, Train PTSD loss: 473.872 Train PTSD acc: 0.710\n","Val total loss: 638.377, Val PHQ loss: 40.410, Val PTSD loss: 597.967 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  141\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 487.805, Train PHQ loss: 16.161, Train PTSD loss: 471.644 Train PTSD acc: 0.710\n","Val total loss: 636.133, Val PHQ loss: 40.307, Val PTSD loss: 595.827 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  142\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 485.662, Train PHQ loss: 16.104, Train PTSD loss: 469.557 Train PTSD acc: 0.710\n","Val total loss: 633.707, Val PHQ loss: 40.213, Val PTSD loss: 593.494 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  143\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 483.874, Train PHQ loss: 16.061, Train PTSD loss: 467.813 Train PTSD acc: 0.710\n","Val total loss: 631.317, Val PHQ loss: 40.136, Val PTSD loss: 591.181 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  144\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 481.795, Train PHQ loss: 16.006, Train PTSD loss: 465.789 Train PTSD acc: 0.710\n","Val total loss: 629.111, Val PHQ loss: 40.031, Val PTSD loss: 589.080 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  145\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 479.576, Train PHQ loss: 15.951, Train PTSD loss: 463.625 Train PTSD acc: 0.710\n","Val total loss: 628.738, Val PHQ loss: 40.073, Val PTSD loss: 588.665 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  146\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 477.520, Train PHQ loss: 15.910, Train PTSD loss: 461.610 Train PTSD acc: 0.710\n","Val total loss: 627.083, Val PHQ loss: 40.055, Val PTSD loss: 587.028 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  147\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 475.630, Train PHQ loss: 15.868, Train PTSD loss: 459.762 Train PTSD acc: 0.710\n","Val total loss: 626.244, Val PHQ loss: 40.063, Val PTSD loss: 586.181 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  148\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 473.486, Train PHQ loss: 15.801, Train PTSD loss: 457.685 Train PTSD acc: 0.710\n","Val total loss: 624.889, Val PHQ loss: 39.993, Val PTSD loss: 584.896 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  149\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 471.317, Train PHQ loss: 15.736, Train PTSD loss: 455.581 Train PTSD acc: 0.710\n","Val total loss: 623.763, Val PHQ loss: 40.017, Val PTSD loss: 583.746 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  150\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 469.374, Train PHQ loss: 15.680, Train PTSD loss: 453.694 Train PTSD acc: 0.710\n","Val total loss: 621.595, Val PHQ loss: 39.932, Val PTSD loss: 581.662 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  151\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 467.195, Train PHQ loss: 15.606, Train PTSD loss: 451.590 Train PTSD acc: 0.710\n","Val total loss: 619.398, Val PHQ loss: 39.856, Val PTSD loss: 579.542 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  152\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 465.251, Train PHQ loss: 15.551, Train PTSD loss: 449.699 Train PTSD acc: 0.710\n","Val total loss: 618.547, Val PHQ loss: 39.927, Val PTSD loss: 578.620 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  153\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 463.498, Train PHQ loss: 15.515, Train PTSD loss: 447.983 Train PTSD acc: 0.710\n","Val total loss: 616.859, Val PHQ loss: 39.835, Val PTSD loss: 577.024 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  154\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 461.599, Train PHQ loss: 15.469, Train PTSD loss: 446.130 Train PTSD acc: 0.710\n","Val total loss: 616.316, Val PHQ loss: 39.822, Val PTSD loss: 576.493 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  155\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 459.691, Train PHQ loss: 15.409, Train PTSD loss: 444.281 Train PTSD acc: 0.710\n","Val total loss: 614.995, Val PHQ loss: 39.759, Val PTSD loss: 575.236 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  156\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 457.864, Train PHQ loss: 15.361, Train PTSD loss: 442.503 Train PTSD acc: 0.710\n","Val total loss: 613.875, Val PHQ loss: 39.760, Val PTSD loss: 574.115 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  157\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 455.948, Train PHQ loss: 15.302, Train PTSD loss: 440.646 Train PTSD acc: 0.710\n","Val total loss: 612.118, Val PHQ loss: 39.678, Val PTSD loss: 572.441 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  158\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 454.036, Train PHQ loss: 15.253, Train PTSD loss: 438.783 Train PTSD acc: 0.710\n","Val total loss: 610.144, Val PHQ loss: 39.605, Val PTSD loss: 570.539 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  159\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 452.392, Train PHQ loss: 15.220, Train PTSD loss: 437.172 Train PTSD acc: 0.710\n","Val total loss: 609.157, Val PHQ loss: 39.598, Val PTSD loss: 569.559 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  160\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 450.798, Train PHQ loss: 15.186, Train PTSD loss: 435.612 Train PTSD acc: 0.710\n","Val total loss: 608.097, Val PHQ loss: 39.556, Val PTSD loss: 568.542 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  161\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 449.104, Train PHQ loss: 15.135, Train PTSD loss: 433.969 Train PTSD acc: 0.710\n","Val total loss: 606.397, Val PHQ loss: 39.555, Val PTSD loss: 566.841 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  162\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 447.440, Train PHQ loss: 15.080, Train PTSD loss: 432.361 Train PTSD acc: 0.710\n","Val total loss: 604.487, Val PHQ loss: 39.473, Val PTSD loss: 565.014 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  163\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 445.756, Train PHQ loss: 15.032, Train PTSD loss: 430.724 Train PTSD acc: 0.710\n","Val total loss: 602.498, Val PHQ loss: 39.389, Val PTSD loss: 563.109 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  164\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 444.034, Train PHQ loss: 14.984, Train PTSD loss: 429.050 Train PTSD acc: 0.710\n","Val total loss: 601.017, Val PHQ loss: 39.347, Val PTSD loss: 561.669 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  165\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 442.219, Train PHQ loss: 14.939, Train PTSD loss: 427.280 Train PTSD acc: 0.710\n","Val total loss: 599.698, Val PHQ loss: 39.296, Val PTSD loss: 560.402 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  166\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 440.460, Train PHQ loss: 14.884, Train PTSD loss: 425.576 Train PTSD acc: 0.710\n","Val total loss: 598.535, Val PHQ loss: 39.267, Val PTSD loss: 559.268 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  167\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 438.784, Train PHQ loss: 14.842, Train PTSD loss: 423.942 Train PTSD acc: 0.710\n","Val total loss: 597.115, Val PHQ loss: 39.243, Val PTSD loss: 557.872 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  168\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 437.139, Train PHQ loss: 14.802, Train PTSD loss: 422.337 Train PTSD acc: 0.710\n","Val total loss: 595.293, Val PHQ loss: 39.180, Val PTSD loss: 556.113 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  169\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 435.380, Train PHQ loss: 14.747, Train PTSD loss: 420.633 Train PTSD acc: 0.710\n","Val total loss: 594.430, Val PHQ loss: 39.132, Val PTSD loss: 555.298 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  170\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 433.661, Train PHQ loss: 14.697, Train PTSD loss: 418.964 Train PTSD acc: 0.710\n","Val total loss: 592.655, Val PHQ loss: 39.071, Val PTSD loss: 553.584 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  171\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 432.157, Train PHQ loss: 14.661, Train PTSD loss: 417.495 Train PTSD acc: 0.710\n","Val total loss: 590.955, Val PHQ loss: 39.001, Val PTSD loss: 551.954 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  172\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 430.633, Train PHQ loss: 14.624, Train PTSD loss: 416.009 Train PTSD acc: 0.710\n","Val total loss: 590.674, Val PHQ loss: 39.059, Val PTSD loss: 551.615 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  173\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 428.906, Train PHQ loss: 14.571, Train PTSD loss: 414.335 Train PTSD acc: 0.710\n","Val total loss: 589.217, Val PHQ loss: 39.037, Val PTSD loss: 550.180 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  174\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 427.527, Train PHQ loss: 14.559, Train PTSD loss: 412.968 Train PTSD acc: 0.710\n","Val total loss: 587.521, Val PHQ loss: 38.973, Val PTSD loss: 548.548 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  175\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 425.855, Train PHQ loss: 14.516, Train PTSD loss: 411.339 Train PTSD acc: 0.710\n","Val total loss: 585.785, Val PHQ loss: 38.893, Val PTSD loss: 546.892 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  176\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 424.515, Train PHQ loss: 14.486, Train PTSD loss: 410.029 Train PTSD acc: 0.710\n","Val total loss: 584.193, Val PHQ loss: 38.819, Val PTSD loss: 545.374 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  177\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 422.974, Train PHQ loss: 14.434, Train PTSD loss: 408.540 Train PTSD acc: 0.710\n","Val total loss: 582.553, Val PHQ loss: 38.752, Val PTSD loss: 543.800 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  178\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 421.624, Train PHQ loss: 14.391, Train PTSD loss: 407.233 Train PTSD acc: 0.710\n","Val total loss: 580.907, Val PHQ loss: 38.694, Val PTSD loss: 542.213 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  179\n","Adjusting learning rate of group 0 to 1.0000e-05.\n","Train total loss: 420.082, Train PHQ loss: 14.343, Train PTSD loss: 405.740 Train PTSD acc: 0.710\n","Val total loss: 579.482, Val PHQ loss: 38.614, Val PTSD loss: 540.868 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  180\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 418.563, Train PHQ loss: 14.289, Train PTSD loss: 404.273 Train PTSD acc: 0.710\n","Val total loss: 578.902, Val PHQ loss: 38.614, Val PTSD loss: 540.288 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  181\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 417.144, Train PHQ loss: 14.261, Train PTSD loss: 402.882 Train PTSD acc: 0.710\n","Val total loss: 577.917, Val PHQ loss: 38.591, Val PTSD loss: 539.326 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  182\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 415.668, Train PHQ loss: 14.221, Train PTSD loss: 401.448 Train PTSD acc: 0.710\n","Val total loss: 576.854, Val PHQ loss: 38.529, Val PTSD loss: 538.325 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  183\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 414.152, Train PHQ loss: 14.174, Train PTSD loss: 399.978 Train PTSD acc: 0.710\n","Val total loss: 575.327, Val PHQ loss: 38.458, Val PTSD loss: 536.869 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  184\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 412.778, Train PHQ loss: 14.132, Train PTSD loss: 398.646 Train PTSD acc: 0.710\n","Val total loss: 574.791, Val PHQ loss: 38.480, Val PTSD loss: 536.311 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  185\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 411.321, Train PHQ loss: 14.089, Train PTSD loss: 397.232 Train PTSD acc: 0.710\n","Val total loss: 573.241, Val PHQ loss: 38.417, Val PTSD loss: 534.824 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  186\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 409.915, Train PHQ loss: 14.049, Train PTSD loss: 395.866 Train PTSD acc: 0.710\n","Val total loss: 571.775, Val PHQ loss: 38.353, Val PTSD loss: 533.423 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  187\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 408.717, Train PHQ loss: 14.013, Train PTSD loss: 394.704 Train PTSD acc: 0.710\n","Val total loss: 571.442, Val PHQ loss: 38.379, Val PTSD loss: 533.063 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  188\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 407.236, Train PHQ loss: 13.969, Train PTSD loss: 393.267 Train PTSD acc: 0.710\n","Val total loss: 570.896, Val PHQ loss: 38.413, Val PTSD loss: 532.483 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  189\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 405.767, Train PHQ loss: 13.923, Train PTSD loss: 391.845 Train PTSD acc: 0.710\n","Val total loss: 569.712, Val PHQ loss: 38.343, Val PTSD loss: 531.368 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  190\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 404.523, Train PHQ loss: 13.882, Train PTSD loss: 390.641 Train PTSD acc: 0.710\n","Val total loss: 568.242, Val PHQ loss: 38.279, Val PTSD loss: 529.963 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  191\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 403.175, Train PHQ loss: 13.845, Train PTSD loss: 389.330 Train PTSD acc: 0.710\n","Val total loss: 566.803, Val PHQ loss: 38.235, Val PTSD loss: 528.568 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  192\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 401.839, Train PHQ loss: 13.802, Train PTSD loss: 388.037 Train PTSD acc: 0.710\n","Val total loss: 565.405, Val PHQ loss: 38.171, Val PTSD loss: 527.234 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  193\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 400.543, Train PHQ loss: 13.765, Train PTSD loss: 386.777 Train PTSD acc: 0.710\n","Val total loss: 564.935, Val PHQ loss: 38.231, Val PTSD loss: 526.704 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  194\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 399.268, Train PHQ loss: 13.734, Train PTSD loss: 385.534 Train PTSD acc: 0.710\n","Val total loss: 563.468, Val PHQ loss: 38.166, Val PTSD loss: 525.302 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  195\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 397.953, Train PHQ loss: 13.696, Train PTSD loss: 384.257 Train PTSD acc: 0.710\n","Val total loss: 562.138, Val PHQ loss: 38.101, Val PTSD loss: 524.038 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  196\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 396.752, Train PHQ loss: 13.663, Train PTSD loss: 383.089 Train PTSD acc: 0.710\n","Val total loss: 560.727, Val PHQ loss: 38.053, Val PTSD loss: 522.674 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  197\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 395.553, Train PHQ loss: 13.629, Train PTSD loss: 381.923 Train PTSD acc: 0.710\n","Val total loss: 559.316, Val PHQ loss: 38.011, Val PTSD loss: 521.305 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  198\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 394.266, Train PHQ loss: 13.582, Train PTSD loss: 380.684 Train PTSD acc: 0.710\n","Val total loss: 557.946, Val PHQ loss: 37.942, Val PTSD loss: 520.004 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  199\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 393.018, Train PHQ loss: 13.542, Train PTSD loss: 379.476 Train PTSD acc: 0.710\n","Val total loss: 556.590, Val PHQ loss: 37.904, Val PTSD loss: 518.686 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  200\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 391.959, Train PHQ loss: 13.507, Train PTSD loss: 378.452 Train PTSD acc: 0.710\n","Val total loss: 555.247, Val PHQ loss: 37.867, Val PTSD loss: 517.380 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  201\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 390.701, Train PHQ loss: 13.467, Train PTSD loss: 377.234 Train PTSD acc: 0.710\n","Val total loss: 553.913, Val PHQ loss: 37.804, Val PTSD loss: 516.108 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  202\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 389.587, Train PHQ loss: 13.430, Train PTSD loss: 376.156 Train PTSD acc: 0.710\n","Val total loss: 552.623, Val PHQ loss: 37.752, Val PTSD loss: 514.872 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  203\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 388.471, Train PHQ loss: 13.410, Train PTSD loss: 375.060 Train PTSD acc: 0.710\n","Val total loss: 551.934, Val PHQ loss: 37.772, Val PTSD loss: 514.162 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  204\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 387.436, Train PHQ loss: 13.380, Train PTSD loss: 374.056 Train PTSD acc: 0.710\n","Val total loss: 550.658, Val PHQ loss: 37.728, Val PTSD loss: 512.929 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  205\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 386.370, Train PHQ loss: 13.352, Train PTSD loss: 373.019 Train PTSD acc: 0.710\n","Val total loss: 549.483, Val PHQ loss: 37.672, Val PTSD loss: 511.811 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  206\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 385.201, Train PHQ loss: 13.315, Train PTSD loss: 371.886 Train PTSD acc: 0.710\n","Val total loss: 548.709, Val PHQ loss: 37.638, Val PTSD loss: 511.071 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  207\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 384.055, Train PHQ loss: 13.285, Train PTSD loss: 370.770 Train PTSD acc: 0.710\n","Val total loss: 547.444, Val PHQ loss: 37.582, Val PTSD loss: 509.862 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  208\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 382.948, Train PHQ loss: 13.254, Train PTSD loss: 369.694 Train PTSD acc: 0.710\n","Val total loss: 546.233, Val PHQ loss: 37.524, Val PTSD loss: 508.710 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  209\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 381.854, Train PHQ loss: 13.224, Train PTSD loss: 368.630 Train PTSD acc: 0.710\n","Val total loss: 545.106, Val PHQ loss: 37.469, Val PTSD loss: 507.637 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  210\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 380.682, Train PHQ loss: 13.188, Train PTSD loss: 367.494 Train PTSD acc: 0.710\n","Val total loss: 544.673, Val PHQ loss: 37.496, Val PTSD loss: 507.177 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  211\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 379.597, Train PHQ loss: 13.157, Train PTSD loss: 366.439 Train PTSD acc: 0.710\n","Val total loss: 543.625, Val PHQ loss: 37.450, Val PTSD loss: 506.175 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  212\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 378.515, Train PHQ loss: 13.130, Train PTSD loss: 365.384 Train PTSD acc: 0.710\n","Val total loss: 542.462, Val PHQ loss: 37.398, Val PTSD loss: 505.064 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  213\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 377.507, Train PHQ loss: 13.103, Train PTSD loss: 364.404 Train PTSD acc: 0.710\n","Val total loss: 541.269, Val PHQ loss: 37.343, Val PTSD loss: 503.927 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  214\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 376.465, Train PHQ loss: 13.072, Train PTSD loss: 363.393 Train PTSD acc: 0.710\n","Val total loss: 540.049, Val PHQ loss: 37.290, Val PTSD loss: 502.758 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  215\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 375.444, Train PHQ loss: 13.041, Train PTSD loss: 362.403 Train PTSD acc: 0.710\n","Val total loss: 539.631, Val PHQ loss: 37.277, Val PTSD loss: 502.353 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  216\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 374.637, Train PHQ loss: 13.030, Train PTSD loss: 361.607 Train PTSD acc: 0.710\n","Val total loss: 538.648, Val PHQ loss: 37.239, Val PTSD loss: 501.409 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  217\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 373.603, Train PHQ loss: 13.000, Train PTSD loss: 360.603 Train PTSD acc: 0.710\n","Val total loss: 537.579, Val PHQ loss: 37.193, Val PTSD loss: 500.386 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  218\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 372.544, Train PHQ loss: 12.972, Train PTSD loss: 359.572 Train PTSD acc: 0.710\n","Val total loss: 536.451, Val PHQ loss: 37.140, Val PTSD loss: 499.311 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  219\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 371.496, Train PHQ loss: 12.942, Train PTSD loss: 358.554 Train PTSD acc: 0.710\n","Val total loss: 536.065, Val PHQ loss: 37.163, Val PTSD loss: 498.902 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  220\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 370.574, Train PHQ loss: 12.921, Train PTSD loss: 357.653 Train PTSD acc: 0.710\n","Val total loss: 535.165, Val PHQ loss: 37.164, Val PTSD loss: 498.000 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  221\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 369.564, Train PHQ loss: 12.888, Train PTSD loss: 356.676 Train PTSD acc: 0.710\n","Val total loss: 534.073, Val PHQ loss: 37.122, Val PTSD loss: 496.951 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  222\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 368.621, Train PHQ loss: 12.860, Train PTSD loss: 355.761 Train PTSD acc: 0.710\n","Val total loss: 533.320, Val PHQ loss: 37.117, Val PTSD loss: 496.203 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  223\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 367.847, Train PHQ loss: 12.847, Train PTSD loss: 354.999 Train PTSD acc: 0.710\n","Val total loss: 532.360, Val PHQ loss: 37.063, Val PTSD loss: 495.296 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  224\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 366.876, Train PHQ loss: 12.813, Train PTSD loss: 354.064 Train PTSD acc: 0.710\n","Val total loss: 531.336, Val PHQ loss: 37.014, Val PTSD loss: 494.322 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  225\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 365.939, Train PHQ loss: 12.784, Train PTSD loss: 353.155 Train PTSD acc: 0.710\n","Val total loss: 530.959, Val PHQ loss: 36.995, Val PTSD loss: 493.964 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  226\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 364.916, Train PHQ loss: 12.759, Train PTSD loss: 352.157 Train PTSD acc: 0.710\n","Val total loss: 529.837, Val PHQ loss: 36.947, Val PTSD loss: 492.891 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  227\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 363.917, Train PHQ loss: 12.727, Train PTSD loss: 351.190 Train PTSD acc: 0.710\n","Val total loss: 528.858, Val PHQ loss: 36.893, Val PTSD loss: 491.965 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  228\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 363.358, Train PHQ loss: 12.718, Train PTSD loss: 350.639 Train PTSD acc: 0.710\n","Val total loss: 528.475, Val PHQ loss: 36.929, Val PTSD loss: 491.546 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  229\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 362.463, Train PHQ loss: 12.693, Train PTSD loss: 349.770 Train PTSD acc: 0.710\n","Val total loss: 527.942, Val PHQ loss: 36.919, Val PTSD loss: 491.023 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  230\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 361.557, Train PHQ loss: 12.663, Train PTSD loss: 348.894 Train PTSD acc: 0.710\n","Val total loss: 527.120, Val PHQ loss: 36.921, Val PTSD loss: 490.199 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  231\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 360.716, Train PHQ loss: 12.643, Train PTSD loss: 348.073 Train PTSD acc: 0.710\n","Val total loss: 526.179, Val PHQ loss: 36.879, Val PTSD loss: 489.300 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  232\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 359.962, Train PHQ loss: 12.624, Train PTSD loss: 347.338 Train PTSD acc: 0.710\n","Val total loss: 525.089, Val PHQ loss: 36.836, Val PTSD loss: 488.253 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  233\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 359.167, Train PHQ loss: 12.604, Train PTSD loss: 346.563 Train PTSD acc: 0.710\n","Val total loss: 524.130, Val PHQ loss: 36.799, Val PTSD loss: 487.331 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  234\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 358.270, Train PHQ loss: 12.573, Train PTSD loss: 345.697 Train PTSD acc: 0.710\n","Val total loss: 523.400, Val PHQ loss: 36.758, Val PTSD loss: 486.642 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  235\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 357.376, Train PHQ loss: 12.548, Train PTSD loss: 344.828 Train PTSD acc: 0.710\n","Val total loss: 522.756, Val PHQ loss: 36.744, Val PTSD loss: 486.012 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  236\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 356.511, Train PHQ loss: 12.515, Train PTSD loss: 343.996 Train PTSD acc: 0.710\n","Val total loss: 522.380, Val PHQ loss: 36.777, Val PTSD loss: 485.603 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  237\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 355.715, Train PHQ loss: 12.486, Train PTSD loss: 343.229 Train PTSD acc: 0.710\n","Val total loss: 522.481, Val PHQ loss: 36.805, Val PTSD loss: 485.675 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  238\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 355.019, Train PHQ loss: 12.468, Train PTSD loss: 342.551 Train PTSD acc: 0.710\n","Val total loss: 522.436, Val PHQ loss: 36.828, Val PTSD loss: 485.608 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  239\n","Adjusting learning rate of group 0 to 1.0000e-06.\n","Train total loss: 354.104, Train PHQ loss: 12.438, Train PTSD loss: 341.666 Train PTSD acc: 0.710\n","Val total loss: 521.489, Val PHQ loss: 36.788, Val PTSD loss: 484.701 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  240\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 353.195, Train PHQ loss: 12.417, Train PTSD loss: 340.778 Train PTSD acc: 0.710\n","Val total loss: 520.676, Val PHQ loss: 36.741, Val PTSD loss: 483.935 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  241\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 352.403, Train PHQ loss: 12.394, Train PTSD loss: 340.009 Train PTSD acc: 0.710\n","Val total loss: 519.671, Val PHQ loss: 36.699, Val PTSD loss: 482.972 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  242\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 351.603, Train PHQ loss: 12.373, Train PTSD loss: 339.229 Train PTSD acc: 0.710\n","Val total loss: 520.163, Val PHQ loss: 36.791, Val PTSD loss: 483.372 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  243\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 350.943, Train PHQ loss: 12.352, Train PTSD loss: 338.592 Train PTSD acc: 0.710\n","Val total loss: 519.775, Val PHQ loss: 36.779, Val PTSD loss: 482.996 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  244\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 350.204, Train PHQ loss: 12.335, Train PTSD loss: 337.868 Train PTSD acc: 0.710\n","Val total loss: 519.345, Val PHQ loss: 36.760, Val PTSD loss: 482.584 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  245\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 349.311, Train PHQ loss: 12.304, Train PTSD loss: 337.007 Train PTSD acc: 0.710\n","Val total loss: 518.748, Val PHQ loss: 36.755, Val PTSD loss: 481.993 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  246\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 348.642, Train PHQ loss: 12.288, Train PTSD loss: 336.353 Train PTSD acc: 0.710\n","Val total loss: 518.547, Val PHQ loss: 36.779, Val PTSD loss: 481.768 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  247\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 347.814, Train PHQ loss: 12.258, Train PTSD loss: 335.556 Train PTSD acc: 0.710\n","Val total loss: 517.686, Val PHQ loss: 36.736, Val PTSD loss: 480.949 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  248\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 347.242, Train PHQ loss: 12.243, Train PTSD loss: 334.998 Train PTSD acc: 0.710\n","Val total loss: 516.908, Val PHQ loss: 36.692, Val PTSD loss: 480.216 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  249\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 346.391, Train PHQ loss: 12.219, Train PTSD loss: 334.173 Train PTSD acc: 0.710\n","Val total loss: 516.663, Val PHQ loss: 36.701, Val PTSD loss: 479.962 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  250\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 345.641, Train PHQ loss: 12.197, Train PTSD loss: 333.444 Train PTSD acc: 0.710\n","Val total loss: 515.741, Val PHQ loss: 36.658, Val PTSD loss: 479.083 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  251\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 344.845, Train PHQ loss: 12.174, Train PTSD loss: 332.671 Train PTSD acc: 0.710\n","Val total loss: 514.808, Val PHQ loss: 36.620, Val PTSD loss: 478.188 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  252\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 344.140, Train PHQ loss: 12.157, Train PTSD loss: 331.983 Train PTSD acc: 0.710\n","Val total loss: 513.922, Val PHQ loss: 36.573, Val PTSD loss: 477.349 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  253\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 343.407, Train PHQ loss: 12.138, Train PTSD loss: 331.269 Train PTSD acc: 0.710\n","Val total loss: 512.996, Val PHQ loss: 36.531, Val PTSD loss: 476.465 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  254\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 342.814, Train PHQ loss: 12.116, Train PTSD loss: 330.698 Train PTSD acc: 0.710\n","Val total loss: 512.384, Val PHQ loss: 36.482, Val PTSD loss: 475.901 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  255\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 342.125, Train PHQ loss: 12.099, Train PTSD loss: 330.026 Train PTSD acc: 0.710\n","Val total loss: 511.656, Val PHQ loss: 36.447, Val PTSD loss: 475.209 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  256\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 341.338, Train PHQ loss: 12.078, Train PTSD loss: 329.260 Train PTSD acc: 0.710\n","Val total loss: 510.879, Val PHQ loss: 36.413, Val PTSD loss: 474.465 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  257\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 340.621, Train PHQ loss: 12.056, Train PTSD loss: 328.565 Train PTSD acc: 0.710\n","Val total loss: 510.874, Val PHQ loss: 36.424, Val PTSD loss: 474.450 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  258\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 339.923, Train PHQ loss: 12.032, Train PTSD loss: 327.891 Train PTSD acc: 0.710\n","Val total loss: 510.149, Val PHQ loss: 36.381, Val PTSD loss: 473.768 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  259\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 339.228, Train PHQ loss: 12.013, Train PTSD loss: 327.216 Train PTSD acc: 0.710\n","Val total loss: 509.674, Val PHQ loss: 36.373, Val PTSD loss: 473.301 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  260\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 338.518, Train PHQ loss: 12.000, Train PTSD loss: 326.518 Train PTSD acc: 0.710\n","Val total loss: 509.193, Val PHQ loss: 36.361, Val PTSD loss: 472.832 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  261\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 337.768, Train PHQ loss: 11.981, Train PTSD loss: 325.787 Train PTSD acc: 0.710\n","Val total loss: 509.241, Val PHQ loss: 36.375, Val PTSD loss: 472.867 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  262\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 337.010, Train PHQ loss: 11.955, Train PTSD loss: 325.054 Train PTSD acc: 0.710\n","Val total loss: 508.415, Val PHQ loss: 36.337, Val PTSD loss: 472.077 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  263\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 336.268, Train PHQ loss: 11.934, Train PTSD loss: 324.334 Train PTSD acc: 0.710\n","Val total loss: 507.603, Val PHQ loss: 36.308, Val PTSD loss: 471.295 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  264\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 335.493, Train PHQ loss: 11.908, Train PTSD loss: 323.584 Train PTSD acc: 0.710\n","Val total loss: 506.877, Val PHQ loss: 36.271, Val PTSD loss: 470.606 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  265\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 334.880, Train PHQ loss: 11.888, Train PTSD loss: 322.992 Train PTSD acc: 0.710\n","Val total loss: 506.100, Val PHQ loss: 36.229, Val PTSD loss: 469.871 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  266\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 334.204, Train PHQ loss: 11.871, Train PTSD loss: 322.334 Train PTSD acc: 0.710\n","Val total loss: 505.573, Val PHQ loss: 36.226, Val PTSD loss: 469.347 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  267\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 333.610, Train PHQ loss: 11.854, Train PTSD loss: 321.756 Train PTSD acc: 0.710\n","Val total loss: 504.794, Val PHQ loss: 36.197, Val PTSD loss: 468.597 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  268\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 333.091, Train PHQ loss: 11.849, Train PTSD loss: 321.242 Train PTSD acc: 0.710\n","Val total loss: 504.322, Val PHQ loss: 36.204, Val PTSD loss: 468.119 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  269\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 332.484, Train PHQ loss: 11.833, Train PTSD loss: 320.651 Train PTSD acc: 0.710\n","Val total loss: 503.666, Val PHQ loss: 36.169, Val PTSD loss: 467.498 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  270\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 331.786, Train PHQ loss: 11.812, Train PTSD loss: 319.974 Train PTSD acc: 0.710\n","Val total loss: 503.879, Val PHQ loss: 36.214, Val PTSD loss: 467.665 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  271\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 331.176, Train PHQ loss: 11.790, Train PTSD loss: 319.386 Train PTSD acc: 0.710\n","Val total loss: 503.175, Val PHQ loss: 36.173, Val PTSD loss: 467.002 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  272\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 330.624, Train PHQ loss: 11.775, Train PTSD loss: 318.849 Train PTSD acc: 0.710\n","Val total loss: 502.385, Val PHQ loss: 36.154, Val PTSD loss: 466.231 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  273\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 329.958, Train PHQ loss: 11.759, Train PTSD loss: 318.199 Train PTSD acc: 0.710\n","Val total loss: 502.028, Val PHQ loss: 36.183, Val PTSD loss: 465.845 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  274\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 329.433, Train PHQ loss: 11.746, Train PTSD loss: 317.686 Train PTSD acc: 0.710\n","Val total loss: 502.016, Val PHQ loss: 36.195, Val PTSD loss: 465.821 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  275\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 328.794, Train PHQ loss: 11.728, Train PTSD loss: 317.066 Train PTSD acc: 0.710\n","Val total loss: 501.199, Val PHQ loss: 36.173, Val PTSD loss: 465.027 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  276\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 328.090, Train PHQ loss: 11.707, Train PTSD loss: 316.382 Train PTSD acc: 0.710\n","Val total loss: 500.475, Val PHQ loss: 36.140, Val PTSD loss: 464.336 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  277\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 327.481, Train PHQ loss: 11.690, Train PTSD loss: 315.791 Train PTSD acc: 0.710\n","Val total loss: 499.864, Val PHQ loss: 36.102, Val PTSD loss: 463.762 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  278\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 326.884, Train PHQ loss: 11.670, Train PTSD loss: 315.214 Train PTSD acc: 0.710\n","Val total loss: 499.298, Val PHQ loss: 36.107, Val PTSD loss: 463.191 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  279\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 326.255, Train PHQ loss: 11.651, Train PTSD loss: 314.604 Train PTSD acc: 0.710\n","Val total loss: 498.739, Val PHQ loss: 36.072, Val PTSD loss: 462.667 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  280\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 325.737, Train PHQ loss: 11.638, Train PTSD loss: 314.098 Train PTSD acc: 0.710\n","Val total loss: 498.671, Val PHQ loss: 36.110, Val PTSD loss: 462.560 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  281\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 325.138, Train PHQ loss: 11.621, Train PTSD loss: 313.517 Train PTSD acc: 0.710\n","Val total loss: 497.954, Val PHQ loss: 36.072, Val PTSD loss: 461.882 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  282\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 324.637, Train PHQ loss: 11.607, Train PTSD loss: 313.030 Train PTSD acc: 0.710\n","Val total loss: 497.371, Val PHQ loss: 36.079, Val PTSD loss: 461.292 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  283\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 324.053, Train PHQ loss: 11.591, Train PTSD loss: 312.462 Train PTSD acc: 0.710\n","Val total loss: 496.805, Val PHQ loss: 36.064, Val PTSD loss: 460.741 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  284\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 323.407, Train PHQ loss: 11.571, Train PTSD loss: 311.837 Train PTSD acc: 0.710\n","Val total loss: 496.324, Val PHQ loss: 36.031, Val PTSD loss: 460.293 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  285\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 322.951, Train PHQ loss: 11.563, Train PTSD loss: 311.389 Train PTSD acc: 0.710\n","Val total loss: 495.697, Val PHQ loss: 35.997, Val PTSD loss: 459.699 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  286\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 322.300, Train PHQ loss: 11.549, Train PTSD loss: 310.751 Train PTSD acc: 0.710\n","Val total loss: 495.024, Val PHQ loss: 35.961, Val PTSD loss: 459.064 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  287\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 321.696, Train PHQ loss: 11.530, Train PTSD loss: 310.167 Train PTSD acc: 0.710\n","Val total loss: 494.608, Val PHQ loss: 35.923, Val PTSD loss: 458.685 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  288\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 321.043, Train PHQ loss: 11.511, Train PTSD loss: 309.532 Train PTSD acc: 0.710\n","Val total loss: 494.081, Val PHQ loss: 35.899, Val PTSD loss: 458.183 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  289\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 320.433, Train PHQ loss: 11.499, Train PTSD loss: 308.934 Train PTSD acc: 0.710\n","Val total loss: 493.497, Val PHQ loss: 35.867, Val PTSD loss: 457.630 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  290\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 319.892, Train PHQ loss: 11.483, Train PTSD loss: 308.408 Train PTSD acc: 0.710\n","Val total loss: 493.101, Val PHQ loss: 35.855, Val PTSD loss: 457.246 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  291\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 319.311, Train PHQ loss: 11.464, Train PTSD loss: 307.847 Train PTSD acc: 0.710\n","Val total loss: 493.340, Val PHQ loss: 35.917, Val PTSD loss: 457.423 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  292\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 318.721, Train PHQ loss: 11.448, Train PTSD loss: 307.273 Train PTSD acc: 0.710\n","Val total loss: 493.806, Val PHQ loss: 35.986, Val PTSD loss: 457.820 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  293\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 318.188, Train PHQ loss: 11.431, Train PTSD loss: 306.757 Train PTSD acc: 0.710\n","Val total loss: 493.402, Val PHQ loss: 35.988, Val PTSD loss: 457.414 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  294\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 317.607, Train PHQ loss: 11.413, Train PTSD loss: 306.194 Train PTSD acc: 0.710\n","Val total loss: 493.033, Val PHQ loss: 35.970, Val PTSD loss: 457.063 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  295\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 317.112, Train PHQ loss: 11.397, Train PTSD loss: 305.715 Train PTSD acc: 0.710\n","Val total loss: 493.066, Val PHQ loss: 35.989, Val PTSD loss: 457.077 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  296\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 316.573, Train PHQ loss: 11.382, Train PTSD loss: 305.190 Train PTSD acc: 0.710\n","Val total loss: 492.922, Val PHQ loss: 36.000, Val PTSD loss: 456.922 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  297\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 315.965, Train PHQ loss: 11.364, Train PTSD loss: 304.601 Train PTSD acc: 0.710\n","Val total loss: 492.925, Val PHQ loss: 36.022, Val PTSD loss: 456.902 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  298\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 315.383, Train PHQ loss: 11.345, Train PTSD loss: 304.037 Train PTSD acc: 0.710\n","Val total loss: 493.174, Val PHQ loss: 36.072, Val PTSD loss: 457.102 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  299\n","Adjusting learning rate of group 0 to 1.0000e-07.\n","Train total loss: 314.932, Train PHQ loss: 11.338, Train PTSD loss: 303.595 Train PTSD acc: 0.710\n","Val total loss: 493.233, Val PHQ loss: 36.090, Val PTSD loss: 457.143 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  300\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 314.428, Train PHQ loss: 11.318, Train PTSD loss: 303.110 Train PTSD acc: 0.710\n","Val total loss: 492.985, Val PHQ loss: 36.089, Val PTSD loss: 456.895 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  301\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 313.943, Train PHQ loss: 11.301, Train PTSD loss: 302.642 Train PTSD acc: 0.710\n","Val total loss: 492.508, Val PHQ loss: 36.086, Val PTSD loss: 456.422 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  302\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 313.497, Train PHQ loss: 11.286, Train PTSD loss: 302.211 Train PTSD acc: 0.710\n","Val total loss: 491.857, Val PHQ loss: 36.068, Val PTSD loss: 455.789 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  303\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 313.020, Train PHQ loss: 11.272, Train PTSD loss: 301.748 Train PTSD acc: 0.710\n","Val total loss: 491.140, Val PHQ loss: 36.038, Val PTSD loss: 455.102 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  304\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 312.632, Train PHQ loss: 11.263, Train PTSD loss: 301.369 Train PTSD acc: 0.710\n","Val total loss: 491.031, Val PHQ loss: 36.050, Val PTSD loss: 454.980 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  305\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 312.130, Train PHQ loss: 11.255, Train PTSD loss: 300.875 Train PTSD acc: 0.710\n","Val total loss: 490.456, Val PHQ loss: 36.021, Val PTSD loss: 454.435 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  306\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 311.615, Train PHQ loss: 11.241, Train PTSD loss: 300.374 Train PTSD acc: 0.710\n","Val total loss: 490.527, Val PHQ loss: 36.036, Val PTSD loss: 454.490 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  307\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 311.046, Train PHQ loss: 11.218, Train PTSD loss: 299.828 Train PTSD acc: 0.710\n","Val total loss: 489.902, Val PHQ loss: 36.008, Val PTSD loss: 453.894 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  308\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 310.672, Train PHQ loss: 11.206, Train PTSD loss: 299.466 Train PTSD acc: 0.710\n","Val total loss: 489.294, Val PHQ loss: 35.985, Val PTSD loss: 453.309 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  309\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 310.092, Train PHQ loss: 11.189, Train PTSD loss: 298.903 Train PTSD acc: 0.710\n","Val total loss: 488.681, Val PHQ loss: 35.959, Val PTSD loss: 452.722 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  310\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 309.576, Train PHQ loss: 11.178, Train PTSD loss: 298.398 Train PTSD acc: 0.710\n","Val total loss: 488.837, Val PHQ loss: 36.007, Val PTSD loss: 452.830 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  311\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 309.143, Train PHQ loss: 11.161, Train PTSD loss: 297.982 Train PTSD acc: 0.710\n","Val total loss: 488.333, Val PHQ loss: 35.978, Val PTSD loss: 452.355 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  312\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 308.839, Train PHQ loss: 11.163, Train PTSD loss: 297.677 Train PTSD acc: 0.710\n","Val total loss: 487.790, Val PHQ loss: 35.950, Val PTSD loss: 451.840 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  313\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 308.289, Train PHQ loss: 11.147, Train PTSD loss: 297.142 Train PTSD acc: 0.710\n","Val total loss: 487.398, Val PHQ loss: 35.952, Val PTSD loss: 451.446 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  314\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 307.741, Train PHQ loss: 11.129, Train PTSD loss: 296.612 Train PTSD acc: 0.710\n","Val total loss: 487.838, Val PHQ loss: 36.019, Val PTSD loss: 451.818 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  315\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 307.397, Train PHQ loss: 11.118, Train PTSD loss: 296.279 Train PTSD acc: 0.710\n","Val total loss: 488.409, Val PHQ loss: 36.087, Val PTSD loss: 452.322 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  316\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 306.847, Train PHQ loss: 11.100, Train PTSD loss: 295.747 Train PTSD acc: 0.710\n","Val total loss: 488.022, Val PHQ loss: 36.057, Val PTSD loss: 451.965 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  317\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 306.315, Train PHQ loss: 11.087, Train PTSD loss: 295.228 Train PTSD acc: 0.710\n","Val total loss: 487.389, Val PHQ loss: 36.028, Val PTSD loss: 451.361 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  318\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 305.951, Train PHQ loss: 11.075, Train PTSD loss: 294.876 Train PTSD acc: 0.710\n","Val total loss: 487.319, Val PHQ loss: 36.033, Val PTSD loss: 451.286 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  319\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 305.453, Train PHQ loss: 11.067, Train PTSD loss: 294.386 Train PTSD acc: 0.710\n","Val total loss: 487.258, Val PHQ loss: 36.047, Val PTSD loss: 451.212 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  320\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 305.039, Train PHQ loss: 11.066, Train PTSD loss: 293.973 Train PTSD acc: 0.710\n","Val total loss: 486.598, Val PHQ loss: 36.013, Val PTSD loss: 450.584 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  321\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 304.706, Train PHQ loss: 11.060, Train PTSD loss: 293.646 Train PTSD acc: 0.710\n","Val total loss: 486.293, Val PHQ loss: 35.978, Val PTSD loss: 450.316 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  322\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 304.199, Train PHQ loss: 11.045, Train PTSD loss: 293.154 Train PTSD acc: 0.710\n","Val total loss: 486.086, Val PHQ loss: 35.956, Val PTSD loss: 450.130 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  323\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 303.762, Train PHQ loss: 11.033, Train PTSD loss: 292.729 Train PTSD acc: 0.710\n","Val total loss: 485.638, Val PHQ loss: 35.925, Val PTSD loss: 449.713 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  324\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 303.307, Train PHQ loss: 11.023, Train PTSD loss: 292.284 Train PTSD acc: 0.710\n","Val total loss: 485.058, Val PHQ loss: 35.888, Val PTSD loss: 449.170 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  325\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 302.911, Train PHQ loss: 11.015, Train PTSD loss: 291.895 Train PTSD acc: 0.710\n","Val total loss: 484.480, Val PHQ loss: 35.861, Val PTSD loss: 448.619 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  326\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 302.444, Train PHQ loss: 11.000, Train PTSD loss: 291.444 Train PTSD acc: 0.710\n","Val total loss: 483.973, Val PHQ loss: 35.832, Val PTSD loss: 448.141 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  327\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 302.020, Train PHQ loss: 10.984, Train PTSD loss: 291.036 Train PTSD acc: 0.710\n","Val total loss: 483.416, Val PHQ loss: 35.814, Val PTSD loss: 447.602 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  328\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 301.616, Train PHQ loss: 10.974, Train PTSD loss: 290.642 Train PTSD acc: 0.710\n","Val total loss: 482.900, Val PHQ loss: 35.787, Val PTSD loss: 447.113 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  329\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 301.241, Train PHQ loss: 10.967, Train PTSD loss: 290.274 Train PTSD acc: 0.710\n","Val total loss: 482.363, Val PHQ loss: 35.772, Val PTSD loss: 446.590 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  330\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 300.814, Train PHQ loss: 10.961, Train PTSD loss: 289.853 Train PTSD acc: 0.710\n","Val total loss: 481.954, Val PHQ loss: 35.776, Val PTSD loss: 446.179 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  331\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 300.439, Train PHQ loss: 10.951, Train PTSD loss: 289.488 Train PTSD acc: 0.710\n","Val total loss: 481.641, Val PHQ loss: 35.774, Val PTSD loss: 445.866 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  332\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 299.926, Train PHQ loss: 10.940, Train PTSD loss: 288.985 Train PTSD acc: 0.710\n","Val total loss: 481.605, Val PHQ loss: 35.780, Val PTSD loss: 445.825 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  333\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 299.545, Train PHQ loss: 10.926, Train PTSD loss: 288.620 Train PTSD acc: 0.710\n","Val total loss: 481.621, Val PHQ loss: 35.842, Val PTSD loss: 445.780 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  334\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 299.173, Train PHQ loss: 10.921, Train PTSD loss: 288.252 Train PTSD acc: 0.710\n","Val total loss: 481.012, Val PHQ loss: 35.821, Val PTSD loss: 445.191 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  335\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 298.790, Train PHQ loss: 10.912, Train PTSD loss: 287.878 Train PTSD acc: 0.710\n","Val total loss: 480.534, Val PHQ loss: 35.823, Val PTSD loss: 444.711 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  336\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 298.330, Train PHQ loss: 10.900, Train PTSD loss: 287.429 Train PTSD acc: 0.710\n","Val total loss: 480.231, Val PHQ loss: 35.816, Val PTSD loss: 444.415 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  337\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 297.893, Train PHQ loss: 10.892, Train PTSD loss: 287.001 Train PTSD acc: 0.710\n","Val total loss: 480.191, Val PHQ loss: 35.864, Val PTSD loss: 444.327 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  338\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 297.539, Train PHQ loss: 10.881, Train PTSD loss: 286.658 Train PTSD acc: 0.710\n","Val total loss: 480.290, Val PHQ loss: 35.901, Val PTSD loss: 444.389 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  339\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 297.139, Train PHQ loss: 10.866, Train PTSD loss: 286.273 Train PTSD acc: 0.710\n","Val total loss: 480.310, Val PHQ loss: 35.910, Val PTSD loss: 444.400 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  340\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 296.707, Train PHQ loss: 10.855, Train PTSD loss: 285.852 Train PTSD acc: 0.710\n","Val total loss: 479.981, Val PHQ loss: 35.878, Val PTSD loss: 444.103 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  341\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 296.358, Train PHQ loss: 10.846, Train PTSD loss: 285.512 Train PTSD acc: 0.710\n","Val total loss: 479.992, Val PHQ loss: 35.893, Val PTSD loss: 444.099 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  342\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 295.956, Train PHQ loss: 10.833, Train PTSD loss: 285.123 Train PTSD acc: 0.710\n","Val total loss: 479.555, Val PHQ loss: 35.893, Val PTSD loss: 443.662 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  343\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 295.560, Train PHQ loss: 10.822, Train PTSD loss: 284.739 Train PTSD acc: 0.710\n","Val total loss: 479.753, Val PHQ loss: 35.941, Val PTSD loss: 443.813 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  344\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 295.168, Train PHQ loss: 10.813, Train PTSD loss: 284.355 Train PTSD acc: 0.710\n","Val total loss: 479.200, Val PHQ loss: 35.911, Val PTSD loss: 443.289 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  345\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 294.879, Train PHQ loss: 10.804, Train PTSD loss: 284.075 Train PTSD acc: 0.710\n","Val total loss: 479.242, Val PHQ loss: 35.927, Val PTSD loss: 443.315 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  346\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 294.445, Train PHQ loss: 10.792, Train PTSD loss: 283.653 Train PTSD acc: 0.710\n","Val total loss: 478.708, Val PHQ loss: 35.902, Val PTSD loss: 442.806 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  347\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 294.042, Train PHQ loss: 10.784, Train PTSD loss: 283.258 Train PTSD acc: 0.710\n","Val total loss: 478.223, Val PHQ loss: 35.876, Val PTSD loss: 442.347 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  348\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 293.608, Train PHQ loss: 10.768, Train PTSD loss: 282.840 Train PTSD acc: 0.710\n","Val total loss: 477.754, Val PHQ loss: 35.850, Val PTSD loss: 441.904 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  349\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 293.246, Train PHQ loss: 10.757, Train PTSD loss: 282.489 Train PTSD acc: 0.710\n","Val total loss: 477.744, Val PHQ loss: 35.855, Val PTSD loss: 441.890 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  350\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 292.786, Train PHQ loss: 10.743, Train PTSD loss: 282.043 Train PTSD acc: 0.710\n","Val total loss: 477.908, Val PHQ loss: 35.899, Val PTSD loss: 442.008 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  351\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 292.418, Train PHQ loss: 10.735, Train PTSD loss: 281.683 Train PTSD acc: 0.710\n","Val total loss: 477.441, Val PHQ loss: 35.872, Val PTSD loss: 441.568 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  352\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 292.084, Train PHQ loss: 10.727, Train PTSD loss: 281.357 Train PTSD acc: 0.710\n","Val total loss: 477.852, Val PHQ loss: 35.911, Val PTSD loss: 441.940 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  353\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 291.762, Train PHQ loss: 10.721, Train PTSD loss: 281.041 Train PTSD acc: 0.710\n","Val total loss: 477.387, Val PHQ loss: 35.884, Val PTSD loss: 441.503 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  354\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 291.354, Train PHQ loss: 10.709, Train PTSD loss: 280.645 Train PTSD acc: 0.710\n","Val total loss: 476.939, Val PHQ loss: 35.857, Val PTSD loss: 441.081 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  355\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 291.004, Train PHQ loss: 10.708, Train PTSD loss: 280.296 Train PTSD acc: 0.710\n","Val total loss: 477.022, Val PHQ loss: 35.874, Val PTSD loss: 441.148 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  356\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 290.611, Train PHQ loss: 10.693, Train PTSD loss: 279.918 Train PTSD acc: 0.710\n","Val total loss: 476.795, Val PHQ loss: 35.850, Val PTSD loss: 440.944 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  357\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 290.209, Train PHQ loss: 10.683, Train PTSD loss: 279.526 Train PTSD acc: 0.710\n","Val total loss: 476.330, Val PHQ loss: 35.831, Val PTSD loss: 440.500 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  358\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 289.868, Train PHQ loss: 10.669, Train PTSD loss: 279.199 Train PTSD acc: 0.710\n","Val total loss: 475.835, Val PHQ loss: 35.808, Val PTSD loss: 440.027 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  359\n","Adjusting learning rate of group 0 to 1.0000e-08.\n","Train total loss: 289.482, Train PHQ loss: 10.661, Train PTSD loss: 278.822 Train PTSD acc: 0.710\n","Val total loss: 475.909, Val PHQ loss: 35.827, Val PTSD loss: 440.083 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  360\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 289.269, Train PHQ loss: 10.660, Train PTSD loss: 278.609 Train PTSD acc: 0.710\n","Val total loss: 476.032, Val PHQ loss: 35.843, Val PTSD loss: 440.189 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  361\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 288.924, Train PHQ loss: 10.651, Train PTSD loss: 278.273 Train PTSD acc: 0.710\n","Val total loss: 475.486, Val PHQ loss: 35.817, Val PTSD loss: 439.668 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  362\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 288.576, Train PHQ loss: 10.637, Train PTSD loss: 277.939 Train PTSD acc: 0.710\n","Val total loss: 475.004, Val PHQ loss: 35.786, Val PTSD loss: 439.218 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  363\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 288.200, Train PHQ loss: 10.633, Train PTSD loss: 277.567 Train PTSD acc: 0.710\n","Val total loss: 474.661, Val PHQ loss: 35.780, Val PTSD loss: 438.880 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  364\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 287.766, Train PHQ loss: 10.619, Train PTSD loss: 277.147 Train PTSD acc: 0.710\n","Val total loss: 474.154, Val PHQ loss: 35.750, Val PTSD loss: 438.404 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  365\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 287.512, Train PHQ loss: 10.622, Train PTSD loss: 276.891 Train PTSD acc: 0.710\n","Val total loss: 474.227, Val PHQ loss: 35.769, Val PTSD loss: 438.458 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  366\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 287.280, Train PHQ loss: 10.615, Train PTSD loss: 276.666 Train PTSD acc: 0.710\n","Val total loss: 473.745, Val PHQ loss: 35.739, Val PTSD loss: 438.006 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  367\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 286.931, Train PHQ loss: 10.605, Train PTSD loss: 276.327 Train PTSD acc: 0.710\n","Val total loss: 473.321, Val PHQ loss: 35.713, Val PTSD loss: 437.608 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  368\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 286.561, Train PHQ loss: 10.594, Train PTSD loss: 275.967 Train PTSD acc: 0.710\n","Val total loss: 473.279, Val PHQ loss: 35.718, Val PTSD loss: 437.561 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  369\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 286.181, Train PHQ loss: 10.584, Train PTSD loss: 275.597 Train PTSD acc: 0.710\n","Val total loss: 473.161, Val PHQ loss: 35.739, Val PTSD loss: 437.422 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  370\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 285.839, Train PHQ loss: 10.579, Train PTSD loss: 275.260 Train PTSD acc: 0.710\n","Val total loss: 472.665, Val PHQ loss: 35.715, Val PTSD loss: 436.950 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  371\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 285.601, Train PHQ loss: 10.574, Train PTSD loss: 275.027 Train PTSD acc: 0.710\n","Val total loss: 472.471, Val PHQ loss: 35.702, Val PTSD loss: 436.769 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  372\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 285.317, Train PHQ loss: 10.570, Train PTSD loss: 274.747 Train PTSD acc: 0.710\n","Val total loss: 472.173, Val PHQ loss: 35.702, Val PTSD loss: 436.470 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  373\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 285.045, Train PHQ loss: 10.563, Train PTSD loss: 274.482 Train PTSD acc: 0.710\n","Val total loss: 471.942, Val PHQ loss: 35.705, Val PTSD loss: 436.237 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  374\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 284.867, Train PHQ loss: 10.561, Train PTSD loss: 274.306 Train PTSD acc: 0.710\n","Val total loss: 471.652, Val PHQ loss: 35.682, Val PTSD loss: 435.970 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  375\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 284.465, Train PHQ loss: 10.548, Train PTSD loss: 273.917 Train PTSD acc: 0.710\n","Val total loss: 471.259, Val PHQ loss: 35.663, Val PTSD loss: 435.596 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  376\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 284.124, Train PHQ loss: 10.541, Train PTSD loss: 273.583 Train PTSD acc: 0.710\n","Val total loss: 470.864, Val PHQ loss: 35.641, Val PTSD loss: 435.223 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  377\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 283.744, Train PHQ loss: 10.530, Train PTSD loss: 273.214 Train PTSD acc: 0.710\n","Val total loss: 470.979, Val PHQ loss: 35.666, Val PTSD loss: 435.313 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  378\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 283.392, Train PHQ loss: 10.518, Train PTSD loss: 272.874 Train PTSD acc: 0.710\n","Val total loss: 471.057, Val PHQ loss: 35.675, Val PTSD loss: 435.381 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  379\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 283.026, Train PHQ loss: 10.510, Train PTSD loss: 272.516 Train PTSD acc: 0.710\n","Val total loss: 470.915, Val PHQ loss: 35.670, Val PTSD loss: 435.245 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  380\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 282.666, Train PHQ loss: 10.502, Train PTSD loss: 272.164 Train PTSD acc: 0.710\n","Val total loss: 470.851, Val PHQ loss: 35.692, Val PTSD loss: 435.159 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  381\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 282.350, Train PHQ loss: 10.491, Train PTSD loss: 271.859 Train PTSD acc: 0.710\n","Val total loss: 470.453, Val PHQ loss: 35.669, Val PTSD loss: 434.784 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  382\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 282.042, Train PHQ loss: 10.481, Train PTSD loss: 271.561 Train PTSD acc: 0.710\n","Val total loss: 469.992, Val PHQ loss: 35.650, Val PTSD loss: 434.342 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  383\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 281.739, Train PHQ loss: 10.469, Train PTSD loss: 271.270 Train PTSD acc: 0.710\n","Val total loss: 469.580, Val PHQ loss: 35.627, Val PTSD loss: 433.953 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  384\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 281.387, Train PHQ loss: 10.457, Train PTSD loss: 270.930 Train PTSD acc: 0.710\n","Val total loss: 469.249, Val PHQ loss: 35.637, Val PTSD loss: 433.612 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  385\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 281.043, Train PHQ loss: 10.447, Train PTSD loss: 270.596 Train PTSD acc: 0.710\n","Val total loss: 468.896, Val PHQ loss: 35.640, Val PTSD loss: 433.255 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  386\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 280.682, Train PHQ loss: 10.436, Train PTSD loss: 270.246 Train PTSD acc: 0.710\n","Val total loss: 468.639, Val PHQ loss: 35.636, Val PTSD loss: 433.003 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  387\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 280.429, Train PHQ loss: 10.438, Train PTSD loss: 269.991 Train PTSD acc: 0.710\n","Val total loss: 468.699, Val PHQ loss: 35.677, Val PTSD loss: 433.022 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  388\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 280.116, Train PHQ loss: 10.428, Train PTSD loss: 269.688 Train PTSD acc: 0.710\n","Val total loss: 468.286, Val PHQ loss: 35.653, Val PTSD loss: 432.634 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  389\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 279.729, Train PHQ loss: 10.416, Train PTSD loss: 269.313 Train PTSD acc: 0.710\n","Val total loss: 468.132, Val PHQ loss: 35.639, Val PTSD loss: 432.493 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  390\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 279.364, Train PHQ loss: 10.406, Train PTSD loss: 268.959 Train PTSD acc: 0.710\n","Val total loss: 468.549, Val PHQ loss: 35.678, Val PTSD loss: 432.871 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  391\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 279.003, Train PHQ loss: 10.393, Train PTSD loss: 268.609 Train PTSD acc: 0.710\n","Val total loss: 468.425, Val PHQ loss: 35.695, Val PTSD loss: 432.730 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  392\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 278.729, Train PHQ loss: 10.389, Train PTSD loss: 268.340 Train PTSD acc: 0.710\n","Val total loss: 468.171, Val PHQ loss: 35.702, Val PTSD loss: 432.469 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  393\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 278.482, Train PHQ loss: 10.381, Train PTSD loss: 268.101 Train PTSD acc: 0.710\n","Val total loss: 468.052, Val PHQ loss: 35.703, Val PTSD loss: 432.349 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  394\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 278.259, Train PHQ loss: 10.374, Train PTSD loss: 267.885 Train PTSD acc: 0.710\n","Val total loss: 468.091, Val PHQ loss: 35.714, Val PTSD loss: 432.377 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  395\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 277.993, Train PHQ loss: 10.372, Train PTSD loss: 267.621 Train PTSD acc: 0.710\n","Val total loss: 467.668, Val PHQ loss: 35.695, Val PTSD loss: 431.973 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  396\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 277.664, Train PHQ loss: 10.362, Train PTSD loss: 267.301 Train PTSD acc: 0.710\n","Val total loss: 467.874, Val PHQ loss: 35.738, Val PTSD loss: 432.137 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  397\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 277.429, Train PHQ loss: 10.350, Train PTSD loss: 267.078 Train PTSD acc: 0.710\n","Val total loss: 467.817, Val PHQ loss: 35.754, Val PTSD loss: 432.062 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  398\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 277.136, Train PHQ loss: 10.341, Train PTSD loss: 266.795 Train PTSD acc: 0.710\n","Val total loss: 467.405, Val PHQ loss: 35.736, Val PTSD loss: 431.669 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  399\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 276.892, Train PHQ loss: 10.339, Train PTSD loss: 266.553 Train PTSD acc: 0.710\n","Val total loss: 467.302, Val PHQ loss: 35.731, Val PTSD loss: 431.571 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  400\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 276.674, Train PHQ loss: 10.334, Train PTSD loss: 266.340 Train PTSD acc: 0.710\n","Val total loss: 467.177, Val PHQ loss: 35.724, Val PTSD loss: 431.453 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  401\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 276.344, Train PHQ loss: 10.328, Train PTSD loss: 266.016 Train PTSD acc: 0.710\n","Val total loss: 467.289, Val PHQ loss: 35.754, Val PTSD loss: 431.535 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  402\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 276.123, Train PHQ loss: 10.323, Train PTSD loss: 265.800 Train PTSD acc: 0.710\n","Val total loss: 467.216, Val PHQ loss: 35.746, Val PTSD loss: 431.470 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  403\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 275.774, Train PHQ loss: 10.312, Train PTSD loss: 265.462 Train PTSD acc: 0.710\n","Val total loss: 467.076, Val PHQ loss: 35.740, Val PTSD loss: 431.336 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  404\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 275.492, Train PHQ loss: 10.304, Train PTSD loss: 265.188 Train PTSD acc: 0.710\n","Val total loss: 466.851, Val PHQ loss: 35.737, Val PTSD loss: 431.114 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  405\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 275.220, Train PHQ loss: 10.295, Train PTSD loss: 264.925 Train PTSD acc: 0.710\n","Val total loss: 466.866, Val PHQ loss: 35.749, Val PTSD loss: 431.117 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  406\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 274.898, Train PHQ loss: 10.286, Train PTSD loss: 264.612 Train PTSD acc: 0.710\n","Val total loss: 466.487, Val PHQ loss: 35.730, Val PTSD loss: 430.757 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  407\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 274.697, Train PHQ loss: 10.281, Train PTSD loss: 264.416 Train PTSD acc: 0.710\n","Val total loss: 466.132, Val PHQ loss: 35.707, Val PTSD loss: 430.426 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  408\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 274.546, Train PHQ loss: 10.278, Train PTSD loss: 264.268 Train PTSD acc: 0.710\n","Val total loss: 465.986, Val PHQ loss: 35.711, Val PTSD loss: 430.275 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  409\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 274.274, Train PHQ loss: 10.273, Train PTSD loss: 264.001 Train PTSD acc: 0.710\n","Val total loss: 465.577, Val PHQ loss: 35.693, Val PTSD loss: 429.884 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  410\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 273.989, Train PHQ loss: 10.263, Train PTSD loss: 263.727 Train PTSD acc: 0.710\n","Val total loss: 465.696, Val PHQ loss: 35.738, Val PTSD loss: 429.959 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  411\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 273.696, Train PHQ loss: 10.254, Train PTSD loss: 263.442 Train PTSD acc: 0.710\n","Val total loss: 465.253, Val PHQ loss: 35.716, Val PTSD loss: 429.537 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  412\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 273.374, Train PHQ loss: 10.244, Train PTSD loss: 263.129 Train PTSD acc: 0.710\n","Val total loss: 465.287, Val PHQ loss: 35.725, Val PTSD loss: 429.562 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  413\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 273.088, Train PHQ loss: 10.239, Train PTSD loss: 262.849 Train PTSD acc: 0.710\n","Val total loss: 465.402, Val PHQ loss: 35.741, Val PTSD loss: 429.661 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  414\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 272.870, Train PHQ loss: 10.235, Train PTSD loss: 262.635 Train PTSD acc: 0.710\n","Val total loss: 465.108, Val PHQ loss: 35.742, Val PTSD loss: 429.366 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  415\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 272.709, Train PHQ loss: 10.235, Train PTSD loss: 262.474 Train PTSD acc: 0.710\n","Val total loss: 464.979, Val PHQ loss: 35.738, Val PTSD loss: 429.241 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  416\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 272.443, Train PHQ loss: 10.229, Train PTSD loss: 262.214 Train PTSD acc: 0.710\n","Val total loss: 464.971, Val PHQ loss: 35.764, Val PTSD loss: 429.207 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  417\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 272.150, Train PHQ loss: 10.218, Train PTSD loss: 261.932 Train PTSD acc: 0.710\n","Val total loss: 464.841, Val PHQ loss: 35.766, Val PTSD loss: 429.075 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  418\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 271.846, Train PHQ loss: 10.209, Train PTSD loss: 261.637 Train PTSD acc: 0.710\n","Val total loss: 464.445, Val PHQ loss: 35.747, Val PTSD loss: 428.699 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  419\n","Adjusting learning rate of group 0 to 1.0000e-09.\n","Train total loss: 271.543, Train PHQ loss: 10.201, Train PTSD loss: 261.342 Train PTSD acc: 0.710\n","Val total loss: 464.489, Val PHQ loss: 35.758, Val PTSD loss: 428.730 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  420\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 271.303, Train PHQ loss: 10.195, Train PTSD loss: 261.108 Train PTSD acc: 0.710\n","Val total loss: 464.078, Val PHQ loss: 35.740, Val PTSD loss: 428.337 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  421\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 271.048, Train PHQ loss: 10.187, Train PTSD loss: 260.861 Train PTSD acc: 0.710\n","Val total loss: 463.713, Val PHQ loss: 35.721, Val PTSD loss: 427.992 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  422\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 270.830, Train PHQ loss: 10.181, Train PTSD loss: 260.649 Train PTSD acc: 0.710\n","Val total loss: 463.390, Val PHQ loss: 35.694, Val PTSD loss: 427.696 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  423\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 270.694, Train PHQ loss: 10.178, Train PTSD loss: 260.516 Train PTSD acc: 0.710\n","Val total loss: 463.028, Val PHQ loss: 35.672, Val PTSD loss: 427.356 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  424\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 270.403, Train PHQ loss: 10.172, Train PTSD loss: 260.230 Train PTSD acc: 0.710\n","Val total loss: 462.850, Val PHQ loss: 35.665, Val PTSD loss: 427.185 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  425\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 270.167, Train PHQ loss: 10.168, Train PTSD loss: 259.999 Train PTSD acc: 0.710\n","Val total loss: 462.868, Val PHQ loss: 35.678, Val PTSD loss: 427.190 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  426\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 269.886, Train PHQ loss: 10.162, Train PTSD loss: 259.724 Train PTSD acc: 0.710\n","Val total loss: 462.524, Val PHQ loss: 35.655, Val PTSD loss: 426.870 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  427\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 269.631, Train PHQ loss: 10.157, Train PTSD loss: 259.473 Train PTSD acc: 0.710\n","Val total loss: 462.248, Val PHQ loss: 35.634, Val PTSD loss: 426.614 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  428\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 269.307, Train PHQ loss: 10.147, Train PTSD loss: 259.160 Train PTSD acc: 0.710\n","Val total loss: 462.312, Val PHQ loss: 35.673, Val PTSD loss: 426.638 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  429\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 269.100, Train PHQ loss: 10.142, Train PTSD loss: 258.958 Train PTSD acc: 0.710\n","Val total loss: 462.161, Val PHQ loss: 35.670, Val PTSD loss: 426.491 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  430\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 268.879, Train PHQ loss: 10.136, Train PTSD loss: 258.743 Train PTSD acc: 0.710\n","Val total loss: 462.283, Val PHQ loss: 35.687, Val PTSD loss: 426.596 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  431\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 268.614, Train PHQ loss: 10.130, Train PTSD loss: 258.484 Train PTSD acc: 0.710\n","Val total loss: 461.888, Val PHQ loss: 35.668, Val PTSD loss: 426.220 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  432\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 268.382, Train PHQ loss: 10.121, Train PTSD loss: 258.261 Train PTSD acc: 0.710\n","Val total loss: 461.567, Val PHQ loss: 35.647, Val PTSD loss: 425.920 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  433\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 268.145, Train PHQ loss: 10.113, Train PTSD loss: 258.031 Train PTSD acc: 0.710\n","Val total loss: 461.163, Val PHQ loss: 35.628, Val PTSD loss: 425.535 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  434\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 267.941, Train PHQ loss: 10.109, Train PTSD loss: 257.832 Train PTSD acc: 0.710\n","Val total loss: 460.812, Val PHQ loss: 35.606, Val PTSD loss: 425.206 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  435\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 267.626, Train PHQ loss: 10.097, Train PTSD loss: 257.529 Train PTSD acc: 0.710\n","Val total loss: 460.688, Val PHQ loss: 35.605, Val PTSD loss: 425.082 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  436\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 267.353, Train PHQ loss: 10.088, Train PTSD loss: 257.265 Train PTSD acc: 0.710\n","Val total loss: 460.396, Val PHQ loss: 35.589, Val PTSD loss: 424.806 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  437\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 267.086, Train PHQ loss: 10.081, Train PTSD loss: 257.005 Train PTSD acc: 0.710\n","Val total loss: 460.673, Val PHQ loss: 35.617, Val PTSD loss: 425.056 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  438\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 266.941, Train PHQ loss: 10.076, Train PTSD loss: 256.865 Train PTSD acc: 0.710\n","Val total loss: 460.293, Val PHQ loss: 35.598, Val PTSD loss: 424.695 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  439\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 266.707, Train PHQ loss: 10.071, Train PTSD loss: 256.636 Train PTSD acc: 0.710\n","Val total loss: 459.943, Val PHQ loss: 35.579, Val PTSD loss: 424.364 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  440\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 266.541, Train PHQ loss: 10.067, Train PTSD loss: 256.474 Train PTSD acc: 0.710\n","Val total loss: 460.229, Val PHQ loss: 35.596, Val PTSD loss: 424.633 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  441\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 266.267, Train PHQ loss: 10.061, Train PTSD loss: 256.206 Train PTSD acc: 0.710\n","Val total loss: 460.250, Val PHQ loss: 35.606, Val PTSD loss: 424.644 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  442\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 266.010, Train PHQ loss: 10.053, Train PTSD loss: 255.956 Train PTSD acc: 0.710\n","Val total loss: 459.888, Val PHQ loss: 35.587, Val PTSD loss: 424.302 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  443\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 265.738, Train PHQ loss: 10.049, Train PTSD loss: 255.689 Train PTSD acc: 0.710\n","Val total loss: 459.667, Val PHQ loss: 35.583, Val PTSD loss: 424.084 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  444\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 265.568, Train PHQ loss: 10.044, Train PTSD loss: 255.524 Train PTSD acc: 0.710\n","Val total loss: 459.434, Val PHQ loss: 35.562, Val PTSD loss: 423.872 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  445\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 265.302, Train PHQ loss: 10.033, Train PTSD loss: 255.269 Train PTSD acc: 0.710\n","Val total loss: 459.143, Val PHQ loss: 35.544, Val PTSD loss: 423.599 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  446\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 265.100, Train PHQ loss: 10.028, Train PTSD loss: 255.072 Train PTSD acc: 0.710\n","Val total loss: 458.873, Val PHQ loss: 35.520, Val PTSD loss: 423.354 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  447\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 264.864, Train PHQ loss: 10.020, Train PTSD loss: 254.843 Train PTSD acc: 0.710\n","Val total loss: 458.722, Val PHQ loss: 35.512, Val PTSD loss: 423.210 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  448\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 264.605, Train PHQ loss: 10.012, Train PTSD loss: 254.593 Train PTSD acc: 0.710\n","Val total loss: 458.425, Val PHQ loss: 35.486, Val PTSD loss: 422.939 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  449\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 264.394, Train PHQ loss: 10.006, Train PTSD loss: 254.389 Train PTSD acc: 0.710\n","Val total loss: 458.156, Val PHQ loss: 35.464, Val PTSD loss: 422.692 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  450\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 264.120, Train PHQ loss: 9.996, Train PTSD loss: 254.123 Train PTSD acc: 0.710\n","Val total loss: 457.843, Val PHQ loss: 35.442, Val PTSD loss: 422.401 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  451\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 263.860, Train PHQ loss: 9.989, Train PTSD loss: 253.871 Train PTSD acc: 0.710\n","Val total loss: 457.775, Val PHQ loss: 35.432, Val PTSD loss: 422.343 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  452\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 263.602, Train PHQ loss: 9.983, Train PTSD loss: 253.620 Train PTSD acc: 0.710\n","Val total loss: 457.421, Val PHQ loss: 35.416, Val PTSD loss: 422.004 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  453\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 263.381, Train PHQ loss: 9.977, Train PTSD loss: 253.404 Train PTSD acc: 0.710\n","Val total loss: 457.071, Val PHQ loss: 35.394, Val PTSD loss: 421.677 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  454\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 263.151, Train PHQ loss: 9.969, Train PTSD loss: 253.182 Train PTSD acc: 0.710\n","Val total loss: 456.939, Val PHQ loss: 35.384, Val PTSD loss: 421.556 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  455\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 262.917, Train PHQ loss: 9.958, Train PTSD loss: 252.958 Train PTSD acc: 0.710\n","Val total loss: 457.213, Val PHQ loss: 35.431, Val PTSD loss: 421.782 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  456\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 262.638, Train PHQ loss: 9.951, Train PTSD loss: 252.687 Train PTSD acc: 0.710\n","Val total loss: 456.895, Val PHQ loss: 35.414, Val PTSD loss: 421.481 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  457\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 262.390, Train PHQ loss: 9.943, Train PTSD loss: 252.447 Train PTSD acc: 0.710\n","Val total loss: 456.906, Val PHQ loss: 35.437, Val PTSD loss: 421.469 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  458\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 262.196, Train PHQ loss: 9.941, Train PTSD loss: 252.255 Train PTSD acc: 0.710\n","Val total loss: 456.700, Val PHQ loss: 35.420, Val PTSD loss: 421.279 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  459\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 261.935, Train PHQ loss: 9.930, Train PTSD loss: 252.004 Train PTSD acc: 0.710\n","Val total loss: 456.712, Val PHQ loss: 35.434, Val PTSD loss: 421.278 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  460\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 261.678, Train PHQ loss: 9.922, Train PTSD loss: 251.756 Train PTSD acc: 0.710\n","Val total loss: 456.641, Val PHQ loss: 35.431, Val PTSD loss: 421.210 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  461\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 261.498, Train PHQ loss: 9.921, Train PTSD loss: 251.577 Train PTSD acc: 0.710\n","Val total loss: 456.404, Val PHQ loss: 35.412, Val PTSD loss: 420.991 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  462\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 261.337, Train PHQ loss: 9.919, Train PTSD loss: 251.418 Train PTSD acc: 0.710\n","Val total loss: 456.321, Val PHQ loss: 35.401, Val PTSD loss: 420.921 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  463\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 261.180, Train PHQ loss: 9.915, Train PTSD loss: 251.265 Train PTSD acc: 0.710\n","Val total loss: 456.310, Val PHQ loss: 35.409, Val PTSD loss: 420.901 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  464\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 260.915, Train PHQ loss: 9.906, Train PTSD loss: 251.009 Train PTSD acc: 0.710\n","Val total loss: 456.209, Val PHQ loss: 35.397, Val PTSD loss: 420.811 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  465\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 260.712, Train PHQ loss: 9.898, Train PTSD loss: 250.814 Train PTSD acc: 0.710\n","Val total loss: 456.195, Val PHQ loss: 35.417, Val PTSD loss: 420.779 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  466\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 260.520, Train PHQ loss: 9.897, Train PTSD loss: 250.622 Train PTSD acc: 0.710\n","Val total loss: 456.128, Val PHQ loss: 35.435, Val PTSD loss: 420.693 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  467\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 260.325, Train PHQ loss: 9.897, Train PTSD loss: 250.428 Train PTSD acc: 0.710\n","Val total loss: 455.778, Val PHQ loss: 35.414, Val PTSD loss: 420.363 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  468\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 260.098, Train PHQ loss: 9.891, Train PTSD loss: 250.207 Train PTSD acc: 0.710\n","Val total loss: 455.443, Val PHQ loss: 35.394, Val PTSD loss: 420.048 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  469\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 259.887, Train PHQ loss: 9.886, Train PTSD loss: 250.000 Train PTSD acc: 0.710\n","Val total loss: 455.302, Val PHQ loss: 35.393, Val PTSD loss: 419.909 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  470\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 259.787, Train PHQ loss: 9.884, Train PTSD loss: 249.903 Train PTSD acc: 0.710\n","Val total loss: 455.142, Val PHQ loss: 35.395, Val PTSD loss: 419.747 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  471\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 259.512, Train PHQ loss: 9.873, Train PTSD loss: 249.639 Train PTSD acc: 0.710\n","Val total loss: 454.975, Val PHQ loss: 35.387, Val PTSD loss: 419.588 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  472\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 259.254, Train PHQ loss: 9.866, Train PTSD loss: 249.389 Train PTSD acc: 0.710\n","Val total loss: 454.808, Val PHQ loss: 35.384, Val PTSD loss: 419.425 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  473\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 259.066, Train PHQ loss: 9.856, Train PTSD loss: 249.209 Train PTSD acc: 0.710\n","Val total loss: 454.751, Val PHQ loss: 35.381, Val PTSD loss: 419.370 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  474\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 258.893, Train PHQ loss: 9.850, Train PTSD loss: 249.043 Train PTSD acc: 0.710\n","Val total loss: 454.405, Val PHQ loss: 35.357, Val PTSD loss: 419.048 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  475\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 258.699, Train PHQ loss: 9.849, Train PTSD loss: 248.851 Train PTSD acc: 0.710\n","Val total loss: 454.154, Val PHQ loss: 35.338, Val PTSD loss: 418.816 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  476\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 258.541, Train PHQ loss: 9.847, Train PTSD loss: 248.694 Train PTSD acc: 0.710\n","Val total loss: 454.076, Val PHQ loss: 35.333, Val PTSD loss: 418.743 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  477\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 258.329, Train PHQ loss: 9.838, Train PTSD loss: 248.492 Train PTSD acc: 0.710\n","Val total loss: 453.852, Val PHQ loss: 35.338, Val PTSD loss: 418.514 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  478\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 258.164, Train PHQ loss: 9.835, Train PTSD loss: 248.328 Train PTSD acc: 0.710\n","Val total loss: 453.945, Val PHQ loss: 35.351, Val PTSD loss: 418.594 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  479\n","Adjusting learning rate of group 0 to 1.0000e-10.\n","Train total loss: 257.980, Train PHQ loss: 9.830, Train PTSD loss: 248.149 Train PTSD acc: 0.710\n","Val total loss: 453.632, Val PHQ loss: 35.329, Val PTSD loss: 418.303 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  480\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 257.732, Train PHQ loss: 9.823, Train PTSD loss: 247.909 Train PTSD acc: 0.710\n","Val total loss: 453.578, Val PHQ loss: 35.347, Val PTSD loss: 418.231 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  481\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 257.512, Train PHQ loss: 9.819, Train PTSD loss: 247.693 Train PTSD acc: 0.710\n","Val total loss: 453.385, Val PHQ loss: 35.331, Val PTSD loss: 418.054 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  482\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 257.300, Train PHQ loss: 9.816, Train PTSD loss: 247.484 Train PTSD acc: 0.710\n","Val total loss: 453.431, Val PHQ loss: 35.341, Val PTSD loss: 418.090 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  483\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 257.100, Train PHQ loss: 9.812, Train PTSD loss: 247.288 Train PTSD acc: 0.710\n","Val total loss: 453.321, Val PHQ loss: 35.347, Val PTSD loss: 417.974 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  484\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 256.878, Train PHQ loss: 9.810, Train PTSD loss: 247.069 Train PTSD acc: 0.710\n","Val total loss: 453.377, Val PHQ loss: 35.362, Val PTSD loss: 418.015 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  485\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 256.652, Train PHQ loss: 9.804, Train PTSD loss: 246.848 Train PTSD acc: 0.710\n","Val total loss: 453.055, Val PHQ loss: 35.347, Val PTSD loss: 417.708 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  486\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 256.453, Train PHQ loss: 9.801, Train PTSD loss: 246.652 Train PTSD acc: 0.710\n","Val total loss: 452.712, Val PHQ loss: 35.333, Val PTSD loss: 417.379 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  487\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 256.258, Train PHQ loss: 9.798, Train PTSD loss: 246.460 Train PTSD acc: 0.710\n","Val total loss: 452.529, Val PHQ loss: 35.333, Val PTSD loss: 417.196 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  488\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 256.135, Train PHQ loss: 9.797, Train PTSD loss: 246.338 Train PTSD acc: 0.710\n","Val total loss: 452.252, Val PHQ loss: 35.316, Val PTSD loss: 416.936 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  489\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 255.897, Train PHQ loss: 9.788, Train PTSD loss: 246.109 Train PTSD acc: 0.710\n","Val total loss: 452.190, Val PHQ loss: 35.331, Val PTSD loss: 416.858 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  490\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 255.681, Train PHQ loss: 9.780, Train PTSD loss: 245.901 Train PTSD acc: 0.710\n","Val total loss: 451.927, Val PHQ loss: 35.311, Val PTSD loss: 416.617 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  491\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 255.470, Train PHQ loss: 9.775, Train PTSD loss: 245.695 Train PTSD acc: 0.710\n","Val total loss: 451.636, Val PHQ loss: 35.295, Val PTSD loss: 416.340 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  492\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 255.302, Train PHQ loss: 9.775, Train PTSD loss: 245.527 Train PTSD acc: 0.710\n","Val total loss: 451.458, Val PHQ loss: 35.277, Val PTSD loss: 416.181 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  493\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 255.099, Train PHQ loss: 9.767, Train PTSD loss: 245.332 Train PTSD acc: 0.710\n","Val total loss: 451.199, Val PHQ loss: 35.259, Val PTSD loss: 415.940 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  494\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 254.899, Train PHQ loss: 9.761, Train PTSD loss: 245.138 Train PTSD acc: 0.710\n","Val total loss: 450.940, Val PHQ loss: 35.244, Val PTSD loss: 415.696 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  495\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 254.686, Train PHQ loss: 9.752, Train PTSD loss: 244.934 Train PTSD acc: 0.710\n","Val total loss: 450.659, Val PHQ loss: 35.229, Val PTSD loss: 415.429 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  496\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 254.494, Train PHQ loss: 9.752, Train PTSD loss: 244.742 Train PTSD acc: 0.710\n","Val total loss: 450.332, Val PHQ loss: 35.210, Val PTSD loss: 415.122 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  497\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 254.269, Train PHQ loss: 9.744, Train PTSD loss: 244.525 Train PTSD acc: 0.710\n","Val total loss: 450.132, Val PHQ loss: 35.208, Val PTSD loss: 414.924 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  498\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 254.047, Train PHQ loss: 9.736, Train PTSD loss: 244.311 Train PTSD acc: 0.710\n","Val total loss: 449.810, Val PHQ loss: 35.198, Val PTSD loss: 414.613 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  499\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 253.813, Train PHQ loss: 9.728, Train PTSD loss: 244.086 Train PTSD acc: 0.710\n","Val total loss: 449.484, Val PHQ loss: 35.181, Val PTSD loss: 414.303 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  500\n","Adjusting learning rate of group 0 to 1.0000e-11.\n","Train total loss: 253.710, Train PHQ loss: 9.726, Train PTSD loss: 243.984 Train PTSD acc: 0.710\n","Val total loss: 449.284, Val PHQ loss: 35.166, Val PTSD loss: 414.119 Val PTSD acc: 0.830\n","--------------------------------------------------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HK3JjRJpsL9u"},"source":["torch.save(model,'/content/drive/MyDrive/Depression-Detection/multitask_model.pth')\n","f = open('/content/drive/MyDrive/Depression-Detection/model_settings.txt','w+')\n","f.write('learning_rate :'+str(lr))\n","f.write('hidden dim : '+str(hidden_dim))\n","f.write('Model :\\n'+str(model))\n","f.write('train loss dict : '+str(losses))\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"pz-NopUm2XDn","executionInfo":{"status":"ok","timestamp":1619052810934,"user_tz":420,"elapsed":372,"user":{"displayName":"Shubham Nagarkar","photoUrl":"","userId":"10621817079012605482"}},"outputId":"427f1366-2442-4e62-f666-207a6e6d2c2a"},"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","def draw_training_curves(train_losses, test_losses, curve_name, epoch):\n","    plt.clf()\n","    \n","    plt.xlim([0,epoch])\n","    plt.plot(train_losses, label='Training {}'.format(curve_name))\n","    plt.plot(test_losses, label='Testing {}'.format(curve_name))\n","    plt.ylabel(curve_name)\n","    plt.xlabel('Epoch')\n","    \n","    plt.title(\"Depression loss curve\")\n","    plt.legend(frameon=False)\n","    plt.show()\n","\n","draw_training_curves(losses['train']['total'],losses['val']['total'], 'total_loss', 500 )"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"PyatEJMwBhGD","executionInfo":{"status":"ok","timestamp":1619052836684,"user_tz":420,"elapsed":490,"user":{"displayName":"Shubham Nagarkar","photoUrl":"","userId":"10621817079012605482"}},"outputId":"349e9a4a-bef6-4a92-cd97-bb8d083bc0bf"},"source":["draw_training_curves(losses['train']['ptsd'],losses['val']['ptsd'], 'PTSD', 500 )"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164},"id":"Ocx_H2TmBpy5","executionInfo":{"status":"error","timestamp":1619052863948,"user_tz":420,"elapsed":364,"user":{"displayName":"Shubham Nagarkar","photoUrl":"","userId":"10621817079012605482"}},"outputId":"565b3d9e-61ef-4c5c-c210-1b048f560ab7"},"source":["draw_training_curves(losses['train']['phq'],losses['val']['phq'], 'PHQ', 500 )"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-f04e13eac599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdraw_training_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'phq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'phq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PHQ'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'draw_training_curves' is not defined"]}]},{"cell_type":"code","metadata":{"id":"J2p1KDU2Jx7H"},"source":["class LSTM_Single_Task(torch.nn.Module) :\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, glove_weights) :\n","        super().__init__()\n","\n","        self.dropout = nn.Dropout(0.3)\n","        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        self.embeddings.weight.data.copy_(torch.from_numpy(glove_weights))\n","        self.embeddings.weight.requires_grad = True\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n","\n","\n","        self.MLP = nn.Sequential(\n","            nn.Linear(hidden_dim,64),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU(),\n","            nn.Linear(64, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, sentence, sentence_length):\n","        sentence_embed = self.embeddings(sentence)\n","        sentence_embed = self.dropout(sentence_embed)\n","\n","        sentence_pack = pack_padded_sequence(sentence_embed, sentence_length, batch_first=True, enforce_sorted=False)\n","        out_pack, (ht, ct) = self.lstm(sentence_pack)\n","        task_op = self.MLP(ht[-1])\n","  \n","        return torch.squeeze(task_op, 1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ROl81ENeKMxz"},"source":["def train_single_task(task, model, optimizer, criterion, train_loader, val_loader, epochs):\n","\n","  epoch_train_loss = []\n","  epoch_val_loss = []\n","  losses = {'train':[], 'val':[]}\n","\n","  print(\"Training started...\\n\")\n","\n","  model.to(DEVICE)\n","  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=60, gamma=0.1, last_epoch=-1, verbose=True)\n","  early_stop = EarlyStopping(patience=12)\n","  \n","\n","  for epoch in range(epochs):\n","\n","    total = 0\n","    correct =  0\n","    print(\"Epoch : \", epoch+1)\n","    model.train()\n","    for sentence, length, phq_score, ptsd_score in train_loader:\n","      sentence = sentence.to(DEVICE).long()\n","      phq_score = phq_score.to(DEVICE).type(torch.float32)\n","      ptsd_score = ptsd_score.to(DEVICE).type(torch.float32)\n","      if task == 'PHQ':\n","        label = phq_score\n","      else:\n","        label = ptsd_score\n","\n","      optimizer.zero_grad()\n","\n","      task_op = model(sentence, length)\n","\n","      loss = criterion(task_op, label)\n","      loss.backward()\n","     \n","      predicted = torch.round(task_op)\n","   \n","      total += label.size(0)\n","      correct += (predicted==label).sum().item()\n","      epoch_train_loss.append(loss.item())\n","      optimizer.step()\n","      \n","    train_loss = np.average(epoch_train_loss)\n","    train_accuracy = correct/total\n","\n","    model.eval()\n","    total = 0\n","    correct =  0\n","    with torch.no_grad():\n","      for sentence, length, phq_score, ptsd_score in val_loader:\n","        sentence = sentence.to(DEVICE).long()\n","        phq_score = phq_score.to(DEVICE).type(torch.float32)\n","        ptsd_score = ptsd_score.to(DEVICE).type(torch.float32)\n","        if task == 'PHQ':\n","          label = phq_score\n","        else: \n","          label = ptsd_score\n","        \n","        task_op = model(sentence, length)\n","\n","        loss = criterion(task_op, label)\n","        predicted = torch.round(task_op)\n","  \n","        total += label.size(0)\n","        correct += (predicted==label).sum().item()\n","        epoch_val_loss.append(loss.item())\n","\n","    val_loss = np.average(epoch_val_loss)\n","    val_accuracy = correct/total\n","    scheduler.step()\n","    early_stop(val_loss, model)\n","    \n","\n","    print(\"Train loss: {0:.3f} Val loss: {1:.3f}\".format(train_loss, val_loss))\n","    print(\"Train acc: {0:.3f} Val acc: {1:.3f}\".format(train_accuracy, val_accuracy))\n","    print('--------------------------------------------------------------------------------------------------------------------')\n","\n","    if early_stop.early_stop:\n","          print(\"Early stopping\")\n","          used_early_stopping  = True\n","          break\n","\n","    losses['train'].append(train_loss) \n","    losses['val'].append(val_loss) \n","\n","  return model, losses"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ECbzu6k0MR-j","executionInfo":{"status":"ok","timestamp":1619050145071,"user_tz":420,"elapsed":41980,"user":{"displayName":"Shubham Nagarkar","photoUrl":"","userId":"10621817079012605482"}},"outputId":"fdb0c7dd-c808-4e44-c9b9-909825259030"},"source":["vocab_size = 8353\n","embedding_dim = 300\n","hidden_dim = 256\n","lr = 5e-5\n","epochs = 500\n","batch_size = 16\n","\n","model_task = LSTM_Single_Task(vocab_size, embedding_dim, hidden_dim, embed_matrix)\n","optimizer = torch.optim.Adam(model_task.parameters(), lr=lr)\n","criterion = torch.nn.BCELoss().to(DEVICE) \n","\n","train_loader = torch.utils.data.DataLoader(DepressionDataset(train_encoded, train_PHQ, train_PTSD), batch_size=batch_size, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(DepressionDataset(val_encoded, val_PHQ, val_PTSD), batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(DepressionDataset(test_encoded, test_PHQ, test_PTSD), batch_size=batch_size, shuffle=True)\n","\n","model_task, losses = train_single_task('PTSD', model_task, optimizer, criterion, train_loader, val_loader, epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training started...\n","\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Epoch :  1\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.736 Val loss: 0.713\n","Train acc: 0.477 Val acc: 0.286\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  2\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.730 Val loss: 0.712\n","Train acc: 0.467 Val acc: 0.314\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  3\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.725 Val loss: 0.713\n","Train acc: 0.439 Val acc: 0.314\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  4\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.720 Val loss: 0.714\n","Train acc: 0.486 Val acc: 0.343\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  5\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.712 Val loss: 0.713\n","Train acc: 0.589 Val acc: 0.543\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  6\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.707 Val loss: 0.711\n","Train acc: 0.551 Val acc: 0.571\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  7\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.702 Val loss: 0.709\n","Train acc: 0.626 Val acc: 0.571\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  8\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.697 Val loss: 0.707\n","Train acc: 0.579 Val acc: 0.514\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  9\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.690 Val loss: 0.705\n","Train acc: 0.682 Val acc: 0.543\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  10\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.684 Val loss: 0.704\n","Train acc: 0.654 Val acc: 0.514\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  11\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.681 Val loss: 0.703\n","Train acc: 0.626 Val acc: 0.514\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  12\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.675 Val loss: 0.701\n","Train acc: 0.729 Val acc: 0.543\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  13\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.671 Val loss: 0.697\n","Train acc: 0.654 Val acc: 0.657\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  14\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.667 Val loss: 0.694\n","Train acc: 0.682 Val acc: 0.629\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  15\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.666 Val loss: 0.691\n","Train acc: 0.607 Val acc: 0.600\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  16\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.662 Val loss: 0.690\n","Train acc: 0.738 Val acc: 0.629\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  17\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.658 Val loss: 0.687\n","Train acc: 0.729 Val acc: 0.686\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  18\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.654 Val loss: 0.685\n","Train acc: 0.813 Val acc: 0.657\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  19\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.650 Val loss: 0.684\n","Train acc: 0.738 Val acc: 0.657\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  20\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.645 Val loss: 0.682\n","Train acc: 0.860 Val acc: 0.629\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  21\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.641 Val loss: 0.679\n","Train acc: 0.748 Val acc: 0.686\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  22\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.637 Val loss: 0.676\n","Train acc: 0.794 Val acc: 0.714\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  23\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.633 Val loss: 0.675\n","Train acc: 0.794 Val acc: 0.686\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  24\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.630 Val loss: 0.672\n","Train acc: 0.766 Val acc: 0.714\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  25\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.625 Val loss: 0.670\n","Train acc: 0.841 Val acc: 0.657\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  26\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.622 Val loss: 0.670\n","Train acc: 0.757 Val acc: 0.657\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  27\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.618 Val loss: 0.671\n","Train acc: 0.832 Val acc: 0.657\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  28\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.613 Val loss: 0.669\n","Train acc: 0.841 Val acc: 0.657\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  29\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.609 Val loss: 0.668\n","Train acc: 0.860 Val acc: 0.686\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  30\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.605 Val loss: 0.667\n","Train acc: 0.841 Val acc: 0.686\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  31\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.600 Val loss: 0.666\n","Train acc: 0.822 Val acc: 0.657\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  32\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.597 Val loss: 0.666\n","Train acc: 0.850 Val acc: 0.686\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  33\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.593 Val loss: 0.666\n","Train acc: 0.850 Val acc: 0.657\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  34\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.590 Val loss: 0.667\n","Train acc: 0.813 Val acc: 0.657\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  35\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.585 Val loss: 0.668\n","Train acc: 0.897 Val acc: 0.657\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  36\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.581 Val loss: 0.668\n","Train acc: 0.879 Val acc: 0.657\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  37\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.577 Val loss: 0.668\n","Train acc: 0.925 Val acc: 0.686\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  38\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.573 Val loss: 0.667\n","Train acc: 0.869 Val acc: 0.686\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  39\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.570 Val loss: 0.668\n","Train acc: 0.822 Val acc: 0.686\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  40\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.566 Val loss: 0.667\n","Train acc: 0.897 Val acc: 0.686\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  41\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.562 Val loss: 0.668\n","Train acc: 0.916 Val acc: 0.657\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  42\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.558 Val loss: 0.670\n","Train acc: 0.907 Val acc: 0.657\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  43\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.554 Val loss: 0.671\n","Train acc: 0.897 Val acc: 0.657\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  44\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.550 Val loss: 0.672\n","Train acc: 0.925 Val acc: 0.629\n","--------------------------------------------------------------------------------------------------------------------\n","Epoch :  45\n","Adjusting learning rate of group 0 to 5.0000e-05.\n","Train loss: 0.546 Val loss: 0.674\n","Train acc: 0.953 Val acc: 0.600\n","--------------------------------------------------------------------------------------------------------------------\n","Early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"V9DzgizeMnu7","executionInfo":{"status":"ok","timestamp":1619050183341,"user_tz":420,"elapsed":506,"user":{"displayName":"Shubham Nagarkar","photoUrl":"","userId":"10621817079012605482"}},"outputId":"96939313-83d4-45db-b2f1-dd2614a8425c"},"source":["draw_training_curves(losses['train'],losses['val'], 'PTSD_loss', 45 )\n","#PHQ 256 works best for hidden layer"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bg-MNQ39VSjt","executionInfo":{"status":"ok","timestamp":1619045030004,"user_tz":420,"elapsed":684,"user":{"displayName":"Shubham Nagarkar","photoUrl":"","userId":"10621817079012605482"}},"outputId":"2161b1ee-1838-453c-fb6d-539a6ff88802"},"source":["def evaluate_single_task(task, model, test_loader):\n","  output = []\n","  actual = []\n","  model.eval()\n","  with torch.no_grad():\n","    for sentence, length, phq_score, ptsd_score in test_loader:\n","      sentence = sentence.to(DEVICE).long()\n","      phq_score = phq_score.to(DEVICE).type(torch.float32)\n","      ptsd_score = ptsd_score.to(DEVICE).type(torch.float32)\n","      if task == 'PHQ':\n","        label = phq_score\n","      else: \n","        label = ptsd_score\n","      \n","      phqop,ptsdop = model(sentence, length)\n","\n","      output.extend(phqop.cpu().tolist())\n","      actual.extend(phq_score.cpu().tolist())\n","\n","  return actual, output\n","\n","test_loader = torch.utils.data.DataLoader(DepressionDataset(test_encoded, test_PHQ, test_PTSD), batch_size=batch_size, shuffle=False)\n","actual, preds = evaluate_single_task(\"PHQ\", model, test_loader)\n","\n","final_actual = []\n","final_pred = []\n","\n","for val in actual:\n","  if val < 5:\n","    final_actual.append(\"None\")\n","  elif val > 4 and val<15:\n","    final_actual.append(\"Mild to moderate\")\n","  else:\n","    final_actual.append(\"Severe\")\n","\n","for val in preds:\n","  if val < 5:\n","    final_pred.append(\"None\")\n","  elif val > 4 and val<15:\n","    final_pred.append(\"Mild to moderate\")\n","  else:\n","    final_pred.append(\"Severe\")\n","\n","correct = 0\n","total = 0\n","for x,y in zip(final_actual, final_pred):\n","  if x == y:\n","    correct+=1\n","  total+=1\n","\n","print(\"Accuracy: \", correct/total)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy:  0.425531914893617\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IlxWIsyfjwW_"},"source":["\"\"\"\n","References:\n","1. https://docs.google.com/document/d/1_PycTNBTQjboYtyZslkte0WlcdyMlyFTMYZlSHLq0EE/edit#\n","\"\"\""],"execution_count":null,"outputs":[]}]}