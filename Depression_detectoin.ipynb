{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 454490,
     "status": "ok",
     "timestamp": 1619065661923,
     "user": {
      "displayName": "Shubham Nagarkar",
      "photoUrl": "",
      "userId": "10621817079012605482"
     },
     "user_tz": 420
    },
    "id": "Lwd4yowDWvOa",
    "outputId": "c6a7930d-3b66-4478-c985-e40e860d3266"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torchsummary import summary\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cbNRjmMHWWqm"
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'new-train-split.csv'\n",
    "TEST_PATH = 'new-test-split.csv'\n",
    "VAL_PATH = 'new-dev-split.csv'\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "NEW_DATA = 'Extra-data.csv'\n",
    "EMBEDDING_FILE = 'glove.42B.300d.txt'\n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "MAX_LEN = 2204\n",
    "PHQ_MAX_VAL = 23\n",
    "PTSD_MAX_VAL = 85\n",
    "CHECKPOINT = 'temp_models/'\n",
    "GRAPHS = 'temp_plots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6XUO1RBNW86u"
   },
   "outputs": [],
   "source": [
    "def get_data(dataset):\n",
    "    \"\"\"\n",
    "    Returns features along with normalized PHQ and PTSD values\n",
    "    :params: dataset - Train/Test/Validation\n",
    "    \"\"\"\n",
    "    features = dataset.Text\n",
    "    PHQ = dataset.PHQ8_Score\n",
    "    PHQ = PHQ/PHQ_MAX_VAL\n",
    "    PTSD = dataset.PTSD\n",
    "    PTSD = PTSD/PTSD_MAX_VAL\n",
    "  \n",
    "    return features, PHQ, PTSD\n",
    "\n",
    "def get_new_data(dataset):\n",
    "    \"\"\"\n",
    "    Returns features along with normalized PHQ values\n",
    "    :params: dataset - Train/Test\n",
    "    \"\"\"\n",
    "    features = dataset.Text\n",
    "    PHQ = dataset.PHQ8_Score\n",
    "    PHQ = PHQ/PHQ_MAX_VAL\n",
    "  \n",
    "    return features, PHQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Mw3yb6ursQuw"
   },
   "outputs": [],
   "source": [
    "def get_embeddings():\n",
    "    \"\"\"\n",
    "    Returns a dictionary containing words as keys and glove word vectors as values\n",
    "    \"\"\"\n",
    "    embeddings_index = {}\n",
    "    with open(EMBEDDING_FILE, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.rstrip().rsplit(' ')\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "f1yXDCPVvP3L"
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    \"\"\"\n",
    "    Splits text into list of words\n",
    "    :params: text - input paragraph\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    for txt in text:\n",
    "        tokens.append(txt.split())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8JONtkgk3zJQ"
   },
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index):\n",
    "    \"\"\"\n",
    "    Converts sentences into numerical representation\n",
    "    :params: text - input paragraph\n",
    "             vocab2index - dictionary with words as keys and index number as value\n",
    "    \"\"\"\n",
    "    tokenized = tokenize_text([text])\n",
    "    encoded = np.zeros(MAX_LEN, dtype=np.float32)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized[0]])\n",
    "    length = min(MAX_LEN, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return  encoded, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BkT7Eh57LI0R"
   },
   "outputs": [],
   "source": [
    "def get_emb_matrix(glove_embed, word_counts, emb_size = 300):\n",
    "    \"\"\"\n",
    "    returns weight matrix for embeddings along with vocabulary and vocab-to-index dictionary\n",
    "    :params: glove_embed - glove dictionary\n",
    "             word_counts - unique words in dataset\n",
    "             emb_size - size of the word embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    vocab_size = len(word_counts) + 2 \n",
    "    vocab_to_idx = {}\n",
    "    vocab = [\"\", \"UNK\"]\n",
    "    W = np.zeros((vocab_size, emb_size), dtype=\"float32\")\n",
    "    W[0] = np.zeros(emb_size, dtype='float32') # adding a vector for padding\n",
    "    W[1] = np.random.uniform(-0.25, 0.25, emb_size) # adding a vector for unknown words \n",
    "    vocab_to_idx[\"UNK\"] = 1\n",
    "    i = 2\n",
    "    for word in word_counts:\n",
    "        if word in glove_embed:\n",
    "            W[i] = glove_embed[word]\n",
    "        else:\n",
    "            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
    "        vocab_to_idx[word] = i\n",
    "        vocab.append(word)\n",
    "        i += 1   \n",
    "    return W, np.array(vocab), vocab_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gbEzH-CqF_xu"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stops the training if validation loss doesn't improve after a given patience.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, patience=8, verbose=False, delta=0, path= 'early_stopping_model.pth'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 10\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'early_stopping_vgg16model.pth'   \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "    \n",
    "    def __call__(self, val_loss, model):\n",
    "        \n",
    "        score = -val_loss\n",
    "        \n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            \n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            \n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                \n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0   \n",
    "    \n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        \"\"\"\n",
    "        saves the current best version of the model if there is decrease in validation loss\n",
    "        \"\"\"\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.vall_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "bGjKYduu-tpV"
   },
   "outputs": [],
   "source": [
    "class DepressionDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch implementation of Dataset class to return encoding and their labels\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings, PHQ, PTSD):\n",
    "        self.encodings = encodings\n",
    "        self.PHQ = PHQ\n",
    "        self.PTSD = PTSD\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = torch.tensor(self.encodings[idx][0])\n",
    "        phq_score = torch.tensor(self.PHQ[idx])\n",
    "        ptsd_score = torch.tensor(self.PTSD[idx])\n",
    "        length = self.encodings[idx][1]\n",
    "        \n",
    "        return encoding, length, phq_score, ptsd_score\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.PHQ)\n",
    "\n",
    "class NewDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch implementation of Dataset class to return encoding and their labels\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings, PHQ):\n",
    "        self.encodings = encodings\n",
    "        self.PHQ = PHQ\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = torch.tensor(self.encodings[idx][0])\n",
    "        phq_score = torch.tensor(self.PHQ[idx])\n",
    "        length = self.encodings[idx][1]\n",
    "        \n",
    "        return encoding, length, phq_score\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.PHQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "3JGwvuDWQPAv"
   },
   "outputs": [],
   "source": [
    "class LSTM_Multi_Task(torch.nn.Module) :\n",
    "    \"\"\"\n",
    "    LSTM Multi-task model architecture\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, glove_weights) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(glove_weights))\n",
    "        self.embeddings.weight.requires_grad = False\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=3, dropout=0.3, bidirectional=True)\n",
    "\n",
    "        \n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(hidden_dim,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.ptsd_head = nn.Sequential(\n",
    "            nn.Linear(128,84),\n",
    "            nn.BatchNorm1d(84),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(84, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.phq_head = nn.Sequential(\n",
    "            nn.Linear(128,32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, sentence, sentence_length):\n",
    "        sentence_embed = self.embeddings(sentence)\n",
    "        sentence_embed = self.dropout(sentence_embed)\n",
    "\n",
    "        sentence_pack = pack_padded_sequence(sentence_embed, sentence_length, batch_first=True, enforce_sorted=False)\n",
    "        out_pack, (ht, ct) = self.lstm(sentence_pack)\n",
    "        features = self.MLP(ht[-1])\n",
    "        ptsd = self.ptsd_head(features)\n",
    "        phq = self.phq_head(features)\n",
    "\n",
    "        return torch.squeeze(phq, 1), torch.squeeze(ptsd, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "iRi_SHtNS4P7"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion_phq, criterion_ptsd, train_loader, val_loader, epochs):\n",
    "    \"\"\"\n",
    "    returns trained model along with lossess and accuracies per epoch for multitask architecture\n",
    "    :params: model - LSTM model\n",
    "             optimizer - Adam optimizer\n",
    "             criterion_phq, criterion_ptsd - MSE Loss functions\n",
    "             train, val loaders - input data and labels\n",
    "             epochs - number of epochs to train the model\n",
    "    \"\"\"\n",
    "    epoch_train_phq_loss = []\n",
    "    epoch_train_ptsd_loss = []\n",
    "    epoch_train_total_loss = []\n",
    "    epoch_train_ptsd_acc = []\n",
    "\n",
    "    epoch_val_phq_loss = []\n",
    "    epoch_val_ptsd_loss = []\n",
    "    epoch_val_total_loss = []\n",
    "    epoch_val_ptsd_acc = []\n",
    "\n",
    "    epoch_val_loss = []\n",
    "    losses = {'train':{'total':[], 'phq':[], 'ptsd':[]}, 'val':{'total':[], 'phq':[], 'ptsd':[]}}\n",
    "\n",
    "    print(\"Training started...\\n\")\n",
    "    model.to(DEVICE)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.2, last_epoch=-1, verbose=True)\n",
    "    early_stop = EarlyStopping(patience=8, path= CHECKPOINT+\"multitask_early_stopping_bilstm.pth\")\n",
    "    used_early_stopping = False\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        print(\"Epoch : \", epoch+1)\n",
    "        model.train()\n",
    "        for sentence, length, phq_score, ptsd_score in train_loader:\n",
    "            sentence = sentence.to(DEVICE).long()\n",
    "            phq_score = phq_score.to(DEVICE).type(torch.float32)\n",
    "            ptsd_score = ptsd_score.to(DEVICE).type(torch.float32)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            phq_op, ptsd_op = model(sentence, length)\n",
    "\n",
    "            loss_phq = criterion_phq(phq_op, phq_score)\n",
    "            loss_ptsd = criterion_ptsd(ptsd_op, ptsd_score)\n",
    "            \n",
    "            loss = loss_phq + loss_ptsd\n",
    "            loss.backward()\n",
    "\n",
    "\n",
    "            epoch_train_phq_loss.append(loss_phq.item())\n",
    "            epoch_train_ptsd_loss.append(loss_ptsd.item())\n",
    "            epoch_train_total_loss.append(loss.item())\n",
    "            optimizer.step()\n",
    "      \n",
    "        train_total_loss = np.average(epoch_train_total_loss)\n",
    "        train_phq_loss = np.average(epoch_train_phq_loss)\n",
    "        train_ptsd_loss = np.average(epoch_train_ptsd_loss)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for sentence, length, phq_score, ptsd_score in val_loader:\n",
    "                sentence = sentence.to(DEVICE).long()\n",
    "                phq_score = phq_score.to(DEVICE).type(torch.float32)\n",
    "                ptsd_score = ptsd_score.to(DEVICE).type(torch.float32)\n",
    "\n",
    "                phq_op, ptsd_op = model(sentence,length)\n",
    "\n",
    "                loss_phq = criterion_phq(phq_op, phq_score)\n",
    "                loss_ptsd = criterion_ptsd(ptsd_op, ptsd_score)\n",
    "                loss = loss_phq + loss_ptsd\n",
    "\n",
    "\n",
    "                epoch_val_phq_loss.append(loss_phq.item())\n",
    "                epoch_val_ptsd_loss.append(loss_ptsd.item())\n",
    "                epoch_val_total_loss.append(loss.item())\n",
    "\n",
    "      \n",
    "        val_total_loss = np.average(epoch_val_total_loss)\n",
    "        val_phq_loss = np.average(epoch_val_phq_loss)\n",
    "        val_ptsd_loss = np.average(epoch_val_ptsd_loss)\n",
    "\n",
    "\n",
    "        \n",
    "        early_stop(val_total_loss, model)\n",
    "        scheduler.step()\n",
    "        \n",
    "        if early_stop.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            used_early_stopping  = True\n",
    "            break\n",
    "\n",
    "        print(\"Train total loss: {0:.3f}, Train PHQ loss: {1:.3f}, Train PTSD loss: {2:.3f} \".format(train_total_loss, train_phq_loss, train_ptsd_loss))\n",
    "        print(\"Val total loss: {0:.3f}, Val PHQ loss: {1:.3f}, Val PTSD loss: {2:.3f} \".format(val_total_loss, val_phq_loss, val_ptsd_loss))\n",
    "        print('----------------------------------------------------------------------------------------------')\n",
    "\n",
    "        losses['train']['total'].append(train_total_loss) \n",
    "        losses['train']['phq'].append(train_phq_loss) \n",
    "        losses['train']['ptsd'].append(train_ptsd_loss) \n",
    "\n",
    "        losses['val']['total'].append(val_total_loss) \n",
    "        losses['val']['phq'].append(val_phq_loss) \n",
    "        losses['val']['ptsd'].append(val_ptsd_loss) \n",
    "\n",
    "    return model, losses, used_early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(lab, pred, target_names, title, task, TYPE):\n",
    "    \"\"\"\n",
    "    plots normalized confusion matrix\n",
    "    :params: lab - actual labels\n",
    "             pred - predicted labels\n",
    "             target_names - names of classes\n",
    "             title - title of plot\n",
    "             task - name of the task\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(lab, pred)\n",
    "    print(cm)\n",
    "    # Normalise\n",
    "    cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=target_names, yticklabels=target_names, cmap = \"YlGnBu\")\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title(title)\n",
    "    if TYPE == \"\":\n",
    "        plt.savefig(GRAPHS+\"{}_confusion_matrix.png\".format(task))\n",
    "    else:\n",
    "        plt.savefig(GRAPHS+\"{}_{}_confusion_matrix.png\".format(task,TYPE))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def draw_training_curves(train_losses, test_losses, curve_name, title, epoch):\n",
    "    plt.clf()\n",
    "    \n",
    "    plt.xlim([0,epoch])\n",
    "    plt.plot(train_losses, label='Training {}'.format(curve_name))\n",
    "    plt.plot(test_losses, label='Testing {}'.format(curve_name))\n",
    "    plt.ylabel(curve_name)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.title(title)\n",
    "    plt.legend(frameon=False)\n",
    "    plt.savefig(GRAPHS +\"{}_curve.png\".format(curve_name))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137108,
     "status": "ok",
     "timestamp": 1619061264697,
     "user": {
      "displayName": "Shubham Nagarkar",
      "photoUrl": "",
      "userId": "10621817079012605482"
     },
     "user_tz": 420
    },
    "id": "w7IaBbgTmBrE",
    "outputId": "d9e00e12-a6ce-4f40-eaaa-f5346b6a4862"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset length :  126\n",
      "New train length :  88\n",
      "New test length :  38\n",
      "Length of unique words:  6174\n",
      "Shape of Embedding matrix :  (6176, 300)\n",
      "Shape of Vocabulary :  (6176,)\n",
      "Length of Vocab to index :  6175\n"
     ]
    }
   ],
   "source": [
    "#read data from csvs\n",
    "train_dataset = pd.read_csv(TRAIN_PATH)\n",
    "test_dataset = pd.read_csv(TEST_PATH)\n",
    "val_dataset = pd.read_csv(VAL_PATH) \n",
    "\n",
    "new_dataset = pd.read_csv(NEW_DATA)\n",
    "\n",
    "new_dataset = new_dataset.sample(frac=1)\n",
    "\n",
    "split = int(len(new_dataset)*0.7)\n",
    "new_train_dataset = new_dataset.iloc[:split,:]\n",
    "new_test_dataset = new_dataset.iloc[split:,:]\n",
    "\n",
    "print(\"New dataset length : \",len(new_dataset))\n",
    "print(\"New train length : \",len(new_train_dataset))\n",
    "print(\"New test length : \",len(new_test_dataset))\n",
    "\n",
    "# generate sentences and their labels\n",
    "# X_train, train_PHQ, train_PTSD = get_data(train_dataset)\n",
    "# X_val, val_PHQ, val_PTSD = get_data(val_dataset)\n",
    "# X_test, test_PHQ, test_PTSD = get_data(test_dataset)\n",
    "\n",
    "new_X_train, new_train_PHQ = get_new_data(new_train_dataset)\n",
    "new_X_test, new_test_PHQ = get_new_data(new_test_dataset)\n",
    "\n",
    "new_train_PHQ = new_train_PHQ.values\n",
    "\n",
    "new_test_PHQ = new_test_PHQ.values\n",
    "\n",
    "\n",
    "# embeddings_dict = get_embeddings()\n",
    "\n",
    "# train_text = list(X_train.values)\n",
    "# val_text = list(X_val.values)\n",
    "# test_text = list(X_test.values)\n",
    "# train_tokens = tokenize_text(train_text)\n",
    "# val_tokens = tokenize_text(val_text)\n",
    "# test_tokens = tokenize_text(test_text)\n",
    "\n",
    "new_train_text = list(new_X_train.values)\n",
    "new_test_text = list(new_X_test.values)\n",
    "\n",
    "\n",
    "train_tokens = tokenize_text(new_train_text)\n",
    "test_tokens = tokenize_text(new_test_text)\n",
    "\n",
    "counts = Counter()\n",
    "for tok in train_tokens:\n",
    "    counts.update(tok)\n",
    "for tok in test_tokens:  \n",
    "    counts.update(tok)\n",
    "\n",
    "print(\"Length of unique words: \", len(counts))\n",
    "\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)\n",
    "\n",
    "train_encoded = []\n",
    "val_encoded = []\n",
    "test_encoded = []\n",
    "\n",
    "# for text in train_text:\n",
    "#     train_encoded.append(encode_sentence(text, vocab2index))\n",
    "# for text in val_text:\n",
    "#     val_encoded.append(encode_sentence(text, vocab2index))\n",
    "# for text in test_text:\n",
    "#     test_encoded.append(encode_sentence(text, vocab2index))\n",
    "\n",
    "for text in new_train_text:\n",
    "    train_encoded.append(encode_sentence(text, vocab2index))\n",
    "\n",
    "for text in new_test_text:\n",
    "    test_encoded.append(encode_sentence(text, vocab2index))\n",
    "    \n",
    "embed_matrix, vocab, vocab_to_idx = get_emb_matrix(embeddings_dict, counts)\n",
    "print(\"Shape of Embedding matrix : \", embed_matrix.shape)\n",
    "print(\"Shape of Vocabulary : \", vocab.shape)\n",
    "print(\"Length of Vocab to index : \", len(vocab_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "vkMJXcbpgBdI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Epoch :  1\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.318, Train PHQ loss: 0.161, Train PTSD loss: 0.157 \n",
      "Val total loss: 0.323, Val PHQ loss: 0.155, Val PTSD loss: 0.168 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  2\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.298, Train PHQ loss: 0.146, Train PTSD loss: 0.152 \n",
      "Val total loss: 0.319, Val PHQ loss: 0.163, Val PTSD loss: 0.156 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  3\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.309, Train PHQ loss: 0.156, Train PTSD loss: 0.153 \n",
      "Val total loss: 0.314, Val PHQ loss: 0.165, Val PTSD loss: 0.149 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  4\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.306, Train PHQ loss: 0.150, Train PTSD loss: 0.156 \n",
      "Val total loss: 0.307, Val PHQ loss: 0.168, Val PTSD loss: 0.139 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  5\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.310, Train PHQ loss: 0.160, Train PTSD loss: 0.149 \n",
      "Val total loss: 0.297, Val PHQ loss: 0.170, Val PTSD loss: 0.127 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  6\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.304, Train PHQ loss: 0.158, Train PTSD loss: 0.146 \n",
      "Val total loss: 0.288, Val PHQ loss: 0.171, Val PTSD loss: 0.117 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  7\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.298, Train PHQ loss: 0.155, Train PTSD loss: 0.144 \n",
      "Val total loss: 0.276, Val PHQ loss: 0.170, Val PTSD loss: 0.106 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  8\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.292, Train PHQ loss: 0.152, Train PTSD loss: 0.140 \n",
      "Val total loss: 0.267, Val PHQ loss: 0.169, Val PTSD loss: 0.097 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  9\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.288, Train PHQ loss: 0.148, Train PTSD loss: 0.139 \n",
      "Val total loss: 0.260, Val PHQ loss: 0.169, Val PTSD loss: 0.091 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  10\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.284, Train PHQ loss: 0.148, Train PTSD loss: 0.136 \n",
      "Val total loss: 0.254, Val PHQ loss: 0.168, Val PTSD loss: 0.086 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  11\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.278, Train PHQ loss: 0.145, Train PTSD loss: 0.133 \n",
      "Val total loss: 0.249, Val PHQ loss: 0.166, Val PTSD loss: 0.082 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  12\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.274, Train PHQ loss: 0.144, Train PTSD loss: 0.130 \n",
      "Val total loss: 0.247, Val PHQ loss: 0.166, Val PTSD loss: 0.082 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  13\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.268, Train PHQ loss: 0.143, Train PTSD loss: 0.125 \n",
      "Val total loss: 0.247, Val PHQ loss: 0.164, Val PTSD loss: 0.082 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  14\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.262, Train PHQ loss: 0.139, Train PTSD loss: 0.123 \n",
      "Val total loss: 0.240, Val PHQ loss: 0.160, Val PTSD loss: 0.080 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  15\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.255, Train PHQ loss: 0.136, Train PTSD loss: 0.120 \n",
      "Val total loss: 0.240, Val PHQ loss: 0.160, Val PTSD loss: 0.080 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  16\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.254, Train PHQ loss: 0.137, Train PTSD loss: 0.117 \n",
      "Val total loss: 0.239, Val PHQ loss: 0.159, Val PTSD loss: 0.080 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  17\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.250, Train PHQ loss: 0.135, Train PTSD loss: 0.115 \n",
      "Val total loss: 0.238, Val PHQ loss: 0.157, Val PTSD loss: 0.081 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  18\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.246, Train PHQ loss: 0.134, Train PTSD loss: 0.113 \n",
      "Val total loss: 0.236, Val PHQ loss: 0.156, Val PTSD loss: 0.080 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.244, Train PHQ loss: 0.133, Train PTSD loss: 0.111 \n",
      "Val total loss: 0.232, Val PHQ loss: 0.154, Val PTSD loss: 0.079 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  20\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.242, Train PHQ loss: 0.132, Train PTSD loss: 0.110 \n",
      "Val total loss: 0.230, Val PHQ loss: 0.152, Val PTSD loss: 0.077 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  21\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.240, Train PHQ loss: 0.131, Train PTSD loss: 0.108 \n",
      "Val total loss: 0.227, Val PHQ loss: 0.151, Val PTSD loss: 0.076 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  22\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.235, Train PHQ loss: 0.129, Train PTSD loss: 0.106 \n",
      "Val total loss: 0.224, Val PHQ loss: 0.149, Val PTSD loss: 0.075 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  23\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.233, Train PHQ loss: 0.128, Train PTSD loss: 0.105 \n",
      "Val total loss: 0.222, Val PHQ loss: 0.147, Val PTSD loss: 0.075 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  24\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.230, Train PHQ loss: 0.127, Train PTSD loss: 0.103 \n",
      "Val total loss: 0.221, Val PHQ loss: 0.147, Val PTSD loss: 0.074 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  25\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.229, Train PHQ loss: 0.127, Train PTSD loss: 0.102 \n",
      "Val total loss: 0.218, Val PHQ loss: 0.145, Val PTSD loss: 0.073 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  26\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.226, Train PHQ loss: 0.125, Train PTSD loss: 0.100 \n",
      "Val total loss: 0.215, Val PHQ loss: 0.144, Val PTSD loss: 0.071 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  27\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.224, Train PHQ loss: 0.125, Train PTSD loss: 0.099 \n",
      "Val total loss: 0.214, Val PHQ loss: 0.144, Val PTSD loss: 0.070 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  28\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.222, Train PHQ loss: 0.125, Train PTSD loss: 0.097 \n",
      "Val total loss: 0.211, Val PHQ loss: 0.142, Val PTSD loss: 0.069 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  29\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.219, Train PHQ loss: 0.124, Train PTSD loss: 0.096 \n",
      "Val total loss: 0.209, Val PHQ loss: 0.141, Val PTSD loss: 0.068 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  30\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.218, Train PHQ loss: 0.124, Train PTSD loss: 0.094 \n",
      "Val total loss: 0.206, Val PHQ loss: 0.139, Val PTSD loss: 0.067 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  31\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.216, Train PHQ loss: 0.123, Train PTSD loss: 0.093 \n",
      "Val total loss: 0.205, Val PHQ loss: 0.139, Val PTSD loss: 0.066 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  32\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.213, Train PHQ loss: 0.122, Train PTSD loss: 0.092 \n",
      "Val total loss: 0.204, Val PHQ loss: 0.138, Val PTSD loss: 0.066 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  33\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.211, Train PHQ loss: 0.120, Train PTSD loss: 0.090 \n",
      "Val total loss: 0.203, Val PHQ loss: 0.137, Val PTSD loss: 0.066 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  34\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.209, Train PHQ loss: 0.120, Train PTSD loss: 0.089 \n",
      "Val total loss: 0.201, Val PHQ loss: 0.136, Val PTSD loss: 0.065 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  35\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.206, Train PHQ loss: 0.118, Train PTSD loss: 0.088 \n",
      "Val total loss: 0.199, Val PHQ loss: 0.135, Val PTSD loss: 0.064 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  36\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.204, Train PHQ loss: 0.117, Train PTSD loss: 0.087 \n",
      "Val total loss: 0.198, Val PHQ loss: 0.134, Val PTSD loss: 0.063 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  37\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.202, Train PHQ loss: 0.116, Train PTSD loss: 0.085 \n",
      "Val total loss: 0.196, Val PHQ loss: 0.133, Val PTSD loss: 0.063 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.200, Train PHQ loss: 0.116, Train PTSD loss: 0.084 \n",
      "Val total loss: 0.196, Val PHQ loss: 0.133, Val PTSD loss: 0.063 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  39\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 1 to 1.0000e-03.\n",
      "Adjusting learning rate of group 2 to 1.0000e-03.\n",
      "Adjusting learning rate of group 3 to 1.0000e-04.\n",
      "Train total loss: 0.198, Train PHQ loss: 0.115, Train PTSD loss: 0.083 \n",
      "Val total loss: 0.194, Val PHQ loss: 0.132, Val PTSD loss: 0.062 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  40\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.197, Train PHQ loss: 0.115, Train PTSD loss: 0.082 \n",
      "Val total loss: 0.193, Val PHQ loss: 0.131, Val PTSD loss: 0.062 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  41\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.195, Train PHQ loss: 0.114, Train PTSD loss: 0.081 \n",
      "Val total loss: 0.192, Val PHQ loss: 0.131, Val PTSD loss: 0.062 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  42\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.194, Train PHQ loss: 0.114, Train PTSD loss: 0.080 \n",
      "Val total loss: 0.191, Val PHQ loss: 0.130, Val PTSD loss: 0.061 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  43\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.193, Train PHQ loss: 0.114, Train PTSD loss: 0.079 \n",
      "Val total loss: 0.190, Val PHQ loss: 0.129, Val PTSD loss: 0.061 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  44\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.191, Train PHQ loss: 0.113, Train PTSD loss: 0.078 \n",
      "Val total loss: 0.189, Val PHQ loss: 0.128, Val PTSD loss: 0.060 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  45\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.190, Train PHQ loss: 0.112, Train PTSD loss: 0.078 \n",
      "Val total loss: 0.187, Val PHQ loss: 0.128, Val PTSD loss: 0.060 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  46\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.188, Train PHQ loss: 0.112, Train PTSD loss: 0.077 \n",
      "Val total loss: 0.187, Val PHQ loss: 0.128, Val PTSD loss: 0.060 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  47\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.187, Train PHQ loss: 0.111, Train PTSD loss: 0.076 \n",
      "Val total loss: 0.186, Val PHQ loss: 0.127, Val PTSD loss: 0.059 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  48\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.185, Train PHQ loss: 0.110, Train PTSD loss: 0.075 \n",
      "Val total loss: 0.186, Val PHQ loss: 0.127, Val PTSD loss: 0.059 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  49\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.183, Train PHQ loss: 0.109, Train PTSD loss: 0.074 \n",
      "Val total loss: 0.184, Val PHQ loss: 0.126, Val PTSD loss: 0.059 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  50\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.182, Train PHQ loss: 0.109, Train PTSD loss: 0.073 \n",
      "Val total loss: 0.184, Val PHQ loss: 0.125, Val PTSD loss: 0.058 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  51\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.181, Train PHQ loss: 0.108, Train PTSD loss: 0.072 \n",
      "Val total loss: 0.183, Val PHQ loss: 0.125, Val PTSD loss: 0.058 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  52\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.180, Train PHQ loss: 0.108, Train PTSD loss: 0.072 \n",
      "Val total loss: 0.182, Val PHQ loss: 0.125, Val PTSD loss: 0.057 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  53\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.179, Train PHQ loss: 0.108, Train PTSD loss: 0.071 \n",
      "Val total loss: 0.181, Val PHQ loss: 0.124, Val PTSD loss: 0.057 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  54\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.177, Train PHQ loss: 0.107, Train PTSD loss: 0.071 \n",
      "Val total loss: 0.181, Val PHQ loss: 0.124, Val PTSD loss: 0.057 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  55\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.176, Train PHQ loss: 0.106, Train PTSD loss: 0.070 \n",
      "Val total loss: 0.181, Val PHQ loss: 0.124, Val PTSD loss: 0.057 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  56\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.175, Train PHQ loss: 0.106, Train PTSD loss: 0.069 \n",
      "Val total loss: 0.180, Val PHQ loss: 0.123, Val PTSD loss: 0.057 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.174, Train PHQ loss: 0.105, Train PTSD loss: 0.069 \n",
      "Val total loss: 0.179, Val PHQ loss: 0.123, Val PTSD loss: 0.056 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  58\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.173, Train PHQ loss: 0.105, Train PTSD loss: 0.068 \n",
      "Val total loss: 0.179, Val PHQ loss: 0.123, Val PTSD loss: 0.056 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  59\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.172, Train PHQ loss: 0.104, Train PTSD loss: 0.068 \n",
      "Val total loss: 0.178, Val PHQ loss: 0.123, Val PTSD loss: 0.056 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  60\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.171, Train PHQ loss: 0.104, Train PTSD loss: 0.067 \n",
      "Val total loss: 0.178, Val PHQ loss: 0.122, Val PTSD loss: 0.056 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  61\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.170, Train PHQ loss: 0.103, Train PTSD loss: 0.067 \n",
      "Val total loss: 0.177, Val PHQ loss: 0.122, Val PTSD loss: 0.055 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  62\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.168, Train PHQ loss: 0.102, Train PTSD loss: 0.066 \n",
      "Val total loss: 0.176, Val PHQ loss: 0.121, Val PTSD loss: 0.055 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  63\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.167, Train PHQ loss: 0.102, Train PTSD loss: 0.065 \n",
      "Val total loss: 0.176, Val PHQ loss: 0.121, Val PTSD loss: 0.055 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  64\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.166, Train PHQ loss: 0.101, Train PTSD loss: 0.065 \n",
      "Val total loss: 0.175, Val PHQ loss: 0.121, Val PTSD loss: 0.055 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  65\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.165, Train PHQ loss: 0.101, Train PTSD loss: 0.064 \n",
      "Val total loss: 0.175, Val PHQ loss: 0.121, Val PTSD loss: 0.054 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  66\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.164, Train PHQ loss: 0.100, Train PTSD loss: 0.064 \n",
      "Val total loss: 0.175, Val PHQ loss: 0.120, Val PTSD loss: 0.054 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  67\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.163, Train PHQ loss: 0.100, Train PTSD loss: 0.063 \n",
      "Val total loss: 0.174, Val PHQ loss: 0.120, Val PTSD loss: 0.054 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  68\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.162, Train PHQ loss: 0.099, Train PTSD loss: 0.063 \n",
      "Val total loss: 0.174, Val PHQ loss: 0.120, Val PTSD loss: 0.054 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  69\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.161, Train PHQ loss: 0.099, Train PTSD loss: 0.062 \n",
      "Val total loss: 0.173, Val PHQ loss: 0.120, Val PTSD loss: 0.053 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  70\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.160, Train PHQ loss: 0.099, Train PTSD loss: 0.062 \n",
      "Val total loss: 0.173, Val PHQ loss: 0.120, Val PTSD loss: 0.053 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  71\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.160, Train PHQ loss: 0.098, Train PTSD loss: 0.062 \n",
      "Val total loss: 0.172, Val PHQ loss: 0.119, Val PTSD loss: 0.053 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  72\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.159, Train PHQ loss: 0.098, Train PTSD loss: 0.061 \n",
      "Val total loss: 0.172, Val PHQ loss: 0.119, Val PTSD loss: 0.053 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  73\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.158, Train PHQ loss: 0.097, Train PTSD loss: 0.061 \n",
      "Val total loss: 0.172, Val PHQ loss: 0.119, Val PTSD loss: 0.053 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  74\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.157, Train PHQ loss: 0.097, Train PTSD loss: 0.060 \n",
      "Val total loss: 0.171, Val PHQ loss: 0.119, Val PTSD loss: 0.053 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  75\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.157, Train PHQ loss: 0.097, Train PTSD loss: 0.060 \n",
      "Val total loss: 0.171, Val PHQ loss: 0.119, Val PTSD loss: 0.052 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.156, Train PHQ loss: 0.096, Train PTSD loss: 0.059 \n",
      "Val total loss: 0.171, Val PHQ loss: 0.119, Val PTSD loss: 0.052 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  77\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.155, Train PHQ loss: 0.096, Train PTSD loss: 0.059 \n",
      "Val total loss: 0.170, Val PHQ loss: 0.118, Val PTSD loss: 0.052 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  78\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.155, Train PHQ loss: 0.096, Train PTSD loss: 0.059 \n",
      "Val total loss: 0.170, Val PHQ loss: 0.118, Val PTSD loss: 0.052 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  79\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 1 to 2.0000e-04.\n",
      "Adjusting learning rate of group 2 to 2.0000e-04.\n",
      "Adjusting learning rate of group 3 to 2.0000e-05.\n",
      "Train total loss: 0.154, Train PHQ loss: 0.095, Train PTSD loss: 0.058 \n",
      "Val total loss: 0.170, Val PHQ loss: 0.118, Val PTSD loss: 0.052 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  80\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.153, Train PHQ loss: 0.095, Train PTSD loss: 0.058 \n",
      "Val total loss: 0.171, Val PHQ loss: 0.118, Val PTSD loss: 0.052 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  81\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.152, Train PHQ loss: 0.095, Train PTSD loss: 0.058 \n",
      "Val total loss: 0.170, Val PHQ loss: 0.118, Val PTSD loss: 0.052 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  82\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.151, Train PHQ loss: 0.094, Train PTSD loss: 0.057 \n",
      "Val total loss: 0.170, Val PHQ loss: 0.118, Val PTSD loss: 0.052 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  83\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.151, Train PHQ loss: 0.094, Train PTSD loss: 0.057 \n",
      "Val total loss: 0.170, Val PHQ loss: 0.118, Val PTSD loss: 0.052 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  84\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.150, Train PHQ loss: 0.093, Train PTSD loss: 0.057 \n",
      "Val total loss: 0.170, Val PHQ loss: 0.118, Val PTSD loss: 0.052 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  85\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.149, Train PHQ loss: 0.093, Train PTSD loss: 0.056 \n",
      "Val total loss: 0.169, Val PHQ loss: 0.118, Val PTSD loss: 0.052 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  86\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.149, Train PHQ loss: 0.093, Train PTSD loss: 0.056 \n",
      "Val total loss: 0.169, Val PHQ loss: 0.118, Val PTSD loss: 0.051 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  87\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.148, Train PHQ loss: 0.093, Train PTSD loss: 0.056 \n",
      "Val total loss: 0.169, Val PHQ loss: 0.117, Val PTSD loss: 0.051 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  88\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.148, Train PHQ loss: 0.092, Train PTSD loss: 0.055 \n",
      "Val total loss: 0.168, Val PHQ loss: 0.117, Val PTSD loss: 0.051 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  89\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.147, Train PHQ loss: 0.092, Train PTSD loss: 0.055 \n",
      "Val total loss: 0.168, Val PHQ loss: 0.117, Val PTSD loss: 0.051 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  90\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.147, Train PHQ loss: 0.092, Train PTSD loss: 0.055 \n",
      "Val total loss: 0.168, Val PHQ loss: 0.117, Val PTSD loss: 0.051 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  91\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.146, Train PHQ loss: 0.091, Train PTSD loss: 0.055 \n",
      "Val total loss: 0.168, Val PHQ loss: 0.117, Val PTSD loss: 0.051 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  92\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.145, Train PHQ loss: 0.091, Train PTSD loss: 0.054 \n",
      "Val total loss: 0.167, Val PHQ loss: 0.116, Val PTSD loss: 0.051 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  93\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.145, Train PHQ loss: 0.091, Train PTSD loss: 0.054 \n",
      "Val total loss: 0.167, Val PHQ loss: 0.116, Val PTSD loss: 0.051 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  94\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.145, Train PHQ loss: 0.091, Train PTSD loss: 0.054 \n",
      "Val total loss: 0.167, Val PHQ loss: 0.116, Val PTSD loss: 0.051 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.144, Train PHQ loss: 0.091, Train PTSD loss: 0.054 \n",
      "Val total loss: 0.167, Val PHQ loss: 0.116, Val PTSD loss: 0.051 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  96\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.144, Train PHQ loss: 0.090, Train PTSD loss: 0.053 \n",
      "Val total loss: 0.167, Val PHQ loss: 0.116, Val PTSD loss: 0.051 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  97\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.143, Train PHQ loss: 0.090, Train PTSD loss: 0.053 \n",
      "Val total loss: 0.167, Val PHQ loss: 0.116, Val PTSD loss: 0.051 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  98\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.143, Train PHQ loss: 0.090, Train PTSD loss: 0.053 \n",
      "Val total loss: 0.166, Val PHQ loss: 0.116, Val PTSD loss: 0.051 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  99\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.143, Train PHQ loss: 0.090, Train PTSD loss: 0.053 \n",
      "Val total loss: 0.166, Val PHQ loss: 0.116, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  100\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.142, Train PHQ loss: 0.090, Train PTSD loss: 0.052 \n",
      "Val total loss: 0.166, Val PHQ loss: 0.115, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  101\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.142, Train PHQ loss: 0.089, Train PTSD loss: 0.052 \n",
      "Val total loss: 0.166, Val PHQ loss: 0.115, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  102\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.141, Train PHQ loss: 0.089, Train PTSD loss: 0.052 \n",
      "Val total loss: 0.166, Val PHQ loss: 0.115, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  103\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.141, Train PHQ loss: 0.089, Train PTSD loss: 0.052 \n",
      "Val total loss: 0.166, Val PHQ loss: 0.115, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  104\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.140, Train PHQ loss: 0.089, Train PTSD loss: 0.052 \n",
      "Val total loss: 0.165, Val PHQ loss: 0.115, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  105\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.140, Train PHQ loss: 0.088, Train PTSD loss: 0.051 \n",
      "Val total loss: 0.165, Val PHQ loss: 0.115, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  106\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.139, Train PHQ loss: 0.088, Train PTSD loss: 0.051 \n",
      "Val total loss: 0.165, Val PHQ loss: 0.115, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  107\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.139, Train PHQ loss: 0.088, Train PTSD loss: 0.051 \n",
      "Val total loss: 0.165, Val PHQ loss: 0.115, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  108\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.139, Train PHQ loss: 0.088, Train PTSD loss: 0.051 \n",
      "Val total loss: 0.165, Val PHQ loss: 0.115, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  109\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.138, Train PHQ loss: 0.088, Train PTSD loss: 0.051 \n",
      "Val total loss: 0.165, Val PHQ loss: 0.115, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  110\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.138, Train PHQ loss: 0.087, Train PTSD loss: 0.050 \n",
      "Val total loss: 0.164, Val PHQ loss: 0.114, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  111\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.137, Train PHQ loss: 0.087, Train PTSD loss: 0.050 \n",
      "Val total loss: 0.164, Val PHQ loss: 0.114, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  112\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.137, Train PHQ loss: 0.087, Train PTSD loss: 0.050 \n",
      "Val total loss: 0.164, Val PHQ loss: 0.114, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  113\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.136, Train PHQ loss: 0.087, Train PTSD loss: 0.050 \n",
      "Val total loss: 0.164, Val PHQ loss: 0.114, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.136, Train PHQ loss: 0.087, Train PTSD loss: 0.050 \n",
      "Val total loss: 0.164, Val PHQ loss: 0.114, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  115\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.136, Train PHQ loss: 0.086, Train PTSD loss: 0.049 \n",
      "Val total loss: 0.164, Val PHQ loss: 0.114, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  116\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.135, Train PHQ loss: 0.086, Train PTSD loss: 0.049 \n",
      "Val total loss: 0.164, Val PHQ loss: 0.114, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  117\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.135, Train PHQ loss: 0.086, Train PTSD loss: 0.049 \n",
      "Val total loss: 0.164, Val PHQ loss: 0.114, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  118\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.135, Train PHQ loss: 0.086, Train PTSD loss: 0.049 \n",
      "Val total loss: 0.163, Val PHQ loss: 0.114, Val PTSD loss: 0.050 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  119\n",
      "Adjusting learning rate of group 0 to 4.0000e-05.\n",
      "Adjusting learning rate of group 1 to 4.0000e-05.\n",
      "Adjusting learning rate of group 2 to 4.0000e-05.\n",
      "Adjusting learning rate of group 3 to 4.0000e-06.\n",
      "Train total loss: 0.134, Train PHQ loss: 0.086, Train PTSD loss: 0.049 \n",
      "Val total loss: 0.163, Val PHQ loss: 0.114, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  120\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.134, Train PHQ loss: 0.085, Train PTSD loss: 0.048 \n",
      "Val total loss: 0.163, Val PHQ loss: 0.114, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  121\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.133, Train PHQ loss: 0.085, Train PTSD loss: 0.048 \n",
      "Val total loss: 0.163, Val PHQ loss: 0.113, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  122\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.133, Train PHQ loss: 0.085, Train PTSD loss: 0.048 \n",
      "Val total loss: 0.163, Val PHQ loss: 0.113, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  123\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.133, Train PHQ loss: 0.085, Train PTSD loss: 0.048 \n",
      "Val total loss: 0.162, Val PHQ loss: 0.113, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  124\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.132, Train PHQ loss: 0.085, Train PTSD loss: 0.048 \n",
      "Val total loss: 0.162, Val PHQ loss: 0.113, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  125\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.132, Train PHQ loss: 0.084, Train PTSD loss: 0.048 \n",
      "Val total loss: 0.162, Val PHQ loss: 0.113, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  126\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.132, Train PHQ loss: 0.084, Train PTSD loss: 0.047 \n",
      "Val total loss: 0.162, Val PHQ loss: 0.113, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  127\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.131, Train PHQ loss: 0.084, Train PTSD loss: 0.047 \n",
      "Val total loss: 0.162, Val PHQ loss: 0.113, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  128\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.131, Train PHQ loss: 0.084, Train PTSD loss: 0.047 \n",
      "Val total loss: 0.162, Val PHQ loss: 0.113, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  129\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.131, Train PHQ loss: 0.084, Train PTSD loss: 0.047 \n",
      "Val total loss: 0.162, Val PHQ loss: 0.113, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  130\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.131, Train PHQ loss: 0.084, Train PTSD loss: 0.047 \n",
      "Val total loss: 0.161, Val PHQ loss: 0.113, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  131\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.130, Train PHQ loss: 0.083, Train PTSD loss: 0.047 \n",
      "Val total loss: 0.161, Val PHQ loss: 0.113, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  132\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.130, Train PHQ loss: 0.083, Train PTSD loss: 0.047 \n",
      "Val total loss: 0.161, Val PHQ loss: 0.113, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.130, Train PHQ loss: 0.083, Train PTSD loss: 0.047 \n",
      "Val total loss: 0.161, Val PHQ loss: 0.112, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  134\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.129, Train PHQ loss: 0.083, Train PTSD loss: 0.046 \n",
      "Val total loss: 0.161, Val PHQ loss: 0.112, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  135\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.129, Train PHQ loss: 0.083, Train PTSD loss: 0.046 \n",
      "Val total loss: 0.161, Val PHQ loss: 0.112, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  136\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.129, Train PHQ loss: 0.083, Train PTSD loss: 0.046 \n",
      "Val total loss: 0.161, Val PHQ loss: 0.112, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  137\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.129, Train PHQ loss: 0.083, Train PTSD loss: 0.046 \n",
      "Val total loss: 0.161, Val PHQ loss: 0.112, Val PTSD loss: 0.049 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  138\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.128, Train PHQ loss: 0.082, Train PTSD loss: 0.046 \n",
      "Val total loss: 0.161, Val PHQ loss: 0.112, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  139\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.128, Train PHQ loss: 0.082, Train PTSD loss: 0.046 \n",
      "Val total loss: 0.160, Val PHQ loss: 0.112, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  140\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.128, Train PHQ loss: 0.082, Train PTSD loss: 0.046 \n",
      "Val total loss: 0.160, Val PHQ loss: 0.112, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  141\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.127, Train PHQ loss: 0.082, Train PTSD loss: 0.045 \n",
      "Val total loss: 0.160, Val PHQ loss: 0.112, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  142\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.127, Train PHQ loss: 0.082, Train PTSD loss: 0.045 \n",
      "Val total loss: 0.160, Val PHQ loss: 0.112, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  143\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.127, Train PHQ loss: 0.081, Train PTSD loss: 0.045 \n",
      "Val total loss: 0.160, Val PHQ loss: 0.112, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  144\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.127, Train PHQ loss: 0.082, Train PTSD loss: 0.045 \n",
      "Val total loss: 0.160, Val PHQ loss: 0.111, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  145\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.126, Train PHQ loss: 0.081, Train PTSD loss: 0.045 \n",
      "Val total loss: 0.160, Val PHQ loss: 0.111, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  146\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.126, Train PHQ loss: 0.081, Train PTSD loss: 0.045 \n",
      "Val total loss: 0.159, Val PHQ loss: 0.111, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  147\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.126, Train PHQ loss: 0.081, Train PTSD loss: 0.045 \n",
      "Val total loss: 0.159, Val PHQ loss: 0.111, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  148\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.126, Train PHQ loss: 0.081, Train PTSD loss: 0.045 \n",
      "Val total loss: 0.159, Val PHQ loss: 0.111, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  149\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.126, Train PHQ loss: 0.081, Train PTSD loss: 0.045 \n",
      "Val total loss: 0.159, Val PHQ loss: 0.111, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  150\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.126, Train PHQ loss: 0.081, Train PTSD loss: 0.045 \n",
      "Val total loss: 0.159, Val PHQ loss: 0.111, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  151\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.125, Train PHQ loss: 0.081, Train PTSD loss: 0.044 \n",
      "Val total loss: 0.159, Val PHQ loss: 0.111, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.125, Train PHQ loss: 0.081, Train PTSD loss: 0.044 \n",
      "Val total loss: 0.159, Val PHQ loss: 0.111, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  153\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.125, Train PHQ loss: 0.081, Train PTSD loss: 0.044 \n",
      "Val total loss: 0.159, Val PHQ loss: 0.111, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  154\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.125, Train PHQ loss: 0.080, Train PTSD loss: 0.044 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.111, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  155\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.124, Train PHQ loss: 0.080, Train PTSD loss: 0.044 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  156\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.124, Train PHQ loss: 0.080, Train PTSD loss: 0.044 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  157\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.124, Train PHQ loss: 0.080, Train PTSD loss: 0.044 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  158\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.124, Train PHQ loss: 0.080, Train PTSD loss: 0.044 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  159\n",
      "Adjusting learning rate of group 0 to 8.0000e-06.\n",
      "Adjusting learning rate of group 1 to 8.0000e-06.\n",
      "Adjusting learning rate of group 2 to 8.0000e-06.\n",
      "Adjusting learning rate of group 3 to 8.0000e-07.\n",
      "Train total loss: 0.124, Train PHQ loss: 0.080, Train PTSD loss: 0.044 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  160\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.123, Train PHQ loss: 0.080, Train PTSD loss: 0.044 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  161\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.123, Train PHQ loss: 0.080, Train PTSD loss: 0.043 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  162\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.123, Train PHQ loss: 0.080, Train PTSD loss: 0.043 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  163\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.123, Train PHQ loss: 0.080, Train PTSD loss: 0.043 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  164\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.123, Train PHQ loss: 0.079, Train PTSD loss: 0.043 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  165\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.122, Train PHQ loss: 0.079, Train PTSD loss: 0.043 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  166\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.122, Train PHQ loss: 0.079, Train PTSD loss: 0.043 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  167\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.122, Train PHQ loss: 0.079, Train PTSD loss: 0.043 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  168\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.122, Train PHQ loss: 0.079, Train PTSD loss: 0.043 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  169\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.122, Train PHQ loss: 0.079, Train PTSD loss: 0.043 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  170\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.121, Train PHQ loss: 0.079, Train PTSD loss: 0.043 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.121, Train PHQ loss: 0.079, Train PTSD loss: 0.043 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  172\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.121, Train PHQ loss: 0.079, Train PTSD loss: 0.042 \n",
      "Val total loss: 0.158, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  173\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.121, Train PHQ loss: 0.079, Train PTSD loss: 0.042 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  174\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.121, Train PHQ loss: 0.079, Train PTSD loss: 0.042 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  175\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.121, Train PHQ loss: 0.078, Train PTSD loss: 0.042 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.048 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  176\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.120, Train PHQ loss: 0.078, Train PTSD loss: 0.042 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  177\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.120, Train PHQ loss: 0.078, Train PTSD loss: 0.042 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  178\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.120, Train PHQ loss: 0.078, Train PTSD loss: 0.042 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  179\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.120, Train PHQ loss: 0.078, Train PTSD loss: 0.042 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  180\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.120, Train PHQ loss: 0.078, Train PTSD loss: 0.042 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  181\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.120, Train PHQ loss: 0.078, Train PTSD loss: 0.042 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  182\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.119, Train PHQ loss: 0.078, Train PTSD loss: 0.042 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  183\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.119, Train PHQ loss: 0.078, Train PTSD loss: 0.042 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  184\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.119, Train PHQ loss: 0.078, Train PTSD loss: 0.041 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  185\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.119, Train PHQ loss: 0.078, Train PTSD loss: 0.041 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  186\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.119, Train PHQ loss: 0.078, Train PTSD loss: 0.041 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  187\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.119, Train PHQ loss: 0.078, Train PTSD loss: 0.041 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  188\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.119, Train PHQ loss: 0.078, Train PTSD loss: 0.041 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  189\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.118, Train PHQ loss: 0.077, Train PTSD loss: 0.041 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.118, Train PHQ loss: 0.077, Train PTSD loss: 0.041 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  191\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.118, Train PHQ loss: 0.077, Train PTSD loss: 0.041 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  192\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.118, Train PHQ loss: 0.077, Train PTSD loss: 0.041 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.110, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  193\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.118, Train PHQ loss: 0.077, Train PTSD loss: 0.041 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  194\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.118, Train PHQ loss: 0.077, Train PTSD loss: 0.041 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  195\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.118, Train PHQ loss: 0.077, Train PTSD loss: 0.041 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  196\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.118, Train PHQ loss: 0.077, Train PTSD loss: 0.041 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  197\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.117, Train PHQ loss: 0.077, Train PTSD loss: 0.041 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  198\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.117, Train PHQ loss: 0.077, Train PTSD loss: 0.041 \n",
      "Val total loss: 0.156, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  199\n",
      "Adjusting learning rate of group 0 to 1.6000e-06.\n",
      "Adjusting learning rate of group 1 to 1.6000e-06.\n",
      "Adjusting learning rate of group 2 to 1.6000e-06.\n",
      "Adjusting learning rate of group 3 to 1.6000e-07.\n",
      "Train total loss: 0.117, Train PHQ loss: 0.077, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  200\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.117, Train PHQ loss: 0.077, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.157, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  201\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.117, Train PHQ loss: 0.077, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.156, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  202\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.117, Train PHQ loss: 0.077, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.156, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  203\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.117, Train PHQ loss: 0.077, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.156, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  204\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.117, Train PHQ loss: 0.076, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.156, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  205\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.116, Train PHQ loss: 0.076, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.156, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  206\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.116, Train PHQ loss: 0.076, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.156, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  207\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.116, Train PHQ loss: 0.076, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.156, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  208\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.116, Train PHQ loss: 0.076, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.156, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.116, Train PHQ loss: 0.076, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.156, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  210\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.116, Train PHQ loss: 0.076, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.156, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  211\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.116, Train PHQ loss: 0.076, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.156, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  212\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.116, Train PHQ loss: 0.076, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.156, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  213\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.116, Train PHQ loss: 0.076, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.156, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  214\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.116, Train PHQ loss: 0.076, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.156, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  215\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.115, Train PHQ loss: 0.076, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.155, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  216\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.115, Train PHQ loss: 0.076, Train PTSD loss: 0.040 \n",
      "Val total loss: 0.155, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  217\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.115, Train PHQ loss: 0.076, Train PTSD loss: 0.039 \n",
      "Val total loss: 0.155, Val PHQ loss: 0.108, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  218\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.115, Train PHQ loss: 0.076, Train PTSD loss: 0.039 \n",
      "Val total loss: 0.155, Val PHQ loss: 0.108, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  219\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.115, Train PHQ loss: 0.076, Train PTSD loss: 0.039 \n",
      "Val total loss: 0.156, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  220\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.115, Train PHQ loss: 0.075, Train PTSD loss: 0.039 \n",
      "Val total loss: 0.155, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  221\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.115, Train PHQ loss: 0.075, Train PTSD loss: 0.039 \n",
      "Val total loss: 0.155, Val PHQ loss: 0.108, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  222\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.115, Train PHQ loss: 0.075, Train PTSD loss: 0.039 \n",
      "Val total loss: 0.155, Val PHQ loss: 0.108, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  223\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.115, Train PHQ loss: 0.075, Train PTSD loss: 0.039 \n",
      "Val total loss: 0.155, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  224\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.114, Train PHQ loss: 0.075, Train PTSD loss: 0.039 \n",
      "Val total loss: 0.155, Val PHQ loss: 0.109, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  225\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.114, Train PHQ loss: 0.075, Train PTSD loss: 0.039 \n",
      "Val total loss: 0.155, Val PHQ loss: 0.108, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  226\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.114, Train PHQ loss: 0.075, Train PTSD loss: 0.039 \n",
      "Val total loss: 0.155, Val PHQ loss: 0.108, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  227\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.114, Train PHQ loss: 0.075, Train PTSD loss: 0.039 \n",
      "Val total loss: 0.155, Val PHQ loss: 0.108, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Train total loss: 0.114, Train PHQ loss: 0.075, Train PTSD loss: 0.039 \n",
      "Val total loss: 0.155, Val PHQ loss: 0.108, Val PTSD loss: 0.047 \n",
      "----------------------------------------------------------------------------------------------\n",
      "Epoch :  229\n",
      "Adjusting learning rate of group 0 to 3.2000e-07.\n",
      "Adjusting learning rate of group 1 to 3.2000e-07.\n",
      "Adjusting learning rate of group 2 to 3.2000e-07.\n",
      "Adjusting learning rate of group 3 to 3.2000e-08.\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 8360\n",
    "embedding_dim = 300\n",
    "hidden_dim = 128\n",
    "lr = 1e-3\n",
    "lr_phq = 1e-4\n",
    "epochs = 500\n",
    "batch_size = 32\n",
    "\n",
    "model = LSTM_Multi_Task(vocab_size, embedding_dim, hidden_dim, embed_matrix)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.Adam([{'params':model.lstm.parameters()},\n",
    "                            {'params':model.MLP.parameters()},\n",
    "                            {'params':model.ptsd_head.parameters()},\n",
    "                            {'params':model.phq_head.parameters(), 'lr':lr_phq}], lr=lr\n",
    "                            )\n",
    "\n",
    "criterion_phq = torch.nn.MSELoss().to(DEVICE) \n",
    "criterion_ptsd = torch.nn.MSELoss().to(DEVICE) \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(DepressionDataset(train_encoded, train_PHQ, train_PTSD), batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(DepressionDataset(val_encoded, val_PHQ, val_PTSD), batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(DepressionDataset(test_encoded, test_PHQ, test_PTSD), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "full_train_loader = torch.utils.data.DataLoader(torch.utils.data.ConcatDataset([DepressionDataset(train_encoded, train_PHQ, train_PTSD),DepressionDataset(val_encoded, val_PHQ, val_PTSD)]), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model, losses, early_stop = train(model, optimizer, criterion_phq, criterion_ptsd, full_train_loader, test_loader, epochs)\n",
    "\n",
    "if early_stop:\n",
    "    torch.save(model.state_dict(),CHECKPOINT+'multitask_bilstm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 372,
     "status": "ok",
     "timestamp": 1619052810934,
     "user": {
      "displayName": "Shubham Nagarkar",
      "photoUrl": "",
      "userId": "10621817079012605482"
     },
     "user_tz": 420
    },
    "id": "pz-NopUm2XDn",
    "outputId": "427f1366-2442-4e62-f666-207a6e6d2c2a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_training_curves(losses['train']['total'],losses['val']['total'], 'Multitask_loss', 'Multitask Loss', 229 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 490,
     "status": "ok",
     "timestamp": 1619052836684,
     "user": {
      "displayName": "Shubham Nagarkar",
      "photoUrl": "",
      "userId": "10621817079012605482"
     },
     "user_tz": 420
    },
    "id": "PyatEJMwBhGD",
    "outputId": "349e9a4a-bef6-4a92-cd97-bb8d083bc0bf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_training_curves(losses['train']['ptsd'],losses['val']['ptsd'], 'Multitask_PTSD_loss','Multi-task PTSD Loss', 229 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "executionInfo": {
     "elapsed": 364,
     "status": "error",
     "timestamp": 1619052863948,
     "user": {
      "displayName": "Shubham Nagarkar",
      "photoUrl": "",
      "userId": "10621817079012605482"
     },
     "user_tz": 420
    },
    "id": "Ocx_H2TmBpy5",
    "outputId": "565b3d9e-61ef-4c5c-c210-1b048f560ab7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_training_curves(losses['train']['phq'],losses['val']['phq'], 'Multitask_PHQ_loss', 'Multi-task PHQ Loss', 229 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_stats(model, filename, epochs):\n",
    "    f = open(GRAPHS+filename, 'w+')\n",
    "    f.write('Model Architecture: \\n'+str(model))\n",
    "    f.write('\\nEpochs: '+str(epochs))\n",
    "#     f.write('\\nlearning rate: '+str(lr))\n",
    "    f.write('\\nLearning rate PHQ head: '+str(lr_phq))\n",
    "    f.write('\\nLearning rate : '+str(lr))\n",
    "    f.close()\n",
    "\n",
    "write_stats(model,\"Multitask_details.txt\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),CHECKPOINT+'multitask_bilstm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "J2p1KDU2Jx7H"
   },
   "outputs": [],
   "source": [
    "class LSTM_Single_Task(torch.nn.Module) :\n",
    "    \"\"\"\n",
    "    LSTM architecture for Single task\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, glove_weights) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(glove_weights))\n",
    "        self.embeddings.weight.requires_grad = False\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=2, dropout=0.4, bidirectional=True)\n",
    "\n",
    "\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(hidden_dim,32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, sentence, sentence_length):\n",
    "        sentence_embed = self.embeddings(sentence)\n",
    "        sentence_embed = self.dropout(sentence_embed)\n",
    "\n",
    "        sentence_pack = pack_padded_sequence(sentence_embed, sentence_length, batch_first=True, enforce_sorted=False)\n",
    "        out_pack, (ht, ct) = self.lstm(sentence_pack)\n",
    "        task_op = self.MLP(ht[-1])\n",
    "        return torch.squeeze(task_op, 1)\n",
    "# nn.Linear(hidden_dim,64),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(64, 1),\n",
    "#             nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ROl81ENeKMxz"
   },
   "outputs": [],
   "source": [
    "def train_single_task(task, model, optimizer, criterion, train_loader, val_loader, epochs):\n",
    "    \"\"\"\n",
    "    returns trained model along with lossess and accuracies per epoch for single task\n",
    "    :params: model - LSTM model\n",
    "             optimizer - Adam optimizer\n",
    "             criterion_phq, criterion_ptsd - MSE Loss functions\n",
    "             train, val loaders - input data and labels\n",
    "             epochs - number of epochs to train the model\n",
    "    \"\"\"\n",
    "    epoch_train_loss = []\n",
    "    epoch_val_loss = []\n",
    "    losses = {'train':[], 'val':[]}\n",
    "    used_early_stopping = False\n",
    "    print(\"Training started...\\n\")\n",
    "\n",
    "    model.to(DEVICE)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1, last_epoch=-1, verbose=True)\n",
    "    early_stop = EarlyStopping(patience=12, path='singletask_{}_early_stopping_model.pth'.format(task))\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        total = 0\n",
    "        correct =  0\n",
    "        print(\"Epoch : \", epoch+1)\n",
    "        model.train()\n",
    "        for sentence, length, phq_score, ptsd_score in train_loader:\n",
    "            sentence = sentence.to(DEVICE).long()\n",
    "            phq_score = phq_score.to(DEVICE).type(torch.float32)\n",
    "            ptsd_score = ptsd_score.to(DEVICE).type(torch.float32)\n",
    "            if task == 'PHQ':\n",
    "                label = phq_score\n",
    "            else:\n",
    "                label = ptsd_score\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            task_op = model(sentence, length)\n",
    "\n",
    "            loss = criterion(task_op, label)\n",
    "            loss.backward()\n",
    "            \n",
    "            epoch_train_loss.append(loss.item())\n",
    "            optimizer.step()\n",
    "      \n",
    "        train_loss = np.average(epoch_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total = 0\n",
    "        correct =  0\n",
    "        with torch.no_grad():\n",
    "            for sentence, length, phq_score, ptsd_score in val_loader:\n",
    "                sentence = sentence.to(DEVICE).long()\n",
    "                phq_score = phq_score.to(DEVICE).type(torch.float32)\n",
    "                ptsd_score = ptsd_score.to(DEVICE).type(torch.float32)\n",
    "                if task == 'PHQ':\n",
    "                    label = phq_score\n",
    "                else: \n",
    "                    label = ptsd_score\n",
    "        \n",
    "                task_op = model(sentence, length)\n",
    "\n",
    "                loss = criterion(task_op, label)\n",
    "        \n",
    "                epoch_val_loss.append(loss.item())\n",
    "\n",
    "        val_loss = np.average(epoch_val_loss)\n",
    "\n",
    "        scheduler.step()\n",
    "        early_stop(val_loss, model)\n",
    "\n",
    "\n",
    "        print(\"Train loss: {0:.3f} Val loss: {1:.3f}\".format(train_loss, val_loss))\n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "\n",
    "        if early_stop.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            used_early_stopping  = True\n",
    "            break\n",
    "\n",
    "        losses['train'].append(train_loss) \n",
    "        losses['val'].append(val_loss) \n",
    "\n",
    "    return model, losses, used_early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41980,
     "status": "ok",
     "timestamp": 1619050145071,
     "user": {
      "displayName": "Shubham Nagarkar",
      "photoUrl": "",
      "userId": "10621817079012605482"
     },
     "user_tz": 420
    },
    "id": "ECbzu6k0MR-j",
    "outputId": "fdb0c7dd-c808-4e44-c9b9-909825259030",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch :  1\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.196 Val loss: 0.200\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  2\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.183 Val loss: 0.209\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  3\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.186 Val loss: 0.212\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  4\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.178 Val loss: 0.214\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  5\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.177 Val loss: 0.215\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  6\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.178 Val loss: 0.215\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  7\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.175 Val loss: 0.207\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  8\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.171 Val loss: 0.190\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  9\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.169 Val loss: 0.179\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  10\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.160 Val loss: 0.171\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  11\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.154 Val loss: 0.160\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  12\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.149 Val loss: 0.153\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  13\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.143 Val loss: 0.150\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  14\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.138 Val loss: 0.146\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  15\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.133 Val loss: 0.143\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  16\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.129 Val loss: 0.141\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  17\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.124 Val loss: 0.139\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  18\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.120 Val loss: 0.141\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  19\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.116 Val loss: 0.146\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  20\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.113 Val loss: 0.147\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  21\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.109 Val loss: 0.146\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  22\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.106 Val loss: 0.145\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  23\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.103 Val loss: 0.143\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  24\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.101 Val loss: 0.140\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  25\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.098 Val loss: 0.137\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  26\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.096 Val loss: 0.133\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  27\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.094 Val loss: 0.130\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  28\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.092 Val loss: 0.127\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  29\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.090 Val loss: 0.124\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  30\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.088 Val loss: 0.121\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  31\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.087 Val loss: 0.119\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  32\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.085 Val loss: 0.116\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  33\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.084 Val loss: 0.114\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  34\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.082 Val loss: 0.112\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  35\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.081 Val loss: 0.110\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  36\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.080 Val loss: 0.108\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  37\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.078 Val loss: 0.106\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  38\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.077 Val loss: 0.104\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  39\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.077 Val loss: 0.103\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  40\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.075 Val loss: 0.101\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  41\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.075 Val loss: 0.100\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  42\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.074 Val loss: 0.099\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  43\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.073 Val loss: 0.097\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  44\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.072 Val loss: 0.096\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  45\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.072 Val loss: 0.095\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.071 Val loss: 0.094\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  47\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.070 Val loss: 0.093\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  48\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.070 Val loss: 0.092\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  49\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Train loss: 0.069 Val loss: 0.091\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  50\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.068 Val loss: 0.090\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  51\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.067 Val loss: 0.089\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  52\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.067 Val loss: 0.088\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  53\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.066 Val loss: 0.087\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  54\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.066 Val loss: 0.086\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  55\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.065 Val loss: 0.086\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  56\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.065 Val loss: 0.085\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  57\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.064 Val loss: 0.084\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  58\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.064 Val loss: 0.083\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  59\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.063 Val loss: 0.083\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  60\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.063 Val loss: 0.082\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  61\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.062 Val loss: 0.081\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  62\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.062 Val loss: 0.081\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  63\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.061 Val loss: 0.080\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  64\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.061 Val loss: 0.080\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  65\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.061 Val loss: 0.079\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  66\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.060 Val loss: 0.079\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  67\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.060 Val loss: 0.078\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  68\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.059 Val loss: 0.078\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  69\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.059 Val loss: 0.077\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  70\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.059 Val loss: 0.077\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  71\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.058 Val loss: 0.076\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  72\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.058 Val loss: 0.076\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  73\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.058 Val loss: 0.075\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  74\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Train loss: 0.057 Val loss: 0.075\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  75\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.057 Val loss: 0.074\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  76\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.057 Val loss: 0.074\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  77\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.057 Val loss: 0.073\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  78\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.056 Val loss: 0.073\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  79\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.056 Val loss: 0.073\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  80\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.056 Val loss: 0.072\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  81\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.056 Val loss: 0.072\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  82\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.055 Val loss: 0.072\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  83\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.055 Val loss: 0.071\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  84\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.055 Val loss: 0.071\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  85\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.055 Val loss: 0.071\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  86\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.055 Val loss: 0.070\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  87\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.054 Val loss: 0.070\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  88\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.054 Val loss: 0.070\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  89\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.054 Val loss: 0.069\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  90\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.054 Val loss: 0.069\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.053 Val loss: 0.069\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  92\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.053 Val loss: 0.068\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  93\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.053 Val loss: 0.068\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  94\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.053 Val loss: 0.068\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  95\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.053 Val loss: 0.068\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  96\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.053 Val loss: 0.067\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  97\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.052 Val loss: 0.067\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  98\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.052 Val loss: 0.067\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  99\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Train loss: 0.052 Val loss: 0.067\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  100\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.052 Val loss: 0.066\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  101\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.052 Val loss: 0.066\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  102\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.051 Val loss: 0.066\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  103\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.051 Val loss: 0.066\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  104\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.051 Val loss: 0.065\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  105\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.051 Val loss: 0.065\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  106\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.051 Val loss: 0.065\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  107\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.051 Val loss: 0.065\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  108\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.051 Val loss: 0.065\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  109\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.050 Val loss: 0.064\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  110\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.050 Val loss: 0.064\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  111\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.050 Val loss: 0.064\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  112\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.050 Val loss: 0.064\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  113\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.050 Val loss: 0.064\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  114\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.050 Val loss: 0.063\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  115\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.049 Val loss: 0.063\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  116\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.049 Val loss: 0.063\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  117\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.049 Val loss: 0.063\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  118\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.049 Val loss: 0.063\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  119\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.049 Val loss: 0.063\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  120\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.049 Val loss: 0.062\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  121\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.049 Val loss: 0.062\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  122\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.049 Val loss: 0.062\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  123\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.049 Val loss: 0.062\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  124\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "Train loss: 0.049 Val loss: 0.062\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  125\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.048 Val loss: 0.062\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  126\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.048 Val loss: 0.061\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  127\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.048 Val loss: 0.061\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  128\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.048 Val loss: 0.061\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  129\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.048 Val loss: 0.061\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  130\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.048 Val loss: 0.061\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  131\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.048 Val loss: 0.061\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  132\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.048 Val loss: 0.061\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  133\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.048 Val loss: 0.060\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  134\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.047 Val loss: 0.060\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  135\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.047 Val loss: 0.060\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.047 Val loss: 0.060\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  137\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.047 Val loss: 0.060\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  138\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.047 Val loss: 0.060\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  139\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.047 Val loss: 0.060\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  140\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.047 Val loss: 0.060\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  141\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.047 Val loss: 0.059\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  142\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.047 Val loss: 0.059\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  143\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.047 Val loss: 0.059\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  144\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.047 Val loss: 0.059\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  145\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.047 Val loss: 0.059\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  146\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.047 Val loss: 0.059\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  147\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.046 Val loss: 0.059\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  148\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.046 Val loss: 0.059\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  149\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "Train loss: 0.046 Val loss: 0.059\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  150\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.046 Val loss: 0.058\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  151\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.046 Val loss: 0.058\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  152\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.046 Val loss: 0.058\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  153\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.046 Val loss: 0.058\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  154\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.046 Val loss: 0.058\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  155\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.046 Val loss: 0.058\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  156\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.046 Val loss: 0.058\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  157\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.046 Val loss: 0.058\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  158\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.046 Val loss: 0.058\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  159\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.046 Val loss: 0.058\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  160\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.046 Val loss: 0.057\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  161\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.046 Val loss: 0.057\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  162\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.046 Val loss: 0.057\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  163\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.046 Val loss: 0.057\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  164\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.045 Val loss: 0.057\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  165\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.045 Val loss: 0.057\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  166\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.045 Val loss: 0.057\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  167\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.045 Val loss: 0.057\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  168\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.045 Val loss: 0.057\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  169\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.045 Val loss: 0.057\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  170\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.045 Val loss: 0.057\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  171\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.045 Val loss: 0.056\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  172\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.045 Val loss: 0.056\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  173\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.045 Val loss: 0.056\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  174\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "Train loss: 0.045 Val loss: 0.056\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  175\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.045 Val loss: 0.056\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  176\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.045 Val loss: 0.056\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  177\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.045 Val loss: 0.056\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  178\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.045 Val loss: 0.056\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  179\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.045 Val loss: 0.056\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  180\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.045 Val loss: 0.056\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.045 Val loss: 0.056\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  182\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.056\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  183\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.056\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  184\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.056\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  185\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.055\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  186\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.055\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  187\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.055\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  188\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.055\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  189\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.055\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  190\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.055\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  191\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.055\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  192\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.055\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  193\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.055\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  194\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.055\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  195\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.055\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  196\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.055\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  197\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.055\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  198\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.055\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  199\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "Train loss: 0.044 Val loss: 0.055\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  200\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.044 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  201\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.044 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  202\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.044 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  203\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.044 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  204\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.044 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  205\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  206\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  207\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  208\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  209\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  210\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  211\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  212\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  213\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  214\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  215\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  216\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  217\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  218\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.054\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  219\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  220\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  221\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  222\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  223\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  224\n",
      "Adjusting learning rate of group 0 to 1.0000e-10.\n",
      "Train loss: 0.043 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  225\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.043 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.043 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  227\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.043 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  228\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.043 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  229\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.043 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  230\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.043 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  231\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.043 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  232\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.043 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  233\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.043 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  234\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.042 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  235\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.042 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  236\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.042 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  237\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.042 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  238\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.042 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  239\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.042 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  240\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.042 Val loss: 0.053\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  241\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.042 Val loss: 0.052\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  242\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.042 Val loss: 0.052\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  243\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.042 Val loss: 0.052\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  244\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.042 Val loss: 0.052\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  245\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.042 Val loss: 0.052\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  246\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.042 Val loss: 0.052\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  247\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.042 Val loss: 0.052\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  248\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.042 Val loss: 0.052\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  249\n",
      "Adjusting learning rate of group 0 to 1.0000e-11.\n",
      "Train loss: 0.042 Val loss: 0.052\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  250\n",
      "Adjusting learning rate of group 0 to 1.0000e-12.\n",
      "Train loss: 0.042 Val loss: 0.052\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 8360 #6176\n",
    "embedding_dim = 300\n",
    "hidden_dim = 128\n",
    "lr = 1e-2\n",
    "epochs = 250\n",
    "batch_size = 64\n",
    "task = \"PTSD\"\n",
    "model_task = LSTM_Single_Task(vocab_size, embedding_dim, hidden_dim, embed_matrix)\n",
    "optimizer = torch.optim.Adam(model_task.parameters(), lr=lr)\n",
    "criterion = torch.nn.MSELoss().to(DEVICE) \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(DepressionDataset(train_encoded, train_PHQ, train_PTSD), batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(DepressionDataset(val_encoded, val_PHQ, val_PTSD), batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(DepressionDataset(test_encoded, test_PHQ, test_PTSD), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "full_train_loader = torch.utils.data.DataLoader(torch.utils.data.ConcatDataset([DepressionDataset(train_encoded, train_PHQ, train_PTSD),DepressionDataset(val_encoded, val_PHQ, val_PTSD)]), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model_task, losses, early_stop = train_single_task('PTSD', model_task, optimizer, criterion, full_train_loader, test_loader, epochs)\n",
    "\n",
    "\n",
    "torch.save(model_task.state_dict(), 'singletask_'+task+'_bilstm.pth')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 506,
     "status": "ok",
     "timestamp": 1619050183341,
     "user": {
      "displayName": "Shubham Nagarkar",
      "photoUrl": "",
      "userId": "10621817079012605482"
     },
     "user_tz": 420
    },
    "id": "V9DzgizeMnu7",
    "outputId": "96939313-83d4-45db-b2f1-dd2614a8425c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "draw_training_curves(losses['train'],losses['val'], 'Singletask_PHQ_loss', 'Single-task PHQ Loss', 250 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_stats(model_task,\"Singletask_details.txt\", 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 684,
     "status": "ok",
     "timestamp": 1619045030004,
     "user": {
      "displayName": "Shubham Nagarkar",
      "photoUrl": "",
      "userId": "10621817079012605482"
     },
     "user_tz": 420
    },
    "id": "Bg-MNQ39VSjt",
    "outputId": "2161b1ee-1838-453c-fb6d-539a6ff88802"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is :  0.04228932037949562\n"
     ]
    }
   ],
   "source": [
    "def evaluate_single_task(task, model, criterion, test_loader):\n",
    "    \"\"\"\n",
    "    returns predictions on test dataset with the best trained model for single task\n",
    "    :params: task - PHQ/PTSD\n",
    "             model - trained model\n",
    "             test_loader - test dataset\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    actual = []\n",
    "    model.eval()\n",
    "    loss = []\n",
    "    with torch.no_grad():\n",
    "        for sentence, length, phq_score, ptsd_score in test_loader:\n",
    "            sentence = sentence.to(DEVICE).long()\n",
    "            phq_score = phq_score.to(DEVICE).type(torch.float32)\n",
    "            ptsd_score = ptsd_score.to(DEVICE).type(torch.float32)\n",
    "            if task == 'PHQ':\n",
    "                label = phq_score\n",
    "            else: \n",
    "                label = ptsd_score\n",
    "            \n",
    "            ptsdop = model(sentence, length)\n",
    "            \n",
    "            loss_val = criterion(ptsdop, label)\n",
    "            loss.append(loss_val.item())\n",
    "            output.extend(ptsdop.cpu().tolist())\n",
    "            actual.extend(label.cpu().tolist())\n",
    "    \n",
    "    print(\"Loss is : \", np.average(loss))\n",
    "    return actual, output\n",
    "\n",
    "task = \"PTSD\"\n",
    "phq_model  = 'temp_models/singletask_PHQ_early_stopping_model.pth'\n",
    "ptsd_model = 'temp_models/singletask_PTSD_early_stopping_model.pth'\n",
    "if task == \"PHQ\":\n",
    "    path =  phq_model\n",
    "else:\n",
    "    path = ptsd_model\n",
    "    \n",
    "loaded_model = LSTM_Single_Task(vocab_size, embedding_dim, hidden_dim, embed_matrix).to(DEVICE)\n",
    "loaded_model.load_state_dict(torch.load(path))\n",
    "criterion = torch.nn.MSELoss()\n",
    "actual, preds = evaluate_single_task(task, loaded_model, criterion, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_phq(label, split):\n",
    "    \"\"\"\n",
    "    converts probabilites into classes\n",
    "    :params: label - class probabilities (actual/predicted)\n",
    "             split - 2 way split (yes/no) or 3 way split (no/moderate/severe)\n",
    "    \"\"\"\n",
    "    final_label = []\n",
    "    \n",
    "    if split == \"Three\":\n",
    "        for val in label:\n",
    "            if val <= 0.434:\n",
    "                final_label.append(\"No\")\n",
    "            elif val >0.4340 and val <= 0.608:\n",
    "                final_label.append(\"Moderate\")\n",
    "            else:\n",
    "                final_label.append(\"Severe\")\n",
    "    else:\n",
    "        for val in label:\n",
    "            if val <= 0.434:\n",
    "                final_label.append(\"No\")\n",
    "            else:\n",
    "                final_label.append(\"Yes\")         \n",
    "    \n",
    "    return final_label\n",
    "\n",
    "def classify_ptsd(label):\n",
    "    \"\"\"\n",
    "    converts probabilites into classes\n",
    "    :params: label - class probabilities (actual/predicted)\n",
    "    \"\"\"\n",
    "    final_label = []\n",
    "    \n",
    "    for val in label:\n",
    "        if val < 0.39:\n",
    "            final_label.append(\"No\")\n",
    "        else:\n",
    "            final_label.append(\"Yes\")\n",
    "    \n",
    "    return final_label\n",
    "\n",
    "            \n",
    "def print_accuracy(true_label, predicted_label):   \n",
    "    \"\"\"\n",
    "    prints accuracy of the task\n",
    "    :params: true_label - actual labels of the dataset\n",
    "             predicted_label - predictions from model\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x,y in zip(true_label, predicted_label):\n",
    "        if x == y:\n",
    "            correct+=1\n",
    "        total+=1\n",
    "        \n",
    "    print(\"Accuracy: \", correct/total)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6170212765957447\n",
      "[[19  5]\n",
      " [13 10]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_label = classify_ptsd(actual)\n",
    "pred_label = classify_ptsd(preds)\n",
    "\n",
    "print_accuracy(true_label, pred_label)\n",
    "plot_cm(true_label, pred_label, [\"No\", \"Yes\"], \"PTSD Confusion Matrix\", \"Singletask_\"+task, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "two_true_label = classify_phq(actual, 'Two')\n",
    "three_true_label = classify_phq(actual, 'Three')\n",
    "\n",
    "two_pred_label = classify_phq(preds, 'Two')\n",
    "three_pred_label = classify_phq(preds, 'Three')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7021276595744681\n",
      "[[29  4]\n",
      " [10  4]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_accuracy(two_true_label, two_pred_label)\n",
    "plot_cm(two_true_label, two_pred_label, [\"No\", \"Yes\"], \"PHQ Binary Confusion Matrix\", \"Singletask_\"+task, \"Binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6382978723404256\n",
      "[[ 1  4  0]\n",
      " [ 3 29  1]\n",
      " [ 3  6  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAEWCAYAAACg+rZnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzhElEQVR4nO3dd5wU9f3H8df79kA6SD26CFgQlQCC2CgKQixYsJDYNYQklhTzM4m9oSYaNbEgUURjN6hBREVRBDuggEIsiEg/ehWFu/v8/pg52Dvubvdg526X+zx9zIOdme98v9+5XT/73e985zsyM5xzzqW3rMqugHPOucQ8WDvnXAbwYO2ccxnAg7VzzmUAD9bOOZcBPFg751wG8GDtSiVpk6R9K7seu0vS/pI+lbRR0uW7kc9ISdemsm6VYU95X6saD9YpJGmBpC3h/wy5kh6VVCfcN1nSJcXS95G0uNi2EyV9LGmzpNWSnpDUspTyRoZlbZK0VdK2uPVXy1n3nepnZnXMbH558tlVkqpLukHS1+G5L5A0WtI+Kcj+/4DJZlbXzP6xq5mY2XAzuzkF9SkiPG8r/kUi6bfh9huSzGen97AkFfm+utTxYJ16J5lZHaArcBhwTbIHShoCPAXcCzQGDgK2AlMlNSiePgwedcLyRgDPFq6b2aAky5SklH4OJGXvwmH/AU4GfgbUBw4FZgDHpqBKbYE5KcgnSl8B5xfbdl64PSV28X1xacKDdUTMbAnwKtA5mfSSBNwF3GJmT5rZFjNbDlwCfA9cUZ7yJR0u6X1J6yTNktQnbt9kSbdKei/M+9/A0cB9Yav8vjCdSeoQvj4h7ErYIGlRfGtP0j5h2oslLQTekvSKpMuK1Wm2pFNKqOtxQH9gsJlNM7M8M1tvZveb2SNhmhaSxklaI2mepF/EHX+DpOckPR52dcyR1D3c9xbQN+7c9iveApV0gaR3C98HSXdLWiFpfVjnzuG+MZJuiTvuF2Fd1oR1axG3zyQND38prJV0f/gel2YaUEvSQeHxBwE1w+2Fee4tabyklWGe4yW1CvfdWsZ7+BtJXwNfx7+v4a+ZmYXvk6SYpPckXVdGPV0l8WAdEUmtgZ8CnyZ5yP5AG+D5+I1mVgCMBQaUo+yWwCvALUBD4EpgrKQmccnOBYYBdYELgKnApWGr/NISst1M0NJrAJwA/KqEwNsbOBA4HngMOCeuTocCLYEJJeR9HPCxmS0q47SeBhYDLYAhwAhJ8a3uk4FnwvqNA+4DMLN+xc4tUUt1AHAMsF+Y11nA6uKJJPUDbgPOBJoD34XlxzuR4NfVoWG64xOU/W+CvzEErezHi+3PAh4l+KXQBtjCjvO8mtLfw1OAnkCn+MzMbCvBe3STpAOBPwEx4NYE9XSVwIN16r0kaR3wLvAOQfdEoX+ELd11YZrxcfsah/8uKyHPZUCTEraX5hxggplNMLMCM3sDmE7w5VFojJnNCVux2xJlaGaTzeyzML/ZBMGzd7FkN5jZZjPbAvwX6CipY7jvXIJumq0lZN+Iks8b2P7FdxRwlZn9YGYzgYfDPAu9G55vPkHQOzTROZViG8EX2AGAzOx/ZlZS3X4OjDazT8zsR+DPQK9ifey3m9k6M1sIvA10SVD2E8BQSdWAs8P17cxstZmNNbPvzWwjQVAt/h6U5DYzWxO+L0WY2ecEX+ovEnypnxv+DV2a8WCdeqeYWQMza2tmvy72P8jl4b4GZtaAoOVVaFX4b/MS8mwOrCxHHdoCZxT7YjiqWN5ltWJ3IqmnpLfDn+DrgeHs+ILZKc8wgD0HnBP2iQ8lCKIlWU3J512oBbAmDFCFviNoqRdaHvf6e6DGrvTRmtlbBK3V+4FcSaMk1SulTt/FHbeJ4DzKqlOdBGUvBOYRfMF/XfyXhqRakh6S9J2kDcAUoIGkWILTSvRePwbsQ/AF/3WCtK6SeLBOH18S/Mw/I35jGOhOJ2ilJ2sR8O/4LwYzq21mt8elKT7dYqLpF58i6F5obWb1gZFA8T7Y4nk8RtACPRb43sw+KCXvN4Eehf2vJVgKNJRUN25bG2BJgjqXZjNQK249J36nmf3DzLoRXODdD/hjKXVqW7giqTbBL4RdrVOhx4E/sHMXCOH2/YGeZlaPoLsGdrwPpb2Hid7bBwh+5R0v6ajyVddVFA/WacKCuWqvBK6R9DNJNSXlEPzcbwz8sxzZPQGcJOn48KJRDQXDBEsLhgC5QFljb+sStG5/kNSDYNRGmcLgXEBw4bS0VjVm9ibwBvCipG6SsiXVDS/QXRS2MN8HbgvP5RDgYuDJRHUoxUzgtLCl2iHMCwBJh4W/IqoRBPUfgJK6BZ4CLpTURdJeBK3hj8xswS7WqdCzBP3mz5Wwry5BP/U6SQ2B64vtT/Qe7kTSuUA3gusWlwOPKRxu6tKLB+s0YmbPEvTD/o7gJ/UyggtUvUvpNy0tn0XAYOAvBN0niwhah2W93/cCQ8JRBiWNRf41wYWojcB1lBxMSvI4cDDF+l9LMITg4uOzwHrgc6A7Qasbgm6UfQhatC8C14d98bviboIhkbkErf/4oF8P+BewlqCbYzVwZ/EMzGwScC3Bxd9lQHuCfubdEo4CerOk/mXgHoIRIquAD4HXiu1P9B4WIalNmOd5ZrbJzJ4iuLZx926cgouI/OED6UvSAIILeceGF9UyjqTzgGFm5j+vndsN3rJOY2Y2keDn6eGVXJVdIqkWQYt8VGXXxblM5y1rFwlJxwMvEHRjnG5meZVcJecymgdr55zLAN4N4pxzGSBtJ3b5dPV4b/JH7OS+n1R2FfZ4i2bv9gARl5T9ypp3JSk12wxNOuZsWfj0bpdXXt6yds65DJC2LWvnnKtIKZ4pOOU8WDvnHJCV5tN9p3ftnHOugnjL2jnnMkDZz4aofB6snXMOSPfxFh6snXMO7wZxzrmM4MHaOecygI8Gcc65DOAta+ecywAerJ1zLgNop0eKphcP1s45h7esnXMuI2RlpXc4TO/aOedchfGWtXPOpb107wZJ79o551wFkbKSXhLnpYGSvpQ0T9KfSthfX9LLkmZJmiPpwkR5erB2zjlAZCW9lJmPFAPuBwYBnYChkjoVS/YbYK6ZHQr0Ae6SVL2sfL0bxDnnSGk3SA9gnpnND/LVM8BgYG5cGgPqKpjqrw6wBsgrK1MP1s45B2RlxZJOK2kYMCxu0ygzGxW+bgksitu3GOhZLIv7gHHAUqAucJaZFZRVpgdr55yDhN0b8cLAPKqU3SXdXVP8YbzHAzOBfkB74A1JU81sQ2llep+1c86R0guMi4HWceutCFrQ8S4EXrDAPOBb4ICyMvVg7ZxzpDRYTwM6SmoXXjQ8m6DLI95C4NigXDUD9gfml5Wpd4M45xzl6wYpi5nlSboUeB2IAaPNbI6k4eH+kcDNwBhJnxF0m1xlZqvKyteDtXPOAUrh7eZmNgGYUGzbyLjXS4EB5cnTg7VzzuEPzHXOuYyQqm6QqHiwds450n9uEA/WzjkH4N0gzjmXAdK7Ye3B2jnnAMhK72jtwToJMz/8gsfueYmC/AL6ndSTwecdW2T/u6/PYNwTbwOwV83qXPLHIbTt2CKpY90OfY5szw1XHU8sK4unX/iUB0a/V2R/3Tp7ce9tp9Iypx6xWBajHvuA5/47K6ljXWDKlBnceuu/KCgo4Iwz+jNs2BlF9psZt946infemUGNGntx++1XcNBBHZI6NuOld6xO9+pVvoL8Akbf+QJ/uusX3PXU//Hem5+y+NvlRdI0adGQ6+7/NX/995WcdmF/Rt3xfNLHukBWlrjlL4M471dP0e+UBxg86CA67tu4SJrzzz6Mr79ZyfFnjOLMix/n2isHUC07K6ljHeTn53PTTSN5+OEbeOWV+xk/fgrz5i0skmbKlBksWLCUiRMf4uabf8MNNzyY9LGZzqSkl8rgwTqBeXMXktOqEc1aNiK7WjZHHPcTpk+dUyTN/ge3o069WgB0PKgta1asS/pYF+jSuSULFq5l4ZJ1bMsrYNxrcxjQd/8iacyMOrWDKX9r16rOuvVbyMsvSOpYB7Nnf03bts1p3TqH6tWrccIJxzBp0kdF0kya9CGnnNIPSXTpcgAbNmxmxYo1SR2b8VSOpRJ4sE5gzcr1NGrWYPt6wyb1WbNyfanp3x7/EV16HbBLx1ZlOc3qsjR3x99mWe4GcprWLZJmzNPT6NCuCdMn/Y43xg7n+jtexyy5Yx3k5q4mJ2fHL45mzRqRm7u6zDQ5OUGaZI7NeFlKfqmM6kWZuaRmkh6R9Gq43knSxVGWWRFK+xU0Z8Y83n75Y3726xPLfWxVV+KcksUmlex9ZHvmfrmc7sfezcAzHuLmvwykTu3qSR3rgl8mxRW/a6+kv5ukpI7NeFLySyWIumU9hmAykxbh+lfAb0tLLGmYpOmSpo997LWIq5achk3qszp33fb1NSvXs3fj+jul+27eUh667TmuvOMi6tavXa5jHSzL3UiLZjv+Ns2b1SN35cYiac4c3IVXJ30BwIJFa1m0ZB0d2jVO6lgHOTmNWb58x1xBubmradq0YbE0jYqkWb48SJPMsRkvpuSXShB1sG5sZs8BBRDMRgXkl5bYzEaZWXcz6376+QMjrlpy2h/YmuWLV7Fi6WrytuXx/puf0u2og4qkWbV8LX//8xh+c/1QWrRpUq5jXWDWnCXs07YhrVs2oFp2FicPPIg3Jn9VJM3S5es5smc7ABo3rE37to34bvHapI51cPDBHVmwYCmLFi1n69ZtvPLKFPr161EkTb9+PXnppbcwM2bO/IK6dWvRtGnDpI7NeGneso566N5mSY0In5Ig6XAgozptY9kxLvz9aYz43SgK8o2+J/ag9b45vPHi+wD0P/UIxj46kU0bvmf0nS8Ex8SyGDH6d6Ue63aWn29cO+JVnnjw58Ri4tmXZvLVNys554xuADzx/AzufWgKf795MG+M/SWSGHHPJNau2wJQ4rGuqOzsGNddN5xLLrme/PwCTj/9ODp2bMvTT78KwNChg+jduzvvvDOd/v2HUbPmXowYcUWZx+5R0rxXRyX1RaUsc6kr8E+gM/A50AQ4w8xmJTr209XjvdcxYif3/aSyq7DHWzT77MquQhWx326H2o4DRycdc75+7aIKD+1Rt6znAL0JnoIg4Et8BIpzLh2lMPxKGgjcS/DwgYfN7PZi+/8I/DxczQYOBJqY2ZrS8ow6cH5gZnlmNsfMPjezbcAHEZfpnHPlZrGspJeySIoB9wODgE7AUEmdipRl9jcz62JmXYA/A++UFaghopa1pByCx7HXlPQTdnxn1QNqRVGmc87tltS1rHsA88xsPoCkZ4DBwNxS0g8Fnk6UaVTdIMcDFxA81ffvcds3An+JqEznnNt1qRvl0RJYFLe+GOhZcpGqBQwELk2UaSTB2sweAx6TdLqZjY2iDOecS6ly3JkoaRgwLG7TKDMbVbi7hENKu3h5EvBeoi4QiPgCo5mNlXQCcBBQI277TVGW65xz5VaOhnUYmEeVsnsx0DpuvRWwtJS0Z5NEFwhEf7v5SOAs4DKCP8UZwB42ONM5t0dI3U0x04COktpJqk4QkMftXJzqE4yW+28y1Yt6NMgRZnYesNbMbgR6UfQbxznn0kOKbjcP79S+lGCqjf8Bz5nZHEnDJQ2PS3oqMNHMNidTvajHWf8Q/vu9pBbAaqBdxGU651z5pfA2cjObAEwotm1ksfUxBPMnJSXqYP2ypAbA34BPCDrZ/xVxmc45V35pfrt5ZMFawXPdJ5nZOmCspPFADTPLqLlBnHNVg1XSPNXJiqzP2swKgLvi1n/0QO2cS1tpPute1BcYJ0o6XXvcLOXOuT1Omj/WK+o+698DtYF8SVsITtPMrF7E5TrnXPkkmPOjskV9U4w/CM85lxnS/Pd/1DfFSNI5kq4N11tL2sMeL+Gc2yNU5QfmAg8Q3Ajzs3B9E8HUgc45l17SPFhH3Wfd08y6SvoUwMzWhrdfOudcWrE07waJOlhvCyfiLnwGYxPCh+c651xaqcoXGIF/AC8CTSXdCgwBrom4TOecK780vykm6tEgT0qaARxLcK31FDP7X5RlOufcLknvhnVkj/VqGLe6grj5WiU1TGaibeecq1Bpfu9eVC3rGQT91ALaAGvD1w2AhfjMe865dFMVu0HMrB1sf/jAuHC6QCQNAo6LokznnNsdluYt66h7aQ4rDNQAZvYqwZMRnHMuvWQr+aUSRB2sV0m6RtI+ktpKuprgAQTOOZdeUjjrnqSBkr6UNE/Sn0pJ00fSTElzJL2TKM+oh+4NBa4nGL4HMCXc5pxz6SVFfdbhvSX3A/0JHp47TdI4M5sbl6YBwR3eA81soaSmifKNeujeGuAKSfWAAjPbFGV5zjm3y1LXu9EDmGdm8wEkPQMMBubGpfkZ8IKZLQQwsxWJMo16IqeDw1vNPwPmSJohqXOUZTrn3K6wLCW9SBomaXrcMiwuq5bAorj1xeG2ePsBe0uaHMbF8xLVL+pukIeA35vZ2xD00QCjgCMiLtc558qnHN0gZjaKIJaVpKSMrNh6NtCN4IbBmsAHkj40s69KKzPqYF27MFADmNlkSbUjLtM558ovlrJ+kMVA67j1VsDSEtKsMrPNwGZJU4BDgUoL1vPDuaz/Ha6fA3ybzIH71q0WWaVcYNU6v/M/atsKvq/sKlQJ1VLRoZu6cdbTgI6S2gFLgLPZMU10of8C90nKBqoDPYG7y8o06mB9EXAj8ALBT4MpwIURl+mcc+WXotEgZpYn6VLgdSAGjDazOZKGh/tHmtn/JL0GzCaYifRhM/u8rHyjHg2yFrg8yjKccy4lUni7eXgz4IRi20YWW/8b8Ldk84xqIqdxZe03s5OjKNc553ZVut9uHlXLuhfB0JWngY9I+0dROueqvNRdYIxEVME6h+DunaEEHeuvAE+b2ZyIynPOud2T5rPuRXJTjJnlm9lrZnY+cDgwD5gs6bIoynPOud1WVR+YK2kv4ASC1vU+BI/4eiGq8pxzbrekd8M6sguMjwGdgVeBGxMNSXHOucpmad4NElXL+lxgM8H975drx1VWAWZm9SIq1znndk1VHA1iZmn+6EnnnCumio4Gcc65jJKV5k1MD9bOOUfa94J4sHbOOfBg7ZxzGUFpHq09WDvnHN5n7ZxzGUEerJ1zLv2leS+IB2vnnIO0n8cp2qebO+dcppCSXxLnpYGSvpQ0T9KfStjfR9J6STPD5bpEeXrL2jnnSF03iKQYcD/BNNGLgWmSxpnZ3GJJp5rZicnm68HaOeeArNTdbt4DmGdm8wEkPQMMBooH63LxbhDnnKN83SCShkmaHrcMi8uqJcGTsgotDrcV10vSLEmvSjooUf28Ze2cc5SvG8TMRgGjSsuqpEOKrX8CtDWzTZJ+CrwEdCyrTG9ZO+ccKb3AuBhoHbfeClgan8DMNpjZpvD1BKCapMZlZVpqy1rSP9n52yC+sMsTVtk55zJECofuTQM6SmoHLAHOJngW7XaScoBcMzNJPQgazqvLyrSsbpDpu1df55zLHKkaDWJmeZIuBV4HYsBoM5sjaXi4fyQwBPiVpDxgC3C2mZXaOIYygrWZPZaaqjvnXPpL4WiQwq6NCcW2jYx7fR9wX3nyTHiBUVIT4CqgE1AjrrB+5SnIOefSWbrfbp7MBcYngf8B7YAbgQUEfTLOObfHSOUdjFFIJlg3MrNHgG1m9o6ZXQQcHnG9nHOuQqV7sE5mnPW28N9lkk4gGILSKroqOedcxUv3iZySCda3SKoP/AH4J1AP+F2ktXLOuQqWFavsGpQtYbA2s/Hhy/VA32irk54+eHcud93xAgX5BQw+rRfnX9K/yH4z467bx/L+1LnUqFGd6275OQd0CsbEP/PEZF4a+wFmximn92LouVXyT5iU/r0P5c4bziMWy2LMM29z5wPjiuyvV7cmo+/9Da1bNCY7O8Y9D43n38+/A8BlFw/igqH9MDPmfLGIYVeO5Mcft5VUTJX27tSZ3D5iDPkFBZw+pB+X/OKUIvvNjNtGjGHqlE+pUWMvbh3xKzodtC8//riV88+9ga1bt5GfV0D/43ty6WVnVs5JRCTdLzAmMxrkUUq4OSbsu97j5ecX8Ndbn+e+Ub+haU4Dzj/7To7u25l92zffnub9qXNZ9N1Kxr5yLZ/PXsAdtzzHo0/9gW++XspLYz9gzFN/ILtajCuGP8iRxxxEm7ZNK/GM0lNWlrjnlgs54ecjWLJsNe++fCvj35jBF18v2Z7ml+cN4IuvlzDkojtp3LAusyb/nWdeepcmDevx6wsH8pNjr+SHH7fxxANXcMZJvXjiP1Mq8YzST35+AbfcPJp/PXI1Oc0acdaZf6Zv3+6077CjV3PqlJks/G45E167l9mzvubmmx7h6WdvpXr1aox+9Dpq1a7Btm15nHfO9Rx9dBcO7bJfJZ5RaqX7MxiTucA4HnglXCYRdINsirJS6WTOZ9/Rqk0TWrZuTLVq2QwY1JUpb39WJM2Utz/jpyf3QBIHH9qOjRu3sGrler6dn0vnQ9pSo2Z1srNjdO3egcmTZlfSmaS3w7p04JsFy1mwcAXbtuXz/MsfcOKA7kXSGFCndk0Aateuwdp1m8jLKwAgOztGzRrVicWyqFmzOsty11b0KaS9z2bPo02bZrRu3Yxq1bMZ9NMjeOutogO73n5rGicPPgZJHNplPzZu2MzKFWuRRK3awcjdvLx88rblpX1wK690v8CYMFib2di45UngTKBzMplLaiXpRUkrJeVKGispoy5OrlyxjmY5DbavN23WgJW564ukWbFi/U5pVqxYT/uOzfl0xjesW7eZH7Zs5b2pc8ldvq5iKp5hWuTszeKlO+62XbJsNS2b7V0kzcgxr3NAhxbMn/4A0yf+lStveBwzY2nuWu4ZNZ6vPryPb6c/yIYN3zNp6mfFi6jyVqxYQ05Oo+3rzZo1YkWxL7Xc3LVF0+Q0InfFGiBomZ9+6v9xzFG/oNcRh3DIoWXOO5RxMj5Yl6Aj0CbJtI8C44DmBFMEvhxuK1H8tINjHp5QWrIKVeINoMXfrRISCWi3bw7nXXQclw27n8uHP0jH/VsSi/ncWSUpqZVW/M/av/chzJ77Hft2/zU9B/6Ju2+6gLp1atKgfm1O7N+dA4+8nH0P+zW1a+3F2aceVUE1zxwl3c2880e5pDRBolgsi7Ev/pVJbz/IZ5/N4+uvFkZSz8qS7sE6mT7rjRTts15OcEdjMpqYWXxwHiPpt6Uljp92cP3W18u8T76iNG3WoEhreEXuOpo0rZdEmvoADD6tF4NP6wXAA/e+TNNmDaKuckZasmwNrVrsaNG1bN6IpSuKtvrOPaMPdz34XwDmf5fLgkUr2b99C9q0asyCRStYtWYjAC+9No3Du+3HMy++W3EnkAGaNWvE8uU7fr3k5q6mSdOiv15ychoWTbN8NU2bFE1Tr15tDuvRiXffnUXH/ZJtt6W/7DRvRyXTDVLXzOrFLfuZ2dgk818l6RxJsXA5hwQzS6WbTp3bsOi7lSxZvJpt2/KY+OonHN3n4CJpju57MBPGfYyZ8dmsb6lTpwaNmwTBes3qIIAsX7aGt9+cxYBB3Sr8HDLB9Fnf0KFdDm1bN6FatRhnnNSLV96YUSTNoqWr6HNk0APXtHF99mvfnG8XrmDRklX06NqRmjWqA9D3yM58OW/JTmVUdZ0Pbs/C75azePEKtm3N49UJ79O3b9HrAn36dmfcf6dgZsya+RV16taiSdO9WbNmAxs2bAbghx+28uEHn9OuXYvKOI3IZMmSXipDMi3rSWZ2bKJtpbiIYLKSuwla5++H2zJGdnaMP/5lCJcPf4CC/AJOOvVw2ndoztjnglbb6WcexZFHd+L9KXM47ac3UaNGda695efbj7/q94+wYd1mYtkx/nj1GdSrX6uyTiWt5ecX8Ltrx/Dyv/9MLJbFY89O5n9fLeaSc44D4OEn3uT2f7zIqLuGM23iHUji6tueZvXajaxeu5EXJ3zEBxNGkJdfwKw5C3jkqUmVfEbpJzs7xl+uuYhfXjKC/IICTj2tDx06tubZZ94A4Kyz+3NM758wdcqnDDr+CmrWqM7NI34FwMqVa7n6zw+Qn1+AFRRw/MBe9Om7ZzU80v2mGJU2K5+kGkAt4G2gDzueflAPeNXMDoyyYunSDbIny+kwprKrsMfbsCDZHkO3O6plddntUHvCxHeTjjmvDDiqwkN7WS3rXwK/BVoAM9gRrDcQPLm3VAkeq25mdnM56uicc5GrrO6NZJU1n/W9wL2SLjOzf5Yz380lbKsNXAw0AjxYO+fSSrp3gyRz/bNAUoPCFUl7S/p1WQeY2V2FC8HojprAhcAzwL67UV/nnItEtpJfEpE0UNKXkuZJ+lMZ6Q6TlC9pSKI8kwnWvzCzdYUrZrYW+EUSlW0o6RZgNkELvquZXWVmK5Io0znnKpRkSS9l56MYQVfxIIKHtgyV1KmUdHcQPP4roWSCdZbi7lgIC6ieoLJ/I3hAwUbgYDO7IQzyzjmXlrKU/JJAD2Cemc03s60EPQqDS0h3GTAWSKoBm0ywfh14TtKxkvoBTwOvJjjmDwQXJq8BlkraEC4bJW1IpmLOOVeRssqxxN9tHS7D4rJqCSyKW18cbttOUkvgVGAkSUpmPuurgGHArwhGhHxKcPt4qcwsze8Fcs65osozGiT+busSlNT2Lp75PcBVZpaf7IRYycxnXSDpQ4ILg2cBDQma7s45t8dI5sJhkhYDrePWWxE8YSted+CZMFA3Bn4qKc/MXiq1fqXtkLQfcDYwlOAW8WcBzMxnz3fO7XFSOHRvGtBRUjtgCUEc/Vl8AjNrV/ha0hhgfFmBGspuWX8BTAVOMrN5Yab+OC/n3B4pVTfFmFmepEsJrvfFgNFmNkfS8HB/0v3U8coK1qcTfCO8Lek1giuaaT5s3Dnndk0qb4oxswnAhGLbSgzSZnZBMnmWeiHQzF40s7OAA4DJBA/JbSbpQUkDkqyzc85lhPKMBqms+pXJzDab2ZNmdiJBR/lMoNQ7cpxzLhNl/BSp8cxsDfBQuDjn3B4j3R8+UK5g7Zxze6o0j9UerJ1zDjJ4ilTnnKtK0n2KVA/WzjmHd4M451xG8Ja1c85lgFiW91k751za824Q55zLAD4axDnnMoD3WTvnXAbwYO2ccxmgmneDOOdc+kv3lnW6XwB1zrkKkcKnmyNpoKQvJc2TtNMspZIGS5otaWb4wN2jEuXpLWvnnANiKWpZS4oB9wP9CZ7HOE3SODObG5dsEjDOzEzSIcBzBM8OKJW3rJ1zjpS2rHsA88xsvpltJXjK1uD4BGa2ycwKO8lrs/PTz3fiLWvnnCOl46xbAovi1hcDPYsnknQqcBvQFDghYf1SVTvnnMtk1ZT8ImlY2NdcuAyLy6qktvdO3wThoxMPAE4Bbk5Uv7RtWd/5Wayyq7DHa3H0yZVdhT1etaxalV0Fl6TyjAYxs1HAqFJ2LwZax623ApaWkdcUSe0lNTazVaXWL/nqOefcniuFz2CcBnSU1E5SdeBsYFx8AkkdJCl83RWoDqwuK9O0bVk751xFStVoEDPLk3Qp8DoQA0ab2RxJw8P9I4HTgfMkbQO2AGfFXXAskQdr55wjtTfFmNkEYEKxbSPjXt8B3FGePD1YO+cc/nRz55zLCDGfG8Q559JfmjesPVg75xyk/0ROHqydcw4P1s45lxG8z9o55zKAjwZxzrkM4N0gzjmXAVJ1B2NUPFg75xwpnSI1Eh6snXMOH2ftnHMZwfusnXMuA1TL8m4Q55xLe96yds65DODB2jnnMkC6X2BM9/o551yFkJJfEuelgZK+lDRP0p9K2P9zSbPD5X1JhybK01vWzjlH6rpBJMWA+4H+BA/PnSZpnJnNjUv2LdDbzNZKGkTw8N2eZeXrwdo550hpN0MPYJ6ZzQeQ9AwwGNgerM3s/bj0HxI8Ab2i6uecc5lLsnIsGiZpetwyLC6rlsCiuPXF4bbSXAy8mqh+3rJ2zjmgPL0gZjaKoOsi2axKHMQtqS9BsD4qUZkerJ1zjuQuHCZpMdA6br0VsHTn8nQI8DAwyMxWJ8rUu0Gcc46gOZzsksA0oKOkdpKqA2cD44qUJbUBXgDONbOvkqmft6ydc47UTZFqZnmSLgVeB2LAaDObI2l4uH8kcB3QCHhAQZM+z8y6l5WvB2vnnCOl3SCY2QRgQrFtI+NeXwJcUp48PVg75xzlu8BYGTxYO+ccHqydcy4j+EROe4Bls+Yw8/H/YAUFtOt7JAeePKDI/iXTZ/H58+NRllBWjC7nnk6TAzqQv3Ubb990N/l5eVh+Pq16/oTOQ06spLNIf8cc0pxrz+1KLEs8O/kbHnr5fzul6XlgU645tyvZsSzWbvyRn90yiXbN6/KPy47cnqZ10zrc85/PGPPalxVZ/YwwZcoMbr31XxQUFHDGGf0ZNuyMIvvNjFtvHcU778ygRo29uP32KzjooA5JHZvp0jxWe7BOpKCggE8efY7ef76Mmo0a8OY1f6VF14Op36r59jRNO+/PgG6HIIl1C5fwwb2PMOiu68iqlk3vay6nWo0aFOTl89aNd9H80INo1LFdJZ5ResqSuOGCbpx/29ssX7OFF28ewKRPljBvyYbtaerWqsaNF3bnwjsms2z19zSqtxcA3y7byEl/eW17Pu/fN5iJ0xeVWE5Vlp+fz003jeTRR2+mWbNGDBnye/r160mHDm22p5kyZQYLFixl4sSHmDXrS2644UGef/6upI7NdOn+DEYfZ53AmnkLqNOsCXWaNSaWnU2bXt1YOmN2kTTVatQgHH5D3g8/bv+KlkS1GjUAKMjPpyC/IP2/vivJoe0b8l3uJhat3My2/ALGf7iQ47oVnS7h5CPaMnHaIpat/h6A1Rt+3CmfIzo3Y+GKTSxd9X2F1DuTzJ79NW3bNqd16xyqV6/GCSccw6RJHxVJM2nSh5xySj8k0aXLAWzYsJkVK9YkdWymS+Wse1HwlnUCW9auo1ajvbev12zYgDXzFuyUbvG0mXz2zDh+3LCRo/74q+3bCwoKePPq29m0fCXtB/SmUQdvVZekWcNa24MwwPI133No+0ZF0rTLqUd2tnjy6n7UqVmNMa99yYvvLiiS5sTD2/Ly+99VRJUzTm7uanJyGm9fb9asEbNnf1VmmpycRuTmrk7q2EyX7i3XSIO1pGbACKCFmQ2S1AnoZWaPRFluSpX0y6iEr9ZWh3Wh1WFdWPm/r/n8+fH0ufpyALKyshhw21/Yuvl73rt7FOsXLaV+6xYRVzrzlNhYKfa3j8VE53YNOXfEW9SoFuM/Nw7g03mrWbB8IwDVYlkc260lf3t2VuT1zURmO3+YVeyzXEISJCV1bKZL99OJ+stkDMFdPIXR6Svgt6Uljp/J6pMXXom4asmp2bAB369eu319y5p11Ny7fqnpmxzYkc0rVvHjhk1FtlevXYumB3Zk2ay5pRxZtS1f8z3NG9Xavp7TsBa567bslGbKrGVs+TGftZu28vEXKziwTYPt+3t3ac6cBWtYveGHiqp2RsnJaczy5au2r+fmrqZp04bF0jQqkmb58iBNMsdmuhTebh6JqIN1YzN7DiiA4DZMIL+0xGY2ysy6m1n3rqedEHHVktOwfVs2LV/BphWryM/LY+EHM2jR7eAiaTYuX7G95bH224UU5OVRvW5tftiwka2bg5/2eVu3kvv5l9Rr0azCzyETzJ6/hn1y6tKqSW2qxbI48fA2TJqxuEiaN2cs4bD9mxDLEjWqx+jSvhHfLN1xAfKkXt4FUpaDD+7IggVLWbRoOVu3buOVV6bQr1+PImn69evJSy+9hZkxc+YX1K1bi6ZNGyZ1bKbLUvJLZYi6z3qzpEaEP2glHQ6sj7jMlMqKxeh6wZlMuf3+YOhen17Ub9WCeW9OBaDDcUez+OOZfDf1I7KyY8SqVefwyy5CEj+s28DHDz6OFRRgZrQ+vCstuh6coMSqKb/AuHHMdMZc1YesLPGfd+bz9ZINDD02GDb29KR5fLN0A1NmL+OV2wdhBcazk+fz1eLg41SjeowjO+dw9SPTKvM00lp2dozrrhvOJZdcT35+AaeffhwdO7bl6aeDqZSHDh1E797deeed6fTvP4yaNfdixIgryjx2T5Lu46xVUl9UyjKXugL/BDoDnwNNgCFmNrvMA4FrZ7yZ3uNo9gBP/X1lZVdhj/fNk90quwpVxH67HWqXff9y0jGnea2TKjy0R9ayDp9D1jtc9ifo6vnSzLZFVaZzzu0qVdVx1maWDww2szwzm2Nmn3ugds6lq3S/wBh1n/V7ku4DngU2F240s08iLtc558ol3YfuRR2sjwj/vSlumwH9Ii7XOefKJVbZFUgg0mBtZn2jzN8551IllS1rSQOBewm+Ax42s9uL7T8AeBToClxtZncmyjPScdaSmkl6RNKr4XonSRdHWaZzzu2a1PRah4Mr7gcGAZ2AoeHd2/HWAJcDCYN0obS6g9E55yqLyvFfAj2AeWY238y2As8Ag+MTmNkKM5sGJD3oIq3uYHTOucoiZZVj2TE1RrgMi8uqJRA/R+/icNtu8TsYnXMOKM+gPDMbBYwqR0a7PYg76mD9B2Ac0F7Se4R3MEZcpnPOlZtS19GwGGgdt94KWLq7mUY9GmSGJL+D0TmX9qSUBetpQEdJ7YAlwNnAz3Y306jns55FcEPMs2b2TZRlOefc7knN2D0zy5N0KcHgihgw2szmSBoe7h8pKQeYDtQDCiT9FuhkZhtKyzfqbpCTgbOA5yQVEATu58xsYcTlOudcuSQxyiNpZjYBmFBs28i418sJukeSFuloEDP7zsz+ambdCH4GHAJ8G2WZzjm3K1I4dC8SkT+DUdI+wJkELex84P+iLtM558oruJclfUXdZ/0RUA14HjjDzOZHWZ5zzu269J7JKeqW9flm9kXEZTjn3G6rrO6NZEV9B+NanxvEOZcZssqxVE7tojQGnxvEOZcB0v0Co88N4pxzgKSkl8rgc4M45xygNH/8QNTB+vf43CDOuYxQBS8wSjpMUk74rMXewF+AH4GJBJOcOOdcWkn3bpCo+qwfAraGr48AriZ4csJaSp9W0DnnKlF6P988qm6QmJmtCV+fBYwys7HAWEkzIyrTOed2WQqnSI1EVLWLSSr8IjgWeCtuX+S3uDvnXPlVzZb108A7klYBW4CpAJI64KNBnHNpKCt181lHIpJgbWa3SpoENAcmmlnhI22ygMuiKNM553ZPFQzWAGb2YQnbvoqqPOec2x1VfW4Q55zLEKnrs5Y0UNKXkuZJ+lMJ+yXpH+H+2ZK6JsrTg7VzzpG6cdYKJsa+HxgEdAKGSupULNkgoGO4DAMeTFQ/D9bOOUdwu3mySwI9gHlmNt/MtgLPAIOLpRkMPG6BD4EGkpqXlWnaDqO7udtx6d2BVAJJw8wsY276ufnJyq5B+WXa3zgTVd2/8X5JxxxJwwhaxIVGxf3NWgKL4vYtBnoWy6KkNC2BZaWV6S3r1BqWOInbTf43jp7/jRMws1Fm1j1uif9yKynoW7H1ZNIU4cHaOedSazHQOm69FbB0F9IU4cHaOedSaxrQUVI7SdWBswlmH403DjgvHBVyOLDezErtAoE07rPOUFWwn6/C+d84ev433g1mlifpUoKnZMWA0WY2R9LwcP9IYALwU2Ae8D1wYaJ8tePmQuecc+nKu0Gccy4DeLB2zrkMUOWCtSST9O+49WxJKyWNL2c+CyQ1TlGdLpDUInHKqiN8n+6KW79S0g2VWKWMIulqSXPCW5lnSio+ztdlmCoXrIHNQGdJNcP1/sCSqAsNb0EtzQWAB+uifgROS9UXYlUiqRdwItDVzA4BjqPoDRipLMsHKVSQqhisAV4FTghfDyWYfxsASQ0lvRS2SD6UdEi4vZGkiZI+lfQQcYPaJZ0j6eOwBfNQYWCWtEnSTZI+AnpJuk7SNEmfSxoVDtsZAnQHngyPrympm6R3JM2Q9Hqi21D3UHkEoxJ+V3yHpLaSJoXv0SRJbSq+emmtObDKzH4EMLNVZra0pM+VpAMlfVx4oKR9JM0OX5f4OZQ0WdIISe8AV/jntYKYWZVagE3AIcB/gBrATKAPMD7c/0/g+vB1P2Bm+PofwHXh6xMI7jZqDBwIvAxUC/c9AJwXvjbgzLiyG8a9/jdwUvh6MtA9fF0NeB9oEq6fRTD0p9L/dpXwPtUDFgD1gSuBG8J9LwPnh68vAl6q7Pqm0wLUCT/XX4Wfx95lfa7CtPuGr68CrkmQfjLwQPjaP68VtFTJnzBmNlvSPgSt6gnFdh8FnB6meytsUdcHjgFOC7e/ImltmP5YoBswLZyNqyawItyXD4yNy7uvpP8DagENgTkEgSfe/kBn4I0wvxhlzBewJzOzDZIeBy4neOJQoV6E7wXBl95fK7pu6czMNknqBhwN9AWeBW6h9M/Vc8CZwO0EwfYsEn8Onw3/9c9rBamSwTo0DriToFXdKG57WffslzQoXcBjZvbnEvb9YGb5AJJqELRyupvZovBiWY1S8ptjZr2SOYkq4B7gE+DRMtL4zQLFhJ+7ycBkSZ8Bv6H0z9WzwPOSXggOta8lHVxGegiu/YB/XitMVe2zBhgN3GRmnxXbPgX4OYCkPgR9fxuKbR8E7B2mnwQMkdQ03NdQUtsSyisMzKsk1QGGxO3bCNQNX38JNAkvEiGpmqSDdvUkM52ZrSFo+V0ct/l9glt4IXhP3q3oeqUzSftL6hi3qQvwP0r5XJnZNwS/Aq9lR4s52c+hf14rSJVtWZvZYuDeEnbdADwaXmT5Hjg/3H4j8LSkT4B3gIVhPnMlXQNMlJQFbCNoxXxXrLx1kv4FfEbQDzstbvcYYKSkLQQ/8YcA/wi7X7IJWpdzdu+MM9pdwKVx65cDoyX9EVhJErfqVjF1gH9KakBwoXYewUx6oyj9c/Us8DegHYCZbQ0vfpf5OUw2ndt9fru5c85lgKrcDeKccxnDg7VzzmUAD9bOOZcBPFg751wG8GDtnHMZwIO1i4Sk/HCuk88lPS+p1m7kNSYcHoakhyV1KiNtH0lH7EIZKZtF0bkoeLB2UdliZl3MrDOwFRgev1Nlz0JYKjO7xMzmlpGkD1DuYO1cuvNg7SrCVKBD2Op9W9JTwGeSYpL+Fs5EOFvSLwHC2QjvkzRX0itA08KMwhnfuoevB0r6RNKscPa9fQi+FH4XtuqPltRE0tiwjGmSjgyPLXUWRefSUZW9g9FVDAXzHQ8CXgs39QA6m9m3koYRPNX5MEl7Ae9Jmgj8hGCCoIOBZsBcgukB4vNtAvwLOCbMq6GZrZE0EthkZneG6Z4C7jazdxVMpfo6wUyJ1wPvmtlNkk4guMPPubTlwdpFpaakmeHrqcAjBN0TH5vZt+H2AcAhhf3RBFOhdiSY4fDpcDKipZLeKiH/w4EphXmFc4iU5DigUzgjHEA9SXUpfRZF59KSB2sXlS1m1iV+QxgwN8dvAi4zs9eLpfspiWfSUxJpIOjq62Vm8VOsFtbF51pwGcP7rF1leh34laRqAJL2k1SbYIbDs8M+7eYEczIX9wHQW1K78NiG4fb4GQwBJhI3CZSkLuHL0mZRdC4tebB2lelhgv7oTyR9DjxE8GvvReBrghkKHySY5bAIM1tJ0M/8gqRZ7Jja82Xg1MILjAQz9HUPL2DOZceolBuBY8JZFAcQzqLoXLryWfeccy4DeMvaOecygAdr55zLAB6snXMuA3iwds65DODB2jnnMoAHa+ecywAerJ1zLgP8P5ngKhihqD0UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_accuracy(three_true_label, three_pred_label)\n",
    "plot_cm(three_true_label, three_pred_label, [\"Moderate\", \"No\", \"Severe\"], \"PHQ Tertiary Confusion Matrix\", \"Singletask_\"+task, 'Tertiary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multi_task(model, test_loader):\n",
    "    \"\"\"\n",
    "    returns predictions on test dataset with the best trained model for single task\n",
    "    :params: task - PHQ/PTSD\n",
    "             model - trained model\n",
    "             test_loader - test dataset\n",
    "    \"\"\"\n",
    "    output_phq = []\n",
    "    actual_phq = []\n",
    "    \n",
    "    output_ptsd = []\n",
    "    actual_ptsd = []\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentence, length, phq_score, ptsd_score in test_loader:\n",
    "            sentence = sentence.to(DEVICE).long()\n",
    "            phq_score = phq_score.to(DEVICE).type(torch.float32)\n",
    "            ptsd_score = ptsd_score.to(DEVICE).type(torch.float32)\n",
    "            \n",
    "            phqop, ptsdop = model(sentence, length)\n",
    "            \n",
    "            \n",
    "            output_phq.extend(phqop.cpu().tolist())\n",
    "            actual_phq.extend(phq_score.cpu().tolist())\n",
    "            \n",
    "            output_ptsd.extend(ptsdop.cpu().tolist())\n",
    "            actual_ptsd.extend(ptsd_score.cpu().tolist())\n",
    "    \n",
    "\n",
    "    return actual_phq, actual_ptsd, output_phq, output_ptsd\n",
    "\n",
    "\n",
    "multi_model = 'temp_models/multitask_bilstm.pth'\n",
    "\n",
    "load_multi_model = LSTM_Multi_Task(vocab_size, embedding_dim, hidden_dim, embed_matrix).to(DEVICE)\n",
    "load_multi_model.load_state_dict(torch.load(multi_model))\n",
    "\n",
    "actual_phq, actual_ptsd, output_phq, output_ptsd = evaluate_multi_task(load_multi_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'No': 24, 'Yes': 23})\n",
      "Accuracy:  0.6595744680851063\n",
      "[[19  5]\n",
      " [11 12]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_label = classify_ptsd(actual_ptsd)\n",
    "pred_label = classify_ptsd(output_ptsd)\n",
    "\n",
    "print(Counter(true_label))\n",
    "print_accuracy(true_label, pred_label)\n",
    "plot_cm(true_label, pred_label, [\"No\", \"Yes\"], \"PTSD Confusion Matrix\", 'Multitask_PTSD', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7659574468085106\n",
      "[[33  0]\n",
      " [11  3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "two_true_label = classify_phq(actual_phq, 'Two')\n",
    "three_true_label = classify_phq(actual_phq, 'Three')\n",
    "\n",
    "two_pred_label = classify_phq(output_phq, 'Two')\n",
    "three_pred_label = classify_phq(output_phq, 'Three')\n",
    "\n",
    "print_accuracy(two_true_label, two_pred_label)\n",
    "plot_cm(two_true_label, two_pred_label, [\"No\", \"Yes\"], \"PHQ Binary Confusion Matrix\", 'Multitask_PHQ', \"Binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7021276595744681\n",
      "[[ 0  4  1]\n",
      " [ 0 33  0]\n",
      " [ 2  7  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_accuracy(three_true_label, three_pred_label)\n",
    "plot_cm(three_true_label, three_pred_label, [\"Moderate\", \"No\", \"Severe\"], \"PHQ Tertiary Confusion Matrix\", \"Multitask_PHQ\", 'Tertiary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlxWIsyfjwW_"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "References:\n",
    "1. https://docs.google.com/document/d/1_PycTNBTQjboYtyZslkte0WlcdyMlyFTMYZlSHLq0EE/edit#\n",
    "PTSD = 66%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_train_single_task(task, model, optimizer, criterion, train_loader, val_loader, epochs):\n",
    "    \"\"\"\n",
    "    returns trained model along with lossess and accuracies per epoch for single task\n",
    "    :params: model - LSTM model\n",
    "             optimizer - Adam optimizer\n",
    "             criterion_phq, criterion_ptsd - MSE Loss functions\n",
    "             train, val loaders - input data and labels\n",
    "             epochs - number of epochs to train the model\n",
    "    \"\"\"\n",
    "    epoch_train_loss = []\n",
    "    epoch_val_loss = []\n",
    "    losses = {'train':[], 'val':[]}\n",
    "    used_early_stopping = False\n",
    "    print(\"Training started...\\n\")\n",
    "\n",
    "    model.to(DEVICE)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1, last_epoch=-1, verbose=True)\n",
    "    early_stop = EarlyStopping(patience=12, path='singletask_{}_early_stopping_model.pth'.format(task))\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        total = 0\n",
    "        correct =  0\n",
    "        print(\"Epoch : \", epoch+1)\n",
    "        model.train()\n",
    "        for sentence, length, phq_score in train_loader:\n",
    "            sentence = sentence.to(DEVICE).long()\n",
    "            label = phq_score.to(DEVICE).type(torch.float32)\n",
    "           \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            task_op = model(sentence, length)\n",
    "\n",
    "            loss = criterion(task_op, label)\n",
    "            loss.backward()\n",
    "            \n",
    "            epoch_train_loss.append(loss.item())\n",
    "            optimizer.step()\n",
    "      \n",
    "        train_loss = np.average(epoch_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total = 0\n",
    "        correct =  0\n",
    "        with torch.no_grad():\n",
    "            for sentence, length, phq_score in val_loader:\n",
    "                sentence = sentence.to(DEVICE).long()\n",
    "                label = phq_score.to(DEVICE).type(torch.float32)\n",
    "               \n",
    "        \n",
    "                task_op = model(sentence, length)\n",
    "\n",
    "                loss = criterion(task_op, label)\n",
    "        \n",
    "                epoch_val_loss.append(loss.item())\n",
    "\n",
    "        val_loss = np.average(epoch_val_loss)\n",
    "\n",
    "        scheduler.step()\n",
    "        early_stop(val_loss, model)\n",
    "\n",
    "\n",
    "        print(\"Train loss: {0:.3f} Val loss: {1:.3f}\".format(train_loss, val_loss))\n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "\n",
    "        if early_stop.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            used_early_stopping  = True\n",
    "            break\n",
    "\n",
    "        losses['train'].append(train_loss) \n",
    "        losses['val'].append(val_loss) \n",
    "\n",
    "    return model, losses, used_early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Epoch :  1\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.126 Val loss: 0.109\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  2\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.115 Val loss: 0.084\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  3\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.114 Val loss: 0.078\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  4\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.116 Val loss: 0.082\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  5\n",
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Train loss: 0.117 Val loss: 0.079\n",
      "--------------------------------------------------------------------------------------\n",
      "Epoch :  6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-c4ad0af6538f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNewDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_test_PHQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_train_single_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-6bd0ddefbb7c>\u001b[0m in \u001b[0;36mnew_train_single_task\u001b[0;34m(task, model, optimizer, criterion, train_loader, val_loader, epochs)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mtask_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mtml/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-14c0a0e03530>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence, sentence_length)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0msentence_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mout_pack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_pack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mtask_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mht\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mtml/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mtml/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    662\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    663\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0m\u001b[1;32m    665\u001b[0m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[1;32m    666\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vocab_size = 6176\n",
    "embedding_dim = 300\n",
    "hidden_dim = 128\n",
    "lr = 1e-2\n",
    "epochs = 600\n",
    "batch_size = 64\n",
    "task = \"PHQ\"\n",
    "\n",
    "model_task = LSTM_Single_Task(vocab_size, embedding_dim, hidden_dim, embed_matrix)\n",
    "optimizer = torch.optim.Adam(model_task.parameters(), lr=lr)\n",
    "criterion = torch.nn.MSELoss().to(DEVICE) \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(NewDataset(train_encoded, new_train_PHQ), batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(NewDataset(test_encoded, new_test_PHQ), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model_task, losses, early_stop = new_train_single_task(task, model_task, optimizer, criterion, train_loader, test_loader, epochs)\n",
    "\n",
    "\n",
    "torch.save(model_task.state_dict(), 'singletask_'+task+'_bilstm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Depression_detectoin.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
